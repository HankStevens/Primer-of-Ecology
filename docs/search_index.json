[
["index.html", "Primer of Ecology with R Preface", " Primer of Ecology with R Hank Stevens 2020-08-16 Preface In spite of the presumptuous title, my goals for this book are modest. I wrote it as "],
["theory.html", "1 Theory in Ecology 1.1 Examples of theories 1.2 An example: Metabolic Theory of Ecology 1.3 Power law scaling implies constant relative differences", " 1 Theory in Ecology In this chapter, we introduce a perspective on ecological theory, and provide an example of an efficient theory, metabolic scaling. Scientific theory is a body of knowledge that provides an organized and mechanistic view of how the world works (Scheiner 2010). Theories concerning gravity, general relativity, and evolution by natural selection provide structured ways of connecting observations, patterns, and processes that provide insight into why the world is the way it is. This stands in stark contrast to the colloquial use of theory that implies a lack of knowledge, as when someone says “oh, that’s just a theory”, referring to a guess without much evidence. Scientific theory is a set of explanations whose validity has been tested repeatedly by experiments and new data. 1.1 Examples of theories Ecology has lots of theories, of all different types. Below I discuss some which may be prevalent, important, useful, or some combination. 1.1.1 Hierarchy theory An early and persistent organizing theory in ecology is based on hierarchy theory (O’Neill et al. 1986; Rose et al. 2017, and references therein). It posits that ecological systems are structured hierachically, such that each entity comprises subunits. For instance, an entity such as a population of big bluestem grass (Andropogon gerardii) is part of a larger ecology community of many species. The population of big bluestem comprises subpopulations separated in space, a subpopulation comprises separate individuals, that each individual comprises multiple ramets and a set of organ systems and tissues, which comprise different cell types. This theory posits that each entity gives rise to emergent properties to the hierarchical level above it, and influences processes within each smaller sub-entity in the hierachical level below it. As a disciplinary organizing principle, this approach structures nearly all of the ecology curriculum. Hierarchy theory gets more complicated when the levels of a hierarchy start to include fundamentally different types of entities. The big bluestem hierarchy above included only biotic components–a individual is part of a population which is part of a community of individuals of multiple species, and is made up of organ systems and tissues. Ecology, however, includes both the biotic and the abiotic parts of environments. An ecosystem includes a community of species, but also the nutrients, water, light, and other abiotic components, along with the spatial arrangement of all of these things. Different hierarchies are useful for different questions. An individual organism can play very different roles in different hierarchies. Consider and individual bunch grass. To understand how a population evolves, we need to count individuals within a population, because evolutionary fitness is tracked by the number of independent reproductive units. In contrast, to understand competitive interactions, it may be much more important to weigh the biomass of groups of individuals in a population, because biomass is more closely related of resource uptake. 1.1.2 A general theory of ecology Good scientific theories exist within a hierarchy of disciplinary knowledge (Scheiner and Willig 2011). They explain phenomena within a domain of knowledge which is organized around principles and assumptions. Scheiner and Willig posit a theory of biology that explains phenomena relating to the “diversity and complexity of living systems”. One of the ten principles on which this theory depends is that “the cell is the fundamental unit of life”. Subsumed within their theory of biology is the theory of cells whose domain is “cells and the causes of their structure, function, and variation.” This theory in turn is based on principles and has theories to organize our understanding of cells and what cells do. Models are specific and explicit manifestations of more general theories. In this book, we focus on popular mathematical models that are specific manifestions of theories of ecology. Scheiner and Willig (2011) propose a theory of ecology, some of which we cover in this book. Here is part of this theory: The General Theory of Ecology Domain: The spatial and temporal pattern of the distribution and abundance of organisms, including causes and consequences. Principles: Organisms are distributed in space and time in a heterogeneous manner. Organisms interact with their abiotic and biotic environments. Variation in the characteristics of organisms results in heterogeneity of ecological patterns and processes. The distributions of organisms and their interactions depend on contingencies. Environmental conditions as perceived by organisms are heterogeneous in space and time. Resources as perceived by organisms are finite and heterogeneous in space and time. Birth and death rates are a consequence of interactions with the abiotic and biotic environment. The ecological properties of species are the result of evolution. These principles constitute what we know is true about ecological systems. Some of these principles provide the focus for a single chapter while other principles apply broadly to many chapters in this book. Here is my own perspective on a general theory of ecology: Domain: The house of life1: its constituent entities, causes, and consequences. Principles: Entities2 are open systems with inputs and outputs. Entities have internal complexity. Entities include self-replicating components (living elements). Entities interact via inputs, outputs, and behavior. Rates of change, including inputs and outputs, are influenced directly by physical factors: space, temperature, and concentration. You will see elements of these principles throughout this book as well. 1.1.3 Efficient theory Marquet et al. (2014) argue that the best theories are those which are efficient. Such theories tend to be based on first principles, which are observations and laws that are fundamental assumptions in a scientific domain. In biology, such principles can include the laws of thermodynamics, and mathematical properties such as the central limit theorem. Theories built upon first principles are thus well-grounded in reality as we understand it and lead logically to refinements. Marquet and his colleagues also claim that efficient theory is expressed in mathematics. Mathematics is a universal language that is unamibiguous. It forces us to be as clear as possible about what we mean when we state a theory.3 Last, efficient theories are those that make a large number of predictions using only a small number of free parameters.4 Examples of efficient theories we cover in this book include metabolic scaling, exponential growth, density dependence, and ecological neutral theory. Marquet et al. and Scheiner and Willig emphasize slightly different features of the definition of “theory”. Scheiner and Willig emphasize relatively broad ideas that are well-supported by experiments and repeated observation. Marquet and colleagues tend to mean something fairly specific and narrow, typically something that can be expressed mathematically. Scheiner and Willig might refer to such theory as constitutive theory or even simply a model. Next, I describe the Metabolic Theory of Ecology. This theory is based on first principles, and its central tenets are expressed mathematically. It’s core equation has a very small number of free parameters (fitted constants) and makes a very large number of testable predictions. Parts of this theory are supported by a very large number of observations. It fits everyone’s definition of theory. 1.2 An example: Metabolic Theory of Ecology Metabolic rate is central to how rapidly individuals forage for, consume and use resources, reproduce and die. The metabolic theory of ecology (Brown et al. 2004) is a well-supported body of knowledge about the underlying mechanisms, and the resulting profound and wide-ranging consequences for populations and ecosystems. Body size and temperature are fundamental properties of organisms and the environment. The study of how body shape and body processes scale with body size is allometry. Because body size affects metabolic rate, body size indirectly helps determine population growth rates and how species interact with each other. Temperature affects how molecules vigorously molecules vibrate and move, and so increasing temperature tends to speed up chemical reactions. As metabolism is really just a complex network of biochemical reactions, temperature influences metabolic rate. The core of this theory is expressed in a simple mathematical equation that describes how body size and temperature govern metabolic rate. 1.2.1 Body-size dependence There is a profoundly simple and general rule describing the effect of interspecific variation in body size on metabolism.5 This biological law is referred to as the Kleiber law (Kleiber 1932), or quarter power scaling (Brown et al. 2004). When we compare the basal (i.e. resting) metabolic rates of different species, across a wide range of body sizes spanning many orders of magnitude, we find that whole-organism resting metabolic rate increases with organism mass raised to the three-quarter power, or, \\[ B = aM^{z} \\quad;\\quad z = 3/4 \\] In this equation, \\(B\\) is basal, or resting, metabolic rate, \\(M\\) is body mass, \\(a\\) is a proportionality constant, and \\(z\\) is the power law scaling coefficient. The proportionality constant \\(a\\) varies depending on the type of organism such as arthropods, fish, or mammals. Plants scale in the same manner (Niklas and Enquist 2001), although size or mass is a little trickier to measure. The scaling coefficient, \\(z\\), is the seemingly magical constant that many have argued does not vary substantially among different types of organisms. Ecologists typically describe metabolism-mass relations and other power law behavior using logarithmic scales. When we do that, power law relations become linear. Using our rules for exponents and logarithms, metabolic scaling becomes \\[ \\log B = \\log a + z\\log M\\] so that \\(\\log B\\) increases linearly with \\(\\log M\\) with a slope of \\(3/4\\). Our brains can process and compare linear relations much more easily than curvilinear ones. Here we plot the curvilinear relation in R using curve() in the graphics package of R that is included in the base installation as one of the core packages. The function curve() can plot any curve that be expressed as a function of x. Below, we draw a curve of a dotted 1:1 line for comparison, and then add the power function \\(x^{3/4}\\). Figure 1.1: Metabolic rate increases predictably with species body sizes. ## using curve, let your variable be &#39;x&#39;. curve(1*x, from = .01, to=100, ylab = &quot;Metabolic rate (B)&quot;, xlab=&quot;Body mass (M)&quot;, lty=3) curve(x^(3/4), from = .01, to = 100, add=TRUE)} To help us grasp the implications of this, let’s consider mass-specific metabolic rates. “Mass-specific” means on a per-gram basis.6 Mass-specific metabolic rate is basal metabolic rate of an individual divided by its mass, or \\(B/M\\). The mass-specific metabolic rate allows us to compare directly, for example, the metabolic rate of a cell in a shrew vs. a cell in an elephant. Which cell is burning fuel faster? We can estimate this from the above metabolic scaling principle and the using rules exponents \\[ \\frac{B}{M} = a \\frac{M^z}{M^1} = a M^{z-1} = aM^{-1/4}\\] From this, we now have the rule that mass-specific metabolic rate declines with organisms mass raised to the negative one quater power eq1 = function(M, a){a*M^-0.25} # create the function, F(M) ggplot(data=data.frame(x=c(0.1, 100)), aes(x=x) ) + stat_function(fun=eq1, geom=&quot;line&quot;, args=list(a=1)) + xlab(&quot;Mass (M)&quot;) + ylab(&quot;Mass-specific metabolic rate (B/M)&quot;) Figure 1.2: Mass-specific metabolic rate declines predictably with species body sizes. Over the years, there has been heated debate about (i) the precise value of the scaling coefficient \\(z\\), and (ii) the underlying mechanism. Early arguments suggested that \\(z \\approx 2/3\\) because the rate heat dissipation scales with the amount surface area. Why \\(2/3\\)? Let’s envision the volume of an organism having three linear dimensions, so the volume scales to the cube of linear dimensions, while the surface area scales to the square of these linear dimensions,7 \\[V \\propto L^3\\] \\[A \\propto L^2\\] The early explanation was that metabolic rate, \\(B\\), scales linearly with area, \\[B \\propto A^1 \\propto L^2\\]. With substitution we get, \\[L^2 \\propto V^z \\propto (L^3)^z\\] implying that the exponents \\(2 = 3z\\) or \\(z=2/3\\), so we get, \\[B=V^{2/3}\\], and, for the most part, mass scales linearly with volume for mammals or any other such group. This early theory was because it started with first principles (heat dissipation and geometry) and resulted in the prediction of a single parameter. It could then be used to make predictions about how metabolic rate scales with body mass. Metabolic rate governs a huge amount of biology and ecology, including resource consumption rates, lifespan, and maximum population growth rates. Therefore, this theory and this model could be powerful tools for understanding the world and making testable predictions. The above model is good because it could be tested. That is what has been done, and scientists found that there was a consistent mismatch between observations and the theory. Investigators showed that the value of the exponent appeared closer to 3/4 raher than 2/3. In the 1990s, a group including Jim Brown and Geoffrey West (West, Brown, and Enquist 1997) proposed an underlying mechanism that explained why it should be 3/4. They assumed that organisms must distribute resources from a single source through a branching, fractal-like, space-filling network to all parts of the body, the size of the smallest branch ( a capillary) was the same for organisms of all sizes. the energy required to distribute the resources must be minimized, that less energy-efficient designs would be lost through natural selection. The prediction that resulted from these assumptions was that the exponent would be 3/4. This theory and model begin with different first principles and makes a different prediction. Soon Jayanth Banavar and his colleagues offered an alternative (Banavar, Maritan, and Rinaldo 1999; Banavar et al. 2002), arguing that the assumption of the fractal-like network was not correct, and in any event, was not necessary and did not apply to all organisms. They proposed different theory with less restrictive assumptions and found nonetheless that the exponent was also predicted to be 3/4. At the base of all these arguments is the geometry of the resource distribution system. All organisms take in limiting resources and have to distribute those resources to each part of each cell in the body. The key point is that the larger the organism, the greater the portion of the resources are in transit at any instant in time. This leads to an increasingly inefficient system, in which the metabolism of larger organisms has to run more slowly per unit resource: Larger organisms can process more resources per unit time (\\(B=aM^{3/4}\\)), but do so less and less efficiently (\\(\\frac{B}{M}=aM^{-1/4}\\)) due to resources in transport. Banavar, Brown and others eventually collaborated to address quarter power scaling in animals in particular which led to additional novel predictions (Banavar et al. 2010). This theory remains a fertile and active area of research (Glazier 2018). The interested reader should be careful to distinguish between patterns observed across many species of very different sizes, versus patterns observed in a single species with individuals of different sizes versus other types of patterns. Subtly different patterns may be driven be very different mechanisms. 1.2.2 Temperature dependence In addition to body size, temperature plays the other key role in regulating metabolic rate. The Arrhenius equation connects the macroscopic property of temperature to the kinetic energy of molecules and the rates they govern. Metabolic rate is proportional to these rate determining processes, \\[B = a e^{\\frac{-E_a}{kT}}\\] where \\(a\\) is just a constant, \\(e\\) is the exponential, \\(E_a\\) is the average activation energy of rate-limiting enzymes (units, eV), \\(k\\) is Boltzmann’s constant (units eV\\(\\,\\)K\\(^{-1}\\)), and \\(T\\) (units deg K). Bolztmann’s constant (\\(\\backsim 8.6 \\times 10^-5\\)\\(\\,\\)eV\\(\\,\\)K\\(^{-1}\\)) converts the macroscopic property of temperature to kinetic energy of molecules. Individual biochemical reactions combine to determine basal metabolic rate, so Gillooly (2000) have taken this as a foundation for the metabolic theory of ecology (Brown et al. 2004). In 2000, they suggested that the average activation energy is approximately \\(E_a = 0.23\\,\\)eV . Subsequent work has described this as “temperature sensitivity”, where larger numbers imply that organisms respond more strongly to temperature variation. The Arrhenius equation is a little more complicated that a simple power law, but not too much. Over the range of biologically relevant temperatures, it is dominated by a largely exponential increase in metabolic rate with increasing temperature (Fig @(fig:arrh)). # with base R # base R: curve(10^4*exp(-0.23/(8.5 * 10^-5 *x)), 276, 316), ylab=&quot;B&quot;, xlab=&#39;T&#39;) # or ggplot2 # the function, with default parameter values eq.t &lt;- function(t,a=10^4,E=0.23,k=8.6 * 10^-5){a*exp(-E/(k*t))} # the data used in our function temps &lt;- data.frame(t=276:316) ggplot(data=temps, aes(x=t)) + # set the basic properties of the plot stat_function(fun=eq.t, geom=&quot;line&quot;) + # set the function to plot xlab(&quot;Temperature (K)&quot;) + ylab(&quot;Metabolic rate (B)&quot;) # add labels Figure 1.3: The effect of body temperature on ectothermic metabolic rates can be approximated with the Arrhenius function, \\(B = a e^{-E_a/(kT)}\\). Here \\(a = 10^4\\), and \\(E_a = 0.23\\). It is similar in shape to a power law with z &gt; 1, over the range of biologically relevant temperatures. When we linearize the relation between metabolic rate and temperature, we get \\[ \\begin{aligned} B &amp;= a e^{\\frac{-E_a}{kT}}\\\\ \\log(B) &amp;= \\log{a} - E_a\\frac{1}{kT}\\\\ \\end{aligned} \\] where the dependent variable is \\(1/(kT)\\), \\(-E_a\\) is the slope, and \\(\\log a\\) is the intercept. Thus, the negative slope of this relation describes theoretical prediction for the effect of temperature on metabolic rate. So, there you have it. The metabolic theory ecology is the algebraic product of body size- and temperature-dependence: \\[B = a M^{3/4} e^{\\frac{-E_a}{kT}}\\] This theory makes quantitative predictions regarding all kinds of ecology phenomena (Brown et al. 2004), including home range size population growth population size resource uptake predation and other species interactions, and ecosystem cycling. Note that these relations are based on first principles of geometry and thermodynamics, and that they depend on only a small number of parameters (\\(a\\), \\(-E_a\\), and perhaps \\(z=3/4\\)), and makes a tremendous number of predictions. Therefore, Marquet et al. (2014) propose that this is “good” theory, and very efficient. 1.3 Power law scaling implies constant relative differences In power law scaling, relative change is constant. That is, a proportional change in one variable results in a proportional change in the other. For instance, when we compare a smaller species to a larger species with \\(100 \\times\\) the body mass, we can expect to see metabolic rate increase by \\(31.6 \\times\\), regardless of the mass of the smaller species. For now, we will verify this numerically for some limited cases. # define body mass and metabolic rate m &lt;- c(.01, 1, 100, 10000) b &lt;- m^.75 Now we will divide each mass \\(i\\) by the next smallest mass \\(i-1\\). We do that using a vector by dividing each mass except the first one, by each mass except the last one. # round(x, digits=0) rounds number to zero decimal places round( m[-1]/m[-length(m)], digits = 0) round( b[-1]/b[-length(b)], digits = 1) When we do these divisions, we see the constant relative change (1.1). Table 1.1: As we increase mass by a constant multiplier (10x), power law scaling results in a constant proportional change in basal metabolc rate. Small Med. Big Huge Mass 0.01 1.00 100.00 10000.00 Basal.metabolic.rate 0.03 1.00 31.62 1000.00 Relative.change.m NA 100.00 100.00 100.00 relative.change.b NA 31.62 31.62 31.62 We can verify this generally using algebra, not just in the particular case above. We will show that if mass increases by a constant multiplier, metabolic rate will also, regardless of the particular masses involved. Let mass \\(m_2\\) be greater than mass \\(m_\\) by a factor of \\(c\\), so that \\(m_2 = c m_1\\), and \\[\\frac{m_2}{m_1} = c\\]. We would like to show that the ratio of the metabolic rates \\(b_2 / b_1\\) is also a constant. Since \\(m_2 = cm_1\\), we can say that \\[b_1 = a m_1^{3/4}\\] \\[b_2 = a (cm_1)^{3/4} = ac^{3/4}m_1^{3/4}\\] \\[\\frac{b_2}{b_1} = \\frac{ac^{3/4}m_1^{3/4}}{am_1^{3/4}}\\] When we reduce this fraction, we a left with \\[\\frac{b_2}{b_1} = c^{3/4}\\] This shows that with power law scaling, increasing \\(x\\) by a constant multipier (or proportion), \\(y\\) increases by the same proportion raised to that power. Let’s represent this graphically in a couple of ways, reusing data we made up previously in this chapter. First, we just change the axes themselves, so that the units of the scales are multiples of 10 (often in scientific notation). # using base R par(mar=c(5,4,0,0), mgp=c(1.5,.4,0) )# set figure margins in &quot;lines&quot; curve(x^(3/4), from = .01, to = 100, log=&quot;xy&quot;, ylab=&quot;Basal metabolic rate&quot;, xlab=&quot;Mass&quot;) text(10, 80^.7, expression(M^0.75)) Figure 1.4: changing the scales of the axes to linearize power law relations. Note scales are logarithmic, using the original linear values. References "],
["oft.html", "2 Optimal Foraging 2.1 A prey model 2.2 The patch model 2.3 A simulation of a prey model", " 2 Optimal Foraging knitr::include_graphics(&quot;figs/CowieF3.png&quot;) Figure 2.1: Optimal foraging theory (OFT) generates testable quantitative predictions that allow a less ambiguous description and explanation for observed patterns and processes. Here, a simplistic model of Great Tit (Parus major) foraging that includes only gross energy intake underestimates the time spent in patches (dashed). In contrast, a model that includes energetic costs of traveling and searching matches predictions far better (solid). From Cowie (1977). It can be useful to think of natural selection as an optimizing process: phenotypes diversify, winners replicate and losers don’t, and the phenotypes of winners tend to get passed on to the replicants. Therefore, we often assume, as did Dr. Pangloss, that the species that exist now are the best of all possible species, that is, they are of optimal design. And like Dr. Pangloss, we would be woefully mistaken if we stopped there. Nonetheless, optimization, that is, the tendency toward an optimum, helps us generate testable hypotheses and we consider some of these below. Optimal Foraging Theory (OFT) helps us consider what organisms would do if they foraged optimally. All organisms–plants, fungi, archaea, and even animals–forage, and they are all subject to natural selection. Therefore, their phenotypes work pretty well, but probably not optimally and definitely not optimally for all times and places. Nonetheless, OFT is an efficient theory about the behavior of an organism, in the absence of other complications. Therefore, it allows us to study the relative importance of those “other complications.” Foraging is a key link between the individual, and communities and ecosystems (Beckerman, Petchey, and Morin 2010). All organisms interact with their environment via consumption, and the choices they make influence population dynamics, species interactions, nutrient cycling, and even the physical structures of terrestrial and aquatic habitats. The text and logic of this chapter rely heavily on Stephens and Krebs (1986) and Ellner (2009). In Scheiner and Willig’s edited volume on The Theory of Ecology, Andy Sih (Sih 2011) proposes that the following propositions form the basis of foraging theory: Foraging patterns maximize fitness or a correlate of fitness. Foraging patterns depend on the range of options available to the forager and on how each available option affects fitness or a correlate of fitness. Foraging behaviour balances conflicting demands–tradeoffs are important in shaping foraging behaviour. These properties are the outcome of natural selection operating on foraging behavior. Our understanding of foraging itself considers these three features (Stephens and Krebs 1986): currency (what is being optimized), constraints (features of behaviour that limit optimality), and the resulting decision rules. Currency is that quantity that is optimized by the forager. This currency is assumed to be a quantity that limits fitness, such as energy or a particular consumable resource. It measure it as a rate, for instance, energy gained per unit time (E/T) or the uptake of a critically limiting resource per unit time (R/T). Constraints are limitations that we assume about organisms. These might include distances between resource patches, the time and costs associated with extracting a resource from a substrate or subduing prey. They also include constraints imposed by other species including competitors and predators. Constraints can get coplicated quickly; however, simple quanitative theory makes predictions against which we can evaluate more complicated assumptions. Decision rules are what we ascribed to a forager’s choices. A decision rule concern the probability of attacking prey if encountered, or when to leave one resource patch in order to search for another. An additional way to think about all this is where, when, and what. A great deal of effort has focused on understanding patch use: where foragers should explore for resources, and when they should give up and go in search of another patch (Charnov 1976). These are patch use models, and are based on economic models and the marginal value theorem. Another avenue of inquiry concerns what animals should eat. For instance, should they go after big prey that may be hard to catch and difficult to subdue, or just snack on what is easy? These are prey models or diet models, and attempt to explain why organisms consume what they do. Much like the patch models, theory attempts to predict which prey or resources organisms encounter, perceive, attack or “handle”, and which they ignore. A note on “prey”. All organisms forage for resources. Plants extend branches toward the light, and proliferate leaves and roots into resource rich patches, and rhizomes grow longer faster through resource-poor soils. Bumblebees search for and learn where to find nectar-rich flowers, and wolves hunt in packs to take down large ungulates. Some bacterivorous nanoflagellates intercept particles selectively depending on the perceived nutritional value of particles (Boenigk et al. 2002). So, depending on the forager, its “prey” may be \\(\\mathrm{NO}_{3}^-\\) ions, nectar, moose, or bacteria. Therefore, we will refer to these resources variously as prey, prey items, resources, and resource items. Some of these ideas are best handled with patch-based models (Charnov 1976) where a “resource patch” is a more intuitive and useful unit. A note on “handle”. All organisms pays costs to consume resources. In OFT, “handle” typically means expending energy an time to attack and subdue prey (predators), proliferate into resource rich areas (plants), exude extra cellular enzymes (fungi); ingest the item(s), and then resume searching. 2.1 A prey model Here the forager asks, “should I eat this?”8 Let’s start where this field started, with a prey-centered model (MacArthur and Pianka 1966; Emlen 1966). 2.1.1 Our intuition Figure 2.2: The amount of energy lost and gained by a foraging ant–it may decline slowly over time while searching, and decline quickly while handling a food item. Our ant gains energy when it consumes an item. Below: Our ant. She expends energy while searching for food. Upon encountering a food item, she may choose to ‘handle’ it (encounters 1 and 3) and gain energy, or not handle it (encounter 2) and save the added cost of handling it. What does our intuition tell us is the optimal strategy for foraging? It seems reasonable that if a forager encounters food, it should eat it. However, if handling it costs more than the forager gets back in energy, then it isn’t worth it. We might think of this as the ratio as profitability, \\[\\frac{e_i}{h_i}\\] where \\(e_i\\) is the energy in an item of type \\(i\\), and \\(h_i\\) is the cost of handling said item. If \\(e_i/h_i&lt;1\\), then it doesn’t make sense to select the item. Further, handling an item means that the forager is not looking for a better food item. This suggests that even if \\(e_i/h_i&gt;1\\), a forager may not want to handle it if it is likely to soon encounter food items of higher energy content. On top of this, the act of searching may expose a forager to a risk of running into competing foragers, or even being eaten by a bigger forager. Clearly, a forager faces tradeoffs as it searches and when it encounters resources. 2.1.2 Mathematical support Let us assume that natural selection tends to maximize the currency, or \\(G/T\\). Our model will use these parameters and variables: \\(i =\\) index for prey type \\(p_i =\\) probability that a forager attacks prey if encountered (units are number handled per number encountered, or #/#; this is a dimensionless parameter) \\(S =\\) total time spent searching (units = seconds, \\(s\\)). \\(T =\\) total elapsed time (units = s) \\(\\lambda_i =\\) rate of encounter with prey of type \\(i\\) (units = # encountered/s = \\(\\#/s\\); note this can also be #/area × area/s, if we like). \\(e_i =\\) net energetic gain from catching and consuming a single type-\\(i\\) prey item (units = Joules, J). This includes the gross energy of the item minus handling costs plus energy not lost by searching during that time. \\(h_i =\\) handling time for an item of type \\(i\\), (units = s/#). \\(c =\\) energy cost per unit of time while searching (units = J) From these definitions we can calculate other important quantities. Total number of items encountered of type \\(i\\) is \\(S\\lambda_i\\) (units \\(= s\\, \\#\\,s^{-1} = \\#\\)). Total number of type \\(i\\) items handled is the proportion, \\(p_i\\), of those encountered that the foragers chooses to go after, or \\(S\\lambda_i p_i\\) (units = #). Total time spent handling all items of type \\(i\\) is \\(S\\lambda_i p_i h_i\\) (units = s). Total elapsed time, \\(T\\), is time spent searching plus time spent handling, which is \\(S + \\sum_i^n S\\lambda_i h_i p_i\\). We use the summation to add together the total handling times for each prey or resource type \\(i = \\{1,\\,2, \\ldots ,\\,n\\}\\). A note on \\(\\lambda\\) A forager encounters prey at random, and this is known as a “Poisson process”, where the number of encounters in a specified time interval is a random variable drawn from the Poisson probability distribution. It turns out that the time between events of a Poisson process follows the Exponential distribution. The Poisson distribution is determined by a single parameter, its mean. The Exponential distribution is also described by a single parameter, its rate. It turns out that we use the same \\(\\lambda\\) for both. We have combined many variables and parameters. How can we check the logical consistency? We do that by checking whether the units are the same in all terms of a model. Here we check units for total handling time, \\(H = S\\lambda_i p_i h_i\\) by replacing the variables and parameters with their units. The units for \\(H\\) are seconds, so we have \\[\\mathrm{s = s \\frac{\\#}{s} \\frac{\\#}{\\#} \\frac{s}{\\#}}\\] When we multiply these fractions, we find that the \\(\\#\\)’s and two of the s’s cancel out and we are left with \\(s=s\\). This shows that our use of parameters and variables is at least logically consistent. The total energy gain from eating all the items is the number of items of each type \\(i\\) handled times the net amount of energy per item of type \\(i\\), \\(e_i\\), \\(\\sum_{i=1}^n S\\lambda_i p_i e_i\\). Therefore, rate of energy intake while handling and eating is \\[\\mathrm{intake} = \\frac{\\sum_{i=1}^n S\\lambda_i p_i e_i}{S + \\sum_{i=1}^n S\\lambda_i h_i p_i}\\] If we also subtract the cost of searching, we arrive at the quantity we want to maximize, \\[\\frac{\\sum_{i=1}^n \\lambda_i p_i e_i}{1 + \\sum_{i=1}^n \\lambda_i p_i h_i}-c\\] A major question in OFT is whether a forager should include a particular prey type. Say we rank the prey types, \\(i=\\{1,2,...,m,...,n\\}\\), in terms of energy content, where type \\(i=1\\) has the most energy per item, \\(i=m\\) is intermediate, and type \\(i=n\\) has the least. Which items should a forager include in her diet? Should it be only the most energy-dense, or should it include the second as well, or should it be all of them? Part of the answer rests on the ratio of energy gain versus handling costs, or profitability, \\(e_i/h_i\\). It turns out there is an useful rule, which we won’t derive mathematically: A less energy-dense item should be added if its net energy content is greater than the realized energy gain from all the other items, or \\[\\frac{e_{m+1}}{h_{m+1}} &gt; \\frac{\\sum_{i=1}^m \\lambda_i e_i}{1 + \\sum_{i=1}^{\\tag{2.1}i} (#eq:preypred1)\\] where the diet already includes items 1-\\(m\\), and the realized energy content of the diet takes into account average encounter rates of each item type9 Implicit in this is the prediction that items of type \\(i\\) should either always be selected or never be selected if encountered10. (This can be shown algebraically). Thus, a particular type should always be included if the instantaneous net gain11 of that type is greater than the realized long term average net gain of all the more profitable types. The quantity on the right side of (2.1) takes into account the long term encounter rates \\(\\lambda_i\\) as well as search costs. Another prediction is that when encounter rates increase (as with increasing abundances), selectivity increases12. Note that encounter rates are in the right hand side (RHS), so as they increase, so will that fraction on the right. That will make it harder for the above inequality to be true. If you don’t believe it, try this simplified version (Fig. 2.3). eq = function(lambda){lambda/(1+lambda)} # create the function you want myData &lt;- data.frame( lambda=c(0, 10) ) # data you need ggplot(data=myData, aes(x=lambda)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=eq, geom=&quot;line&quot;) + ylab(bquote(over(lambda, 1 + lambda))) + xlab(bquote(lambda)) # add labels Figure 2.3: Selectivity increases with average encounter rates. So how does this model fair in the real world? Well, the zero-one rule doesn’t work at all; it turns out that for a variety of reasons, foragers do not completely ignore low-profit prey. However, there is great support for the other two predictions (above) (Stephens and Krebs 1986). Most importantly, in all cases, the theory has provided a clear framework to generate testable predictions from unambiguous assumptions, and that is what we want from efficient theory. The model itself helped guide research, and inclusion of greater complexity has led to deeper understanding of behavior and its consequences for species interactions. 2.2 The patch model …in which ominscient rationale agents roam free. Here the forager asks, “how long should I stay here?” In the simple prey model, a forager searches for and then encounters prey one at a time, makes a decision to consume or not, and then resumes searching. In a simple patch model, a forager searches for and encounters patches one at a time, first consumes resources and then makes a decision to leave or not. Perhaps the single most important prediction of the simple patch model is that a forager should leave a patch when its current rate of energy gain drops down to the average or expected rate of energy gain for the habitat at large. In what follows, we rely on Charnov (1976), who applies the marginal-value theorem to explain optimal behavior. Here, as in economics, “marginal value” refers to a rate - the slope of a function. In calculus, this is a derivative. Here, it is the derivative (i.e. slope) of the relation between energy gain and time. Let’s assume the simplest of all patch models: one patch type, all patches are the same, and they are distributed randomly in the habitat. Assume also that a forager uses time to travel between patches (travel time, \\(t_t\\)) and time searching within a patch (residence time, \\(t_r\\)). A forager encounters patches at random, with a rate of \\(\\lambda\\), and as such, would have a mean time to next encounter of \\(1/\\lambda\\). The patch is characterisized by its gain function \\(g(t_r)\\) (Fig. @ref{fig:gain)) which is the expected13 cumulative net energy gained, given time \\(t_r\\) spent in the patch. The gain function is a cumulative total net amount. We can imagine different types of gain functions. Figure 2.4: Net energy gain as a function of patch residence time may take different forms. Net energy gain increases through time but slows (decelerates) as a greater fraction of the resources in the patch are consumed. The top line (solid) assumes that there are diminishing returns as a patch is depleted, but the forager continues to find resources in excess of metabolic losses. The lower line (dashed) represents the net energy gain that could arise as a patch is depleted more fully and the costs continue unabated. Try this: Draw a gain function where the prey remain well hidden at first, but the forager becomes increasingly able to find more and more prey. Draw a gain function where there is no cost to foraging, and where the forager eventually depletes all the prey. In one graph, draw two gain functions for a resource rich patch and for a resource poor patch. So, our currency is long-term average energy intake, \\(R\\), and we want to maximize this. The decision our forager needs to make is how long to stay in a patch. The forager’s constraints share some similarity with the prey model (Stephens and Krebs 1986). between-patch travel time and within-patch hunting time are distinct, and … … independent of each other, a forager encounters patches sequentially and randomly, in a given patch, net expected energy gain is a function of time spent in the patch… …that is zero when \\(t=0\\), and …increases with time, but then decelerates the forager is omniscient - it knows everything about available patches and does not learn anything new as it forages (because it already know everything). The forager must decide how long to stay in the patch to maximize \\(R\\). Let \\[R=\\frac{g(t)}{t_t + t_r}\\] where \\(t_t + t_r\\) is the total time from leaving one patch, traveling to the next patch, foraging in the second patch, and then leaving the second patch. Intuitively, we can imagine that the long term average rate of energy gain \\(R\\) is unimodal (hump-shaped) in the following scenario. Upon encountering a patch the forager has no resources and thus \\(R\\) is actually negative due to the costs of traveling to the new patch. As \\(t_r\\) increases and the forager gains energy, \\(R\\) will increase and become positive. An assumption of the theory (and reality) is that the gain function, \\(g(t_r)\\), decelerates–the rate of energy intake declines as the patch is depleted. With increasing time in the patch and lower rate of energy intake, \\(R\\) starts to decline. Because \\(R\\) is unimodal, we can use calculus to find its maximum. This will occur when its slope is zero, and the slope of a function, \\(F\\), is its derivative, \\(F^\\prime\\). If we asssume that travel time is constant, then we can take the partial derivative of \\(R\\) with respect to just the residence time, \\(t_r\\), \\(\\delta R / \\delta t_r\\). First, recall the product rule of differentiation: \\[F(x) = g(x)f(x)\\quad ; \\quad F^\\prime(x) =f^\\prime(x)g(x) + f(x)g^\\prime(x)\\] With that we can find the necessary derivative. \\[\\frac{\\delta R}{\\delta t_r} = - \\frac{1}{(t_t+t_r)^2} g(t_r) + \\frac{1}{t_t+t_r}g^\\prime(t_r)= \\frac{(t_t+t_r)g^\\prime(t_r) - g(t)}{(t_t+t_r)^2}\\] When we solve \\(\\delta R / \\delta t_r = 0\\), we discover that \\[g^\\prime(t_r)=\\frac{g(t_r)}{t_t + t_r}\\] Now we see that \\[R =\\frac{g(t_r)}{t_t + t_r}= g^\\prime(t_r)\\] which tells us…that in order to maximize the long-term average rate, we should stay in a patch until the instanteous rate, \\(g^\\prime(t_r)\\) drops to the long term average rate, \\(R\\). Figure 2.5: Energy gain vs. time: The origin is when the forager enters the patch; to the left is time spent traveling from one patch to the next, and to the right is time spent in the patch. The graph represents two different habitats, one in which the patches are easy to get to (habitat 1), and another where it takes more time to get from patch to patch (habitat 2). In all cases, the patches are identical, having the same gain function. The curved line is the gain function, the net energy gain as a function of time spent in the patch. The slope of that curve is the derivative of the gain function. Its slope at any single time point is the instantaneous rate of gain. The two straight lines are the expected gains averaged over time for each habitat as a whole. Lambda is the rate at which a forager randomly encounters patches - because it is a Poisson process, the mean or expected time is 1/lambda. The forager should leave the patch when the instantaneous rate of gain in the patch equals the long term average rate of gain for the habitat as a whole. The simple patch model predicts that when average travel time is greater, foragers will stay longer in a patch. Similarly, the model predicts that when patch quality is lower, foragers stay longer in each patch. Use Fig. 2.5 to construct explanations for these predictions. Just a starting point The simple prey and patch models have been extended a great deal to help understand a broad range of foraging situations (Sih 2011). Simultaneous, rather than sequential, encounters can lead to different predictions. In these cases, energy alone, \\(e_i\\), rather than profitability, \\(e_i/h_i\\), may determine prey selection that maximizes the long term mean average rate. Travel time and encounter rates interact with this to explain contrasting situations. Central place foragers play by slightly different rules (Stephens and Krebs 1986). Central place foragers are located in a single location, and remain there. For instance, a parent bird (or dinosaur) finds patches and returns repeatedly to the nest, bringing one or multiple prey items. With parent birds, their fitness depends on offspring viability, and so selection tends to optimize in a manner similar to an organism foraging for themselves. These cases have been built upon patch models, where the question is how to exploit patches that exist at different distances from the nest. Another example of a central place forager is a spider that acts as a ambush or sit-and-wait predator who remains stationary until a prey item gets close enough to attack. One approach to the spider problem is to consider the distance to the prey as a handling cost and search costs are negligible. These simple foraging models provide the starting points for a field of inquiry spanning many decades. The interplay between these models, the natural history of species, and experiments have led to greater appreciation of why organisms behave as they do, and the consequences for their evolution and the food webs and ecosystems in which they reside. 2.3 A simulation of a prey model Next, we embark on a simulation of the simple prey model. We will start with these assumptions: two prey types, \\(i = {1,2}\\) ranked effective energy contents, \\(e_1 &gt; e_2\\) equal handling times, \\(h_1=h_2=1\\) equal relative abundances, \\(r_1=r_2=0.5\\) encounter rates determined by an overall prey encounter rate, \\(\\lambda\\), and the relative abundances where \\(\\lambda_i = \\lambda r_i\\). equal probability of attack if prey is encountered, \\(p_1=p_2=1\\). search cost is constant, \\(c_s=0.01\\) In addition to these properties, our simulation needs several bookkeeping parameters and variables in order to track the forager energy content. It will need to run for a finite amount of time; we’ll control that with the total search time, Total. Remember that encounter rates are means but that actual encounters are random or stochastic. As a result, our forager may go through lean periods in which their net energy intake is negative. We need to keep track of total elapsed time, and for each cycle, the search time, search cost, handling time, and energy gain. optimal.forager &lt;- function( e = c(2, 1), # energy content of the prey types h = c(.5, .5), # handling times r = c(.5, .5), # relative abundance of prey types: sum(r) = 1 lambda = 0.4, # overal encounter rate, for all prey combined p = c(1,1), # prob. of attack if encountered cs = 0.4, # cost of searching per unit time Total = 10 # limit to foraging time ) { ############### ### begin foraging ec &lt;- NULL # an object to tally gains and costs. cycle &lt;- 0 # the cycle count (= search, choose and maybe attack and eat) ct &lt;- 0 # start time of the cyclesan object to tally cycle times. elapsed.time &lt;- 0 # total time spent foraging while( elapsed.time &lt; Total ) { # count which search cycle we&#39;re on (cycle &lt;- cycle + 1) # a random amount of search time, t.s, until it finds something. (lambda.r &lt;- lambda * r) (ts &lt;- rexp(2, rate=lambda.r)) if(ts[1] &lt; ts[2]) i &lt;- 1 else i &lt;- 2 i # cost of searching for that time (cost.s &lt;- ts[i] * cs) # choose to attack the encountered item with probability p (gain &lt;- if(p[i] &gt; runif(1)){e[i]} else {0}) # observed handling time if(gain &gt; 0 ){ h.obs &lt;- h[i] h.obs } else { h.obs &lt;- 0 } h.obs (cycle.time &lt;- ts[i] + h.obs ) ct &lt;- c(ct, cycle.time) (elapsed.time &lt;- elapsed.time + cycle.time) (ec &lt;- c(ec, gain - cost.s)) } df &lt;- data.frame(net.e = ec, cycle.start = cumsum(ct[1:cycle])) params &lt;- list(e=e, h=h, r=r, lambda=lambda, p=p, cs=cs, Total=Total) out &lt;- list(N = cycle, G = sum(ec), Tt = sum(ct), series = df, params = params) return(out) } Here we let the forager forage for 60 minutes and then examine the structure of the output object. myOut &lt;- optimal.forager(Total=60) str(myOut) ## List of 5 ## $ N : num 18 ## $ G : num 3.91 ## $ Tt : num 66.7 ## $ series:&#39;data.frame&#39;: 18 obs. of 2 variables: ## ..$ net.e : num [1:18] 0.84 1.218 0.38 1.593 0.163 ... ## ..$ cycle.start: num [1:18] 0 0.899 3.354 7.903 9.421 ... ## $ params:List of 7 ## ..$ e : num [1:2] 2 1 ## ..$ h : num [1:2] 0.5 0.5 ## ..$ r : num [1:2] 0.5 0.5 ## ..$ lambda: num 0.4 ## ..$ p : num [1:2] 1 1 ## ..$ cs : num 0.4 ## ..$ Total : num 60 N is the number of foraging cycles G is net energy gain Tt is total elapsed time series is a dataframe with two variables: net.e is energy gain minus search costs for each cycle, and cycle.start is the elapsed time at which each cycle starts params is a list that includes all the parameters we used in this run Now let’s graph something, because graphs are fun. ggplot(myOut$series, aes(x=cycle.start, y=cumsum(net.e))) + geom_line() Figure 2.6: The cumulative energy capital of a forager goes down while searching and handling resource items, but increases each time the prey is assimilated. Use this simulation to help solidify in your own mind predictions of the simple prey model. How should we do that? What is the prediction we are interested in? Prediction: Include type 2 if \\[\\frac{e_2}{h_2} &gt; \\frac{\\lambda_1 e_1 }{\\tag{2.2}1} (#eq:prediction)\\] Figure 2.7: The right hand side of our prediction To get a sense of what our prediction (2.2) means, we should graph the righthand quantity as a function of one relevant variable, such as energy content of type 1, or the encounter rate (Fig. 2.7). The parameters that determined these curves are: unlist( myOut$params ) ## e1 e2 h1 h2 r1 r2 lambda p1 p2 cs Total ## 2.0 1.0 0.5 0.5 0.5 0.5 0.4 1.0 1.0 0.4 60.0 2.3.1 Lab exercise Do these parameter values suggest that our forager should or should not include prey type 1 in her diet? Create parameter combinations for which the forager (i) should and (ii) should not include prey type 2. Use the simulation optimal.forager() to confirm your predictions. "]
]
