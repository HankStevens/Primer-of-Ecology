[
["index.html", "Primer of Ecology with R Preface", " Primer of Ecology with R Hank Stevens 2020-09-08 Preface In spite of the presumptuous title, my goals for this book are modest. I wrote it as the manual I wish I had in graduate school, and a primer for our graduate course in Population and Community Ecology at Miami University.1 To install the latest version of the primer R package, install it directly from GitHub. To do this, install the devtools package, and then use this code: devtools::install_github(\"HankStevens/primer\") Miami University is located in the Miami River valley in Oxford, Ohio, USA; the region is home to the Myaamia tribe that dwelled here prior to European occupation.↩︎ "],
["theory.html", "1 Theory in Ecology 1.1 Examples of theories 1.2 An example: Metabolic Theory of Ecology 1.3 Power law scaling implies constant relative differences", " 1 Theory in Ecology In this chapter, we introduce a perspective on ecological theory, and provide an example of an efficient theory, metabolic scaling. Scientific theory is a body of knowledge that provides an organized and mechanistic view of how the world works (Scheiner 2010). Theories concerning gravity, general relativity, and evolution by natural selection provide structured ways of connecting observations, patterns, and processes that provide insight into why the world is the way it is. This stands in stark contrast to the colloquial use of theory that implies a lack of knowledge, as when someone says “oh, that’s just a theory”, referring to a guess without much evidence. Scientific theory is a set of explanations whose validity has been tested repeatedly by experiments and new data. 1.1 Examples of theories Ecology has lots of theories, of all different types. Below I discuss some which may be prevalent, important, useful, or some combination. 1.1.1 Hierarchy theory An early and persistent organizing theory in ecology is based on hierarchy theory (O’Neill et al. 1986; Rose et al. 2017, and references therein). It posits that ecological systems are structured hierachically, such that each entity comprises subunits. For instance, an entity such as a population of big bluestem grass (Andropogon gerardii) is part of a larger ecology community of many species. The population of big bluestem comprises subpopulations separated in space, a subpopulation comprises separate individuals, that each individual comprises multiple ramets and a set of organ systems and tissues, which comprise different cell types. This theory posits that each entity gives rise to emergent properties to the hierarchical level above it, and influences processes within each smaller sub-entity in the hierachical level below it. As a disciplinary organizing principle, this approach structures nearly all of the ecology curriculum. Hierarchy theory gets more complicated when the levels of a hierarchy start to include fundamentally different types of entities. The big bluestem hierarchy above included only biotic components–a individual is part of a population which is part of a community of individuals of multiple species, and is made up of organ systems and tissues. Ecology, however, includes both the biotic and the abiotic parts of environments. An ecosystem includes a community of species, but also the nutrients, water, light, and other abiotic components, along with the spatial arrangement of all of these things. Different hierarchies are useful for different questions. An individual organism can play very different roles in different hierarchies. Consider and individual bunch grass. To understand how a population evolves, we need to count individuals within a population, because evolutionary fitness is tracked by the number of independent reproductive units. In contrast, to understand competitive interactions, it may be much more important to weigh the biomass of groups of individuals in a population, because biomass is more closely related of resource uptake. 1.1.2 A general theory of ecology Good scientific theories exist within a hierarchy of disciplinary knowledge (Scheiner and Willig 2011). They explain phenomena within a domain of knowledge which is organized around principles and assumptions. Scheiner and Willig posit a theory of biology that explains phenomena relating to the “diversity and complexity of living systems”. One of the ten principles on which this theory depends is that “the cell is the fundamental unit of life”. Subsumed within their theory of biology is the theory of cells whose domain is “cells and the causes of their structure, function, and variation.” This theory in turn is based on principles and has theories to organize our understanding of cells and what cells do. Models are specific and explicit manifestations of more general theories. In this book, we focus on popular mathematical models that are specific manifestions of theories of ecology. Scheiner and Willig (2011) propose a theory of ecology, some of which we cover in this book. Here is part of this theory: The General Theory of Ecology Domain: The spatial and temporal pattern of the distribution and abundance of organisms, including causes and consequences. Principles: Organisms are distributed in space and time in a heterogeneous manner. Organisms interact with their abiotic and biotic environments. Variation in the characteristics of organisms results in heterogeneity of ecological patterns and processes. The distributions of organisms and their interactions depend on contingencies. Environmental conditions as perceived by organisms are heterogeneous in space and time. Resources as perceived by organisms are finite and heterogeneous in space and time. Birth and death rates are a consequence of interactions with the abiotic and biotic environment. The ecological properties of species are the result of evolution. These principles constitute what we know is true about ecological systems. Some of these principles provide the focus for a single chapter while other principles apply broadly to many chapters in this book. Here is my own perspective on a general theory of ecology: Domain: The house of life2: its constituent entities, causes, and consequences. Principles: Entities3 are open systems with inputs and outputs. Entities have internal complexity. Entities include self-replicating components (living elements). Entities interact via inputs, outputs, and behavior. Rates of change, including inputs and outputs, are influenced directly by physical factors: space, temperature, and concentration. You will see elements of these principles throughout this book as well. 1.1.3 Efficient theory Marquet et al. (2014) argue that the best theories are those which are efficient. Such theories tend to be based on first principles, which are observations and laws that are fundamental assumptions in a scientific domain. In biology, such principles can include the laws of thermodynamics, and mathematical properties such as the central limit theorem. Theories built upon first principles are thus well-grounded in reality as we understand it and lead logically to refinements. Marquet and his colleagues also claim that efficient theory is expressed in mathematics. Mathematics is a universal language that is unamibiguous. It forces us to be as clear as possible about what we mean when we state a theory.4 Last, efficient theories are those that make a large number of predictions using only a small number of free parameters.5 Examples of efficient theories we cover in this book include metabolic scaling, exponential growth, density dependence, and ecological neutral theory. Marquet et al. and Scheiner and Willig emphasize slightly different features of the definition of “theory”. Scheiner and Willig emphasize relatively broad ideas that are well-supported by experiments and repeated observation. Marquet and colleagues tend to mean something fairly specific and narrow, typically something that can be expressed mathematically. Scheiner and Willig might refer to such theory as constitutive theory or even simply a model. Next, I describe the Metabolic Theory of Ecology. This theory is based on first principles, and its central tenets are expressed mathematically. It’s core equation has a very small number of free parameters (fitted constants) and makes a very large number of testable predictions. Parts of this theory are supported by a very large number of observations. It fits everyone’s definition of theory. 1.2 An example: Metabolic Theory of Ecology Metabolic rate is central to how rapidly individuals forage for, consume and use resources, reproduce and die. The metabolic theory of ecology (Brown et al. 2004) is a well-supported body of knowledge about the underlying mechanisms, and the resulting profound and wide-ranging consequences for populations and ecosystems. Body size and temperature are fundamental properties of organisms and the environment. The study of how body shape and body processes scale with body size is allometry. Because body size affects metabolic rate, body size indirectly helps determine population growth rates and how species interact with each other. Temperature affects how molecules vigorously molecules vibrate and move, and so increasing temperature tends to speed up chemical reactions. As metabolism is really just a complex network of biochemical reactions, temperature influences metabolic rate. The core of this theory is expressed in a simple mathematical equation that describes how body size and temperature govern metabolic rate. 1.2.1 Body-size dependence There is a profoundly simple and general rule describing the effect of interspecific variation in body size on metabolism.6 This biological law is referred to as the Kleiber law (Kleiber 1932), or quarter power scaling (Brown et al. 2004). When we compare the basal (i.e. resting) metabolic rates of different species, across a wide range of body sizes spanning many orders of magnitude, we find that whole-organism resting metabolic rate increases with organism mass raised to the three-quarter power, or, \\[ B = aM^{z} \\quad;\\quad z = 3/4 \\] In this equation, \\(B\\) is basal, or resting, metabolic rate, \\(M\\) is body mass, \\(a\\) is a proportionality constant, and \\(z\\) is the power law scaling coefficient. The proportionality constant \\(a\\) varies depending on the type of organism such as arthropods, fish, or mammals. Plants scale in the same manner (Niklas and Enquist 2001), although size or mass is a little trickier to measure. The scaling coefficient, \\(z\\), is the seemingly magical constant that many have argued does not vary substantially among different types of organisms. Ecologists typically describe metabolism-mass relations and other power law behavior using logarithmic scales. When we do that, power law relations become linear. Using our rules for exponents and logarithms, metabolic scaling becomes \\[ \\log B = \\log a + z\\log M\\] so that \\(\\log B\\) increases linearly with \\(\\log M\\) with a slope of \\(3/4\\). Our brains can process and compare linear relations much more easily than curvilinear ones. Here we plot the curvilinear relation in R using curve() in the graphics package of R that is included in the base installation as one of the core packages. The function curve() can plot any curve that be expressed as a function of x. Below, we draw a curve of a dotted 1:1 line for comparison, and then add the power function \\(x^{3/4}\\). Figure 1.1: Metabolic rate increases predictably with species body sizes. ## using curve, let your variable be &#39;x&#39;. curve(1*x, from = .01, to=100, ylab = &quot;Metabolic rate (B)&quot;, xlab=&quot;Body mass (M)&quot;, lty=3) curve(x^(3/4), from = .01, to = 100, add=TRUE) To help us grasp the implications of this, let’s consider mass-specific metabolic rates. “Mass-specific” means on a per-gram basis.7 Mass-specific metabolic rate is basal metabolic rate of an individual divided by its mass, or \\(B/M\\). The mass-specific metabolic rate allows us to compare directly, for example, the metabolic rate of a cell in a shrew vs. a cell in an elephant. Which cell is burning fuel faster? We can estimate this from the above metabolic scaling principle and the using rules exponents \\[ \\frac{B}{M} = a \\frac{M^z}{M^1} = a M^{z-1} = aM^{-1/4}\\] From this, we now have the rule that mass-specific metabolic rate declines with organisms mass raised to the negative one quater power eq1 = function(M, a){a*M^-0.25} # create the function, F(M) ggplot(data=data.frame(x=c(0.1, 100)), aes(x=x) ) + stat_function(fun=eq1, geom=&quot;line&quot;, args=list(a=1)) + xlab(&quot;Mass (M)&quot;) + ylab(&quot;Mass-specific metabolic rate (B/M)&quot;) Figure 1.2: Mass-specific metabolic rate declines predictably with species body sizes. Over the years, there has been heated debate about (i) the precise value of the scaling coefficient \\(z\\), and (ii) the underlying mechanism. Early arguments suggested that \\(z \\approx 2/3\\) because the rate heat dissipation scales with the amount surface area. Why \\(2/3\\)? Let’s envision the volume of an organism having three linear dimensions, so the volume scales to the cube of linear dimensions, while the surface area scales to the square of these linear dimensions,8 \\[V \\propto L^3\\] \\[A \\propto L^2\\] The early explanation was that metabolic rate, \\(B\\), scales linearly with area, \\[B \\propto A^1 \\propto L^2\\]. With substitution we get, \\[L^2 \\propto V^z \\propto (L^3)^z\\] implying that the exponents \\(2 = 3z\\) or \\(z=2/3\\), so we get, \\[B=V^{2/3}\\], and, for the most part, mass scales linearly with volume for mammals or any other such group. This early theory was because it started with first principles (heat dissipation and geometry) and resulted in the prediction of a single parameter. It could then be used to make predictions about how metabolic rate scales with body mass. Metabolic rate governs a huge amount of biology and ecology, including resource consumption rates, lifespan, and maximum population growth rates. Therefore, this theory and this model could be powerful tools for understanding the world and making testable predictions. The above model is good because it could be tested. That is what has been done, and scientists found that there was a consistent mismatch between observations and the theory. Investigators showed that the value of the exponent appeared closer to 3/4 raher than 2/3. In the 1990s, a group including Jim Brown and Geoffrey West (West, Brown, and Enquist 1997) proposed an underlying mechanism that explained why it should be 3/4. They assumed that organisms must distribute resources from a single source through a branching, fractal-like, space-filling network to all parts of the body, the size of the smallest branch ( a capillary) was the same for organisms of all sizes. the energy required to distribute the resources must be minimized, that less energy-efficient designs would be lost through natural selection. The prediction that resulted from these assumptions was that the exponent would be 3/4. This theory and model begin with different first principles and makes a different prediction. Soon Jayanth Banavar and his colleagues offered an alternative (Banavar, Maritan, and Rinaldo 1999; Banavar et al. 2002), arguing that the assumption of the fractal-like network was not correct, and in any event, was not necessary and did not apply to all organisms. They proposed different theory with less restrictive assumptions and found nonetheless that the exponent was also predicted to be 3/4. At the base of all these arguments is the geometry of the resource distribution system. All organisms take in limiting resources and have to distribute those resources to each part of each cell in the body. The key point is that the larger the organism, the greater the portion of the resources are in transit at any instant in time. This leads to an increasingly inefficient system, in which the metabolism of larger organisms has to run more slowly per unit resource: Larger organisms can process more resources per unit time (\\(B=aM^{3/4}\\)), but do so less and less efficiently (\\(\\frac{B}{M}=aM^{-1/4}\\)) due to resources in transport. Banavar, Brown and others eventually collaborated to address quarter power scaling in animals in particular which led to additional novel predictions (Banavar et al. 2010). This theory remains a fertile and active area of research (Glazier 2018). The interested reader should be careful to distinguish between patterns observed across many species of very different sizes, versus patterns observed in a single species with individuals of different sizes versus other types of patterns. Subtly different patterns may be driven be very different mechanisms. 1.2.2 Temperature dependence In addition to body size, temperature plays the other key role in regulating metabolic rate. The Arrhenius equation connects the macroscopic property of temperature to the kinetic energy of molecules and the rates they govern. Metabolic rate is proportional to these rate determining processes, \\[B = a e^{\\frac{-E_a}{kT}}\\] where \\(a\\) is just a constant, \\(e\\) is the exponential, \\(E_a\\) is the average activation energy of rate-limiting enzymes (units, eV), \\(k\\) is Boltzmann’s constant (units eV\\(\\,\\)K\\(^{-1}\\)), and \\(T\\) (units deg K). Bolztmann’s constant (\\(\\backsim 8.6 \\times 10^-5\\)\\(\\,\\)eV\\(\\,\\)K\\(^{-1}\\)) converts the macroscopic property of temperature to kinetic energy of molecules. Individual biochemical reactions combine to determine basal metabolic rate, so Gillooly (2000) have taken this as a foundation for the metabolic theory of ecology (Brown et al. 2004). In 2000, they suggested that the average activation energy is approximately \\(E_a = 0.23\\,\\)eV . Subsequent work has described this as “temperature sensitivity”, where larger numbers imply that organisms respond more strongly to temperature variation. The Arrhenius equation is a little more complicated that a simple power law, but not too much. Over the range of biologically relevant temperatures, it is dominated by a largely exponential increase in metabolic rate with increasing temperature (Fig @(fig:arrh)). # with base R # base R: curve(10^4*exp(-0.23/(8.5 * 10^-5 *x)), 276, 316), ylab=&quot;B&quot;, xlab=&#39;T&#39;) # or ggplot2 # the function, with default parameter values eq.t &lt;- function(t,a=10^4,E=0.23,k=8.6 * 10^-5){a*exp(-E/(k*t))} # the data used in our function temps &lt;- data.frame(t=276:316) ggplot(data=temps, aes(x=t)) + # set the basic properties of the plot stat_function(fun=eq.t, geom=&quot;line&quot;) + # set the function to plot xlab(&quot;Temperature (K)&quot;) + ylab(&quot;Metabolic rate (B)&quot;) Figure 1.3: The effect of body temperature on ectothermic metabolic rates can be approximated with the Arrhenius function, \\(B = a e^{-E_a/(kT)}\\). Here \\(a = 10^4\\), and \\(E_a = 0.23\\). It is similar in shape to a power law with z &gt; 1, over the range of biologically relevant temperatures. # add labels When we linearize the relation between metabolic rate and temperature, we get \\[ \\begin{aligned} B &amp;= a e^{\\frac{-E_a}{kT}}\\\\ \\log(B) &amp;= \\log{a} - E_a\\frac{1}{kT}\\\\ \\end{aligned} \\] where the dependent variable is \\(1/(kT)\\), \\(-E_a\\) is the slope, and \\(\\log a\\) is the intercept. Thus, the negative slope of this relation describes theoretical prediction for the effect of temperature on metabolic rate. So, there you have it. The metabolic theory ecology is the algebraic product of body size- and temperature-dependence: \\[B = a M^{3/4} e^{\\frac{-E_a}{kT}}\\] This theory makes quantitative predictions regarding all kinds of ecology phenomena (Brown et al. 2004), including home range size population growth population size resource uptake predation and other species interactions, and ecosystem cycling. Note that these relations are based on first principles of geometry and thermodynamics, and that they depend on only a small number of parameters (\\(a\\), \\(-E_a\\), and perhaps \\(z=3/4\\)), and makes a tremendous number of predictions. Therefore, Marquet et al. (2014) propose that this is “good” theory, and very efficient. 1.3 Power law scaling implies constant relative differences In power law scaling, relative change is constant. That is, a proportional change in one variable results in a proportional change in the other. For instance, when we compare a smaller species to a larger species with \\(100 \\times\\) the body mass, we can expect to see metabolic rate increase by \\(31.6 \\times\\), regardless of the mass of the smaller species. For now, we will verify this numerically for some limited cases. # define body mass and metabolic rate m &lt;- c(.01, 1, 100, 10000) b &lt;- m^.75 Now we will divide each mass \\(i\\) by the next smallest mass \\(i-1\\). We do that using a vector by dividing each mass except the first one, by each mass except the last one. # round(x, digits=0) rounds number to zero decimal places round( m[-1]/m[-length(m)], digits = 0) round( b[-1]/b[-length(b)], digits = 1) When we do these divisions, we see the constant relative change (1.1). Table 1.1: As we increase mass by a constant multiplier (10x), power law scaling results in a constant proportional change in basal metabolc rate. Small Med. Big Huge Mass 0.01 1.00 100.00 10000.00 Basal.metabolic.rate 0.03 1.00 31.62 1000.00 Relative.change.m NA 100.00 100.00 100.00 relative.change.b NA 31.62 31.62 31.62 We can verify this generally using algebra, not just in the particular case above. We will show that if mass increases by a constant multiplier, metabolic rate will also, regardless of the particular masses involved. Let mass \\(m_2\\) be greater than mass \\(m_1\\) by a factor of \\(c\\), so that \\(m_2 = c m_1\\), and \\[\\frac{m_2}{m_1} = c\\]. We would like to show that the ratio of the metabolic rates \\(b_2 / b_1\\) is also a constant. Since \\(m_2 = cm_1\\), we can say that \\[b_1 = a m_1^{3/4}\\] \\[b_2 = a (cm_1)^{3/4} = ac^{3/4}m_1^{3/4}\\] \\[\\frac{b_2}{b_1} = \\frac{ac^{3/4}m_1^{3/4}}{am_1^{3/4}}\\] When we reduce this fraction, we a left with \\[\\frac{b_2}{b_1} = c^{3/4}\\] This shows that with power law scaling, increasing \\(x\\) by a constant multipier (or proportion), \\(y\\) increases by the same proportion raised to that power. Let’s represent this graphically in a couple of ways, reusing data we made up previously in this chapter. First, we just change the axes themselves, so that the units of the scales are multiples of 10 (often in scientific notation). # using base R par(mar=c(5,4,0,0), mgp=c(1.5,.4,0) )# set figure margins in &quot;lines&quot; curve(x^(3/4), from = .01, to = 100, log=&quot;xy&quot;, ylab=&quot;Basal metabolic rate&quot;, xlab=&quot;Mass&quot;) text(10, 80^.7, expression(M^0.75)) Figure 1.4: changing the scales of the axes to linearize power law relations. Note scales are logarithmic, using the original linear values. References "],
["oft.html", "2 Optimal Foraging 2.1 A prey model 2.2 The patch model 2.3 A simulation of a prey model", " 2 Optimal Foraging Figure 2.1: Optimal foraging theory (OFT) generates testable quantitative predictions that allow a less ambiguous description and explanation for observed patterns and processes. Here, a simplistic model of Great Tit (Parus major) foraging that includes only gross energy intake underestimates the time spent in patches (dashed). In contrast, a model that includes energetic costs of traveling and searching matches predictions far better (solid). From Cowie (1977). It can be useful to think of natural selection as an optimizing process: phenotypes diversify, winners replicate and losers don’t, and the phenotypes of winners tend to get passed on to the replicants. Therefore, we often assume, as did Dr. Pangloss, that the species that exist now are the best of all possible species, that is, they are of optimal design. And like Dr. Pangloss, we would be woefully mistaken if we stopped there. Nonetheless, optimization, that is, the tendency toward an optimum, helps us generate testable hypotheses and we consider some of these below. Optimal Foraging Theory (OFT) helps us consider what organisms would do if they foraged optimally. All organisms–plants, fungi, archaea, and even animals–forage, and they are all subject to natural selection. Therefore, their phenotypes work pretty well, but probably not optimally and definitely not optimally for all times and places. Nonetheless, OFT is an efficient theory about the behavior of an organism, in the absence of other complications. Therefore, it allows us to study the relative importance of those “other complications.” Foraging is a key link between the individual, and communities and ecosystems (Beckerman, Petchey, and Morin 2010). All organisms interact with their environment via consumption, and the choices they make influence population dynamics, species interactions, nutrient cycling, and even the physical structures of terrestrial and aquatic habitats. The text and logic of this chapter rely heavily on Stephens and Krebs (1986) and Ellner (2009). In Scheiner and Willig’s edited volume on The Theory of Ecology, Andy Sih (Sih 2011) proposes that the following propositions form the basis of foraging theory: Foraging patterns maximize fitness or a correlate of fitness. Foraging patterns depend on the range of options available to the forager and on how each available option affects fitness or a correlate of fitness. Foraging behaviour balances conflicting demands–tradeoffs are important in shaping foraging behaviour. These properties are the outcome of natural selection operating on foraging behavior. Our understanding of foraging itself considers these three features (Stephens and Krebs 1986): currency (what is being optimized), constraints (features of behaviour that limit optimality), and the resulting decision rules. Currency is that quantity that is optimized by the forager. This currency is assumed to be a quantity that limits fitness, such as energy or a particular consumable resource. We measure it as a rate, for instance, as the energy gained per unit time (E/T) or the uptake of a critically limiting resource per unit time (R/T). Constraints are limitations that we assume about organisms. These might include distances between resource patches, the time and costs associated with extracting a resource from a substrate or subduing prey. They also include constraints imposed by other species including competitors and predators. Constraints can get complicated quickly; however, simple quantitative theory makes predictions against which we can evaluate more complicated assumptions. Decision rules are what we ascribed to a forager’s choices. A decision rule concern the probability of attacking prey if encountered, or when to leave one resource patch in order to search for another. An additional way to think about all this is where, when, and what. A great deal of effort has focused on understanding patch use: where foragers should explore for resources, and when they should give up and go in search of another patch (Charnov 1976). These are patch use models, and are based on economic models and the marginal value theorem. Another avenue of inquiry concerns what animals should eat. For instance, should they go after big prey that may be hard to catch and difficult to subdue, or just snack on what is easy? These are prey models or diet models, and attempt to explain why organisms consume what they do. A note on “prey”. All organisms forage for resources. Plants extend branches toward the light, and proliferate leaves and roots into resource rich patches, and rhizomes grow longer faster through resource-poor soils. Bumblebees search for and learn where to find nectar-rich flowers, and wolves hunt in packs to take down large ungulates. Some bacterivorous nanoflagellates intercept particles selectively depending on the perceived nutritional value of particles (Boenigk et al. 2002). So, depending on the forager, its “prey” may be \\(\\mathrm{NO}_{3}^-\\) ions, nectar, moose, or bacteria. Therefore, we will refer to these resources variously as prey, prey items, resources, and resource items. Some of these ideas are best handled with patch-based models (Charnov 1976) where a “resource patch” is a more intuitive and useful unit. A note on “handle”. All organisms pays costs to consume resources. In OFT, “handle” typically means expending energy an time to attack and subdue prey (predators), proliferate into resource rich areas (plants), exude extra cellular enzymes (fungi); ingest the item(s), and then resume searching. 2.1 A prey model …in which a forager asks, “should I eat this?”9 Let’s start where this field started, with a prey-centered model (MacArthur and Pianka 1966; Emlen 1966). The goal is to optimize the currency. 2.1.1 Our intuition Figure 2.2: The amount of energy, E (y-axis), that is lost and gained by a foraging ant–it may decline slowly over time (x-axis) while searching, and decline quickly while handling a food item. Our ant gains energy when it consumes an item. Below: Our ant. She expends energy while searching for food. Upon encountering a food item, she may choose to ‘handle’ it (encounters 1 and 3) and gain energy, or not handle it (encounter 2) and save the added cost of handling it. It seems reasonable that if a forager encounters food, it should eat it. However, if handling it costs more than the forager gets back in energy, then it isn’t worth it. We might think of this as the ratio as profitability, \\[\\frac{e_i}{h_i}\\] where \\(e_i\\) is the energy in an item of type \\(i\\), and \\(h_i\\) is the cost of handling said item. If \\(e_i/h_i&lt;1\\), then it doesn’t make sense to select the item. Further, handling an item means that the forager is not looking for a better food item. This suggests that even if \\(e_i/h_i&gt;1\\), a forager may not want to handle it if it is likely to soon encounter food items of higher energy content. On top of this, the act of searching may expose a forager to a risk of running into competing foragers, or even being eaten by a bigger forager. Clearly, a forager faces tradeoffs as it searches and when it encounters resources. 2.1.2 Mathematical support One of the reasons to represent ideas mathematically is that we make concrete assumptions, and then the math can tell us what the predictions are. That is what we will do here. Let’s assume that natural selection tends to maximize the currency as Gain per unit Time, \\(G/T\\). Our model will use these parameters and variables: \\(i =\\) index for prey type \\(S =\\) total time spent searching (units = seconds, \\(s\\)). \\(\\lambda_i =\\) rate of encounter with prey of type \\(i\\) (units = # encountered/s = \\(\\#/s\\); note this can also be #/area × area/s, if we like)10 \\(p_i =\\) probability that a forager attacks prey if encountered (units are number handled per number encountered, or #/#; this is a dimensionless parameter) \\(h_i =\\) handling time for an item of type \\(i\\), (units = s/#). \\(T =\\) total elapsed time (units = s) From these definitions we can calculate other important quantities. Total number of items encountered of type \\(i\\) is \\[S \\lambda_i\\] The units are \\(s\\, \\#\\,s^{-1} = \\#\\). Total number of type \\(i\\) items handled is the proportion, \\(p_i\\), of those encountered that the foragers chooses to go after, or \\[S\\lambda_i p_i\\] The units are \\(\\#\\). Total time spent handling all items of type \\(i\\) is \\[H=S\\lambda_i p_i h_i\\] The units are \\(s\\).11 Total elapsed time is time spent searching plus time spent handling, which is \\[T=S + \\sum_i^n S\\lambda_i h_i p_i\\] where we use the summation to add together the total handling times for each prey or resource type \\(i = \\{1,\\,2, \\ldots ,\\,n\\}\\). Let \\(e_i =\\) net energetic gain from catching and consuming a single type-i prey item (units = Joules, J). This includes the gross energy of the item minus handling costs plus energy not lost by searching during that time. \\(c =\\) energy cost per unit of time while searching (units = J). Total energy gain from eating all the items is the number of items of each type \\(i\\) handled times the net amount of energy per item of type \\(i\\), \\(e_i\\), \\[\\sum_{i=1}^n S\\lambda_i p_i e_i\\] where units are \\(\\# (\\mathrm{J}/ \\#) = \\mathrm{J}\\). Therefore, rate of energy intake (J/\\(s\\)) while handling and eating is \\[\\mathrm{intake} = \\frac{\\sum_{i=1}^n S\\lambda_i p_i e_i}{S + \\sum_{i=1}^n S\\lambda_i h_i p_i}\\] If we then subtract the cost of searching, we arrive at the quantity we want to maximize, \\[G/T=\\frac{\\sum_{i=1}^n \\lambda_i p_i e_i}{1 + \\sum_{i=1}^n \\lambda_i p_i h_i}-c\\] A major question in OFT is whether a forager should include a particular prey type. Say we rank the prey types, \\(i=\\{1,2,...,m,...,n\\}\\), in terms of energy content, where type \\(i=1\\) has the most energy per item, \\(i=m\\) is intermediate, and type \\(i=n\\) has the least. Which items should a forager include in her diet? Should it be only the most energy-dense, or should it include the second as well, or should it be all of them? Part of the answer rests on the ratio of energy gain versus handling costs, or profitability, \\(e_i/h_i\\). If we maximized \\(G/T\\) with respect to \\(p_j\\), we would be able to determine whether to include item \\(j\\). Doing so leads to several predictions. Prediction 1 A less energy-dense item should be added if its net energy content is greater than the realized energy gain from all the other items, \\[\\begin{equation} \\frac{e_{m+1}}{h_{m+1}} &gt; \\frac{\\sum_{i=1}^m \\lambda_i e_i}{1 + \\sum_{i=1}^{m} \\lambda_i h_i} \\tag{2.1} \\end{equation}\\] where the diet already includes items 1-\\(m\\), and the realized energy content of the diet takes into account average encounter rates of each item type. It means that a foraging will always select a particular type (\\(p_j =1\\)), or never select it (\\(p_j=0\\)); this is known as the “zero-one rule”. Prediction 2 Foragers will rank prey types by their profitability, \\(e/h\\). Prediction 3 When encounter rates increase (as with increasing abundances), selectivity increases. Note that encounter rates are in the right hand side, so as they increase, so will that fraction on the right. That will make it harder for the above inequality to be true, and a forager will be pickier. If you don’t believe it, try this simplified version (Fig. 2.3). G.T = function(lambda, h=1, e=1){lambda*e/(1+lambda*h)} # create the function you want myData &lt;- data.frame( lambda=c(0, 10) ) # data you need ggplot(data=myData, aes(x=lambda)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=G.T, geom=&quot;line&quot;) + ylab(bquote(over(lambda*e, 1 + lambda*h))) + xlab(bquote(lambda)) # add labels Figure 2.3: Selectivity increases with average encounter rates. Prediction 4 Inclusion of type \\(m+1\\) in the diet does not depend on its encounter rate. Thus, a particular type should be included if the instantaneous net gain of that type is greater than the realized long term average net gain of all the more profitable types. Note that encounter rate appears on the right hand side, but not the left. So how does this model fair in the real world? Well, the zero-one rule doesn’t work at all; it turns out that for a variety of reasons, foragers do not completely ignore low-profit prey. However, there is great support for the other predictions (above) (Stephens and Krebs 1986). Most importantly, in all cases, the theory has provided a clear framework to generate testable predictions from unambiguous assumptions, and that is what we want from efficient theory. The model itself helped guide research, and inclusion of greater complexity has led to deeper understanding of behavior and its consequences for species interactions. 2.2 The patch model …in which omniscient rationale agents roam free. Here the forager asks, “how long should I stay here?” In the simple prey model, a forager searches for and then encounters prey one at a time, makes a decision to consume or not, and then resumes searching. In a simple patch model, a forager searches for and encounters patches one at a time, first consumes resources and then makes a decision to leave or not. Perhaps the single most important prediction of the simple patch model is that a forager should leave a patch when its current rate of energy gain drops down to the average or expected rate of energy gain for the habitat at large. In what follows, we rely on Charnov (1976), who applies the marginal-value theorem to explain optimal behavior. Here, as in economics, “marginal value” refers to a rate - the slope of a function. In calculus, this is a derivative. Here, it is the derivative (i.e. slope) of the relation between energy gain and time. Let’s assume the simplest of all patch models: one patch type, all patches are the same, and they are distributed randomly in the habitat. Assume also that a forager uses time to travel between patches (travel time, \\(t_t\\)) and time searching within a patch (residence time, \\(t_r\\)). A forager encounters patches at random, with a rate of \\(\\lambda\\), and as such, would have a mean time to next encounter of \\(1/\\lambda\\). The patch is characterisized by its gain function \\(g(t_r)\\) (Fig. 2.4) which is the expected12 cumulative net energy gained, given time \\(t_r\\) spent in the patch. The gain function is a cumulative total net amount. We can imagine different types of gain functions. Figure 2.4: Net energy gain as a function of patch residence time may take different forms. Net energy gain increases through time but slows (decelerates) as a greater fraction of the resources in the patch are consumed. The top line (solid) assumes that there are diminishing returns as a patch is depleted, but the forager continues to find resources in excess of metabolic losses. The lower line (dashed) represents the net energy gain that could arise as a patch is depleted more fully and the costs continue unabated. Try this: Draw a gain function where the prey remain well hidden at first, but the forager becomes increasingly able to find more and more prey. Draw a gain function where there is no cost to foraging, and where the forager eventually depletes all the prey. In one graph, draw two gain functions for a resource rich patch and for a resource poor patch. So, our currency is long-term average energy intake, \\(R\\), and we want to maximize this. The decision our forager needs to make is how long to stay in a patch. The forager’s constraints share some similarity with the prey model (Stephens and Krebs 1986). between-patch travel time and within-patch hunting time are distinct, and … … independent of each other, a forager encounters patches sequentially and randomly, in a given patch, net expected energy gain is a function of time spent in the patch… …that is zero when \\(t=0\\), and …increases with time, but then decelerates the forager is omniscient - it knows everything about available patches and does not learn anything new as it forages (because it already knows everything). The forager must decide how long to stay in the patch to maximize \\(R\\). Let \\[R=\\frac{g(t_r)}{t_t + t_r}\\] where \\(t_t + t_r\\) is the total time from leaving one patch, traveling to the next patch, foraging in the second patch, and then leaving the second patch. Think of this as benefit (\\(g(t)\\)) per unit time. This fraction is the slope of the straight line in Fig. 2.5. Intuitively, we can imagine that the long term average rate of energy gain \\(R\\) is unimodal (hump-shaped) in the following scenario (Fig. 2.4). Upon encountering a patch the forager has no resources and thus \\(R\\) is actually negative due to the costs of traveling to the new patch. As \\(t_r\\) passes and and the forager gains energy (\\(g(t_r)\\) increases), \\(R\\) will increase and become positive. An assumption of the theory (and reality) is that the gain function, \\(g(t_r)\\), decelerates–the rate of energy intake declines as the patch is depleted. With increasing time in the patch and lower rate of energy intake, \\(R\\) starts to decline. When \\(t_r\\) is too short, \\(R\\) is not yet maximizes. When \\(t_r\\) is too long, \\(R\\) begins to decline. Because \\(R\\) is hump-shaped, we can use calculus to find its maximum. This will occur when its slope is zero, and the slope of a function, \\(F\\), is its derivative, \\(F^\\prime\\). If we asssume that travel time is constant, then we can take the partial derivative of \\(R\\) with respect to just the residence time, \\(t_r\\), \\(\\delta R / \\delta t_r\\). First, recall the product rule of differentiation: \\[F(x) = g(x)f(x)\\quad ; \\quad F^\\prime(x) =f^\\prime(x)g(x) + f(x)g^\\prime(x)\\] With that we can find the necessary derivative. \\[\\frac{\\delta R}{\\delta t_r} = - \\frac{1}{(t_t+t_r)^2} g(t_r) + \\frac{1}{t_t+t_r}g^\\prime(t_r)= g^\\prime(t_r) - \\frac{g(t_r)}{t_t+t_r}=0\\] Because this derivative equals zero when the slope of the gain function (\\(g^\\prime(t_r)\\)) equals \\(R\\), that tells use that \\(R\\) is maximized at that point. Therefore, it predicts that in order to maximize the long-term average rate, we should stay in a patch until the instantaneous rate, \\(g^\\prime(t_r)\\) drops to the long term average rate, \\(R\\) (Fig. 2.5). Figure 2.5: Energy gain vs. time: The origin is when the forager enters the patch; to the left is time spent traveling from one patch to the next, and to the right is time spent in the patch. The graph represents two different habitats, one in which the patches are easy to get to (habitat 1), and another where it takes more time to get from patch to patch (habitat 2). In all cases, the patches are identical, having the same gain function. The curved line is the gain function, the net energy gain as a function of time spent in the patch. The slope of that curve is the derivative of the gain function. Its slope at any single time point is the instantaneous rate of gain. The two straight lines are the expected gains averaged over time for each habitat as a whole. Lambda is the rate at which a forager randomly encounters patches - because it is a Poisson process, the mean or expected time is 1/lambda. The forager should leave the patch when the instantaneous rate of gain in the patch equals the long term average rate of gain for the habitat as a whole. The simple patch model predicts that when average travel time is greater, foragers will stay longer in a patch. Similarly, the model predicts that when patch quality is lower, foragers stay longer in each patch. Use Fig. 2.5 to construct explanations for these predictions. Just a starting point The simple prey and patch models have been extended a great deal to help understand a broad range of foraging situations (Sih 2011). Simultaneous, rather than sequential, encounters can lead to different predictions. In these cases, energy alone, \\(e_i\\), rather than profitability, \\(e_i/h_i\\), may determine prey selection that maximizes the long term mean average rate. Travel time and encounter rates interact with this to explain contrasting situations. Central place foragers play by slightly different rules (Stephens and Krebs 1986). Central place foragers are located in a single location, and remain there. For instance, a parent bird (or dinosaur) finds patches and returns repeatedly to the nest, bringing one or multiple prey items. With parent birds, their fitness depends on offspring viability, and so selection tends to optimize in a manner similar to an organism foraging for themselves. These cases have been built upon patch models, where the question is how to exploit patches that exist at different distances from the nest. Another example of a central place forager is a spider that acts as a ambush or sit-and-wait predator who remains stationary until a prey item gets close enough to attack. One approach to the spider problem is to consider the distance to the prey as a handling cost and search costs are negligible. These simple foraging models provide the starting points for a field of inquiry spanning many decades. The interplay between these models, the natural history of species, and experiments have led to greater appreciation of why organisms behave as they do, and the consequences for their evolution and the food webs and ecosystems in which they reside. 2.3 A simulation of a prey model Next, we embark on a simulation of the simple prey model. We will start with these assumptions: two prey types, \\(i = {1,2}\\) ranked effective energy contents, \\(e_1 &gt; e_2\\) equal handling times, \\(h_1=h_2=1\\) equal relative abundances, \\(r_1=r_2=0.5\\) encounter rates determined by an overall prey encounter rate, \\(\\lambda\\), and the relative abundances where \\(\\lambda_i = \\lambda r_i\\). equal probability of attack if prey is encountered, \\(p_1=p_2=1\\). search cost is constant, \\(c_s=0.01\\) In addition to these properties, our simulation needs several bookkeeping parameters and variables in order to track the forager energy content. It will need to run for a finite amount of time; we’ll control that with the total search time, Total. Remember that encounter rates are means but that actual encounters are random or stochastic. As a result, our forager may go through lean periods in which their net energy intake is negative. We need to keep track of total elapsed time, and for each cycle, the search time, search cost, handling time, and energy gain. optimal.forager &lt;- function( e = c(2, 1), # energy content of the prey types h = c(.5, .5), # handling times r = c(.5, .5), # relative abundance of prey types: sum(r) = 1 lambda = 0.4, # overal encounter rate, for all prey combined p = c(1,1), # prob. of attack if encountered cs = 0.4, # cost of searching per unit time Total = 10 # limit to foraging time ) { ############### ### begin foraging ec &lt;- NULL # an object to tally gains and costs. cycle &lt;- 0 # the cycle count (= search, choose and maybe attack and eat) ct &lt;- 0 # start time of the cyclesan object to tally cycle times. elapsed.time &lt;- 0 # total time spent foraging while( elapsed.time &lt; Total ) { # count which search cycle we&#39;re on (cycle &lt;- cycle + 1) # a random amount of search time, t.s, until it finds something. (lambda.r &lt;- lambda * r) (ts &lt;- rexp(2, rate=lambda.r)) if(ts[1] &lt; ts[2]) i &lt;- 1 else i &lt;- 2 i # cost of searching for that time (cost.s &lt;- ts[i] * cs) # choose to attack the encountered item with probability p (gain &lt;- if(p[i] &gt; runif(1)){e[i]} else {0}) # observed handling time if(gain &gt; 0 ){ h.obs &lt;- h[i] h.obs } else { h.obs &lt;- 0 } h.obs (cycle.time &lt;- ts[i] + h.obs ) ct &lt;- c(ct, cycle.time) (elapsed.time &lt;- elapsed.time + cycle.time) (ec &lt;- c(ec, gain - cost.s)) } df &lt;- data.frame(net.e = ec, cycle.start = cumsum(ct[1:cycle])) params &lt;- list(e=e, h=h, r=r, lambda=lambda, p=p, cs=cs, Total=Total) out &lt;- list(N = cycle, G = sum(ec), Tt = sum(ct), series = df, params = params) return(out) } Here we let the forager forage for 60 minutes and then examine the structure of the output object. myOut &lt;- optimal.forager(Total=60) str(myOut) ## List of 5 ## $ N : num 13 ## $ G : num -1.03 ## $ Tt : num 61.6 ## $ series:&#39;data.frame&#39;: 13 obs. of 2 variables: ## ..$ net.e : num [1:13] 0.681 -3.58 1.464 0.998 -3.079 ... ## ..$ cycle.start: num [1:13] 0 1.3 13.2 15.1 15.6 ... ## $ params:List of 7 ## ..$ e : num [1:2] 2 1 ## ..$ h : num [1:2] 0.5 0.5 ## ..$ r : num [1:2] 0.5 0.5 ## ..$ lambda: num 0.4 ## ..$ p : num [1:2] 1 1 ## ..$ cs : num 0.4 ## ..$ Total : num 60 N is the number of foraging cycles G is net energy gain Tt is total elapsed time series is a dataframe with two variables: net.e is energy gain minus search costs for each cycle, and cycle.start is the elapsed time at which each cycle starts params is a list that includes all the parameters we used in this run Now let’s graph something, because graphs are fun. ggplot(myOut$series, aes(x=cycle.start, y=cumsum(net.e))) + geom_line() Figure 2.6: The cumulative energy capital of a forager goes down while searching and handling resource items, but increases each time the prey is assimilated. Use this simulation to help solidify in your own mind predictions of the simple prey model. How should we do that? What is the prediction we are interested in? Prediction: Include type 2 if \\[\\begin{equation} \\frac{e_2}{h_2} &gt; \\frac{\\lambda_1 e_1 }{1 + \\lambda_1 h_1} \\tag{2.2} \\end{equation}\\] Figure 2.7: The right hand side of our prediction To get a sense of what our prediction (2.2) means, we should graph the righthand quantity as a function of one relevant variable, such as energy content of type 1, or the encounter rate (Fig. 2.7). The parameters that determined these curves are: unlist( myOut$params ) ## e1 e2 h1 h2 r1 r2 lambda p1 p2 cs Total ## 2.0 1.0 0.5 0.5 0.5 0.5 0.4 1.0 1.0 0.4 60.0 2.3.1 Lab exercise Do these parameter values suggest that our forager should or should not include prey type 1 in her diet? Create parameter combinations for which the forager (i) should and (ii) should not include prey type 2. Use the simulation optimal.forager() to confirm your predictions. References "],
["expo.html", "3 Simple density-independent growth 3.1 Discrete growth rates of fruit flies in my kitchen 3.2 Fruit flies with continuous overlapping generations 3.3 Properties of geometric and exponential growth 3.4 Modeling with Data: Simulated Dynamics", " 3 Simple density-independent growth Figure 3.1: Song Sparrow (Melospiza melodia) counts in Darrtown, OH, USA. From Sauer, J. R., J.E. Hines, and J. Fallon. 2005. The North American Breeding Bird Survey, Results and Analysis 1966–2004. Version 2005.2. USGS Patuxent Wildlife Research Center, Laurel, MD. Figure 3.2: Song Sparrow (Melospiza melodia) annual changes in population size as a function of population size. Between 1966 and 1971, Song Sparrow (Melospiza melodia) abundance in Darrtown, OH, USA, seemed to increase very quickly, perhaps unimpeded by any particular factor (Fig. @ref{fig:Melospiza1}, @ref{fig:Melospiza2}). In an effort to manage this population, we may want to predict its future population size. We may also want to describe its growth rate and population size in terms of mechanisms that could influence its growth rate. We may want to compare its growth and relevant mechanisms to those of other Song Sparrow populations or to other passerine populations. To do this, we start with the simplest of all population phenomena, geometric and exponential growth. Geometric and exponential growth are examples of density-independent growth. This captures the fundamental process of reproduction (e.g., making seeds or babies) results in a geometric series.13 For instance, one cell divides to make two, those two cells each divide to make four, and so on, where reproduction for each cell results in two cells, regardless of how many other cells are in the population—that is what we mean by density-independent. This myopically observed event of reproduction, whether one cell into two, or one plant producing many seeds, is the genesis of a geometric series. Therefore, most models of populations include this fundamental process of geometric increase. Second, populations can grow in a density-independent fashion when resources are plentiful. It behooves us to start with this simple model because most, more complex population models include this process. Hastings (2011) proposes that we can approach single species poulation growth from either a microscopic or macroscopic point of view. The microscopic approach begins with two propositions. The first is that if we know the location, timing, and traits of all individuals, we can predict perfectly population dynamics; the second is that we can never predict dynamics perfectly because births and deaths are fundamentally random and can be described only with probabilities.14 With this microscopic approach, we would seek a very detailed description of individuals and build a complex model to understand the consequences of the characteristics of all these interacting individuals, including the growth of the population. In this chapter, I choose to start with Hastings’ macroscopic approach. These propositions appear simpler. A population grows exponentially in the absence of other forces. There are forces that can prevent a population from growing exponentially. These are the consequences of the following assumptions. all individuals in a population are identical. there is no migration in or out of the population. the number of offspring per individual (or the per capita birth and death rates) are constant through time, and (ii) independent of the number of individuals in the population. Deviations from these assumptions lead to all of the most interesting parts of single species population dynamics (Hastings 2011). The only deviation we play with in this chapter concerns assumption c; we model stochastic variation in population growth rate to investigate extinction risk. It is also worth mentioning that, although propositions 1 and 2 follow from assumptions a-d, they are not strictly necessary (Hastings 2011). For instance, individuals need not be identical, and we deal with a big exception in the next chapter where we introduce structured population growth. Also, migration is admissable, provided immigration = emigration and it does not alter growth rates. Nonetheless, other deviations from a. and b. can have very important consequences for single species population dynamics. Here we define Density-independence in a real population as a lack of a statistical relation between the density of a population, and its per capita growth rate15. The power to detect a significant relation between any two continuous variables depends on those factors which govern statistical power, such as the number of observations, the range of the predictor variable, and the strength of the underlying relation. Therefore, our conclusion, that a particular population exhibits density-independent growth, may be trivial if our sample size is small, with few generations sampled, or if we sampled the population over a very narrow range of densities. Nonetheless, it behooves us to come back to this definition if, or when, we get caught up in the biology of a particular organism. In this chapter, we’ll introduce density-independent population projection, growth, and per capita growth, for populations with synchronous reproduction (discrete models), and continuous reproduction (continuous models). 3.1 Discrete growth rates of fruit flies in my kitchen Summertime, and the living is easy. Fruit flies in my kitchen, and their number’s quite high. Flies love my ripe fruit, and my red wine. They drown in the wine–I am not sure if that is good or bad. For now, we’ll treat fruit flies as if they grow in discrete generations. This is very common for populatilons that live in seasonal habitats - their reproduction is timed to the season, and they breed altogether in one bout.16 I count the number of flies every week, and I find these numbers: t &lt;- c(0, 1, 2, 3) N &lt;- c(2, 4, 8, 16) qplot(x=t, y=N, geom=c(&quot;line&quot;, &quot;point&quot;) ) There are several ways we can describe fruit fly population growth. We begin by thinking about the proximate causes of change to population size per unit time: births, immigration, death and emigration (Fig. 3.3). Those are the only options, and we state it thus: \\[\\frac{\\Delta N}{\\Delta t} = \\frac{B + I - D - E}{\\Delta t}\\] that is, the pop growthe rate17 is determined by the numbers of births, deaths, and migrants per unit time. Over the past month, I suspect the fruit flies are increasing primarily through reproduction in my kitchen. Clearly, at some point in the past, a fly or two (or three) must have immigrated into my kitchen, either as adults or as eggs or larvae in fruit I brought home (\\(I&gt;0\\)). For now, I will assume fruit fly population dynamics in my kitchen are governed by only births and deaths (\\(I=E=0\\)), so, we have \\[ \\frac{N_{t+1} - N_t}{(t+1) - t}=\\frac{\\Delta N}{\\Delta t}=\\frac{B+D}{\\Delta t}\\] In this equation, \\(t\\) has a particular time unit, one week, so \\(t+1\\) is one additional week. We refer to a population like this as closed, because it is closed to migration in or out. Figure 3.3: The number of fruit flies in my kitchen depends on immigration and emigration, and births and deaths. In the text, we assume that immigration and emigration are zero. All rates are individuals per unit time. I would like to represent births and deaths as proportions of existing adults. that is, as \\[B = bN;\\quad D=dN\\] This reflects the biological realities that adults produce offspring, and everyone has some chance of dying. The parameter \\(b\\) could be any positive real number, \\(b \\ge 0\\). This model of births reflects the geometric property of reproduction: over a specified time interval \\(\\Delta t\\), an average parent makes \\(b\\) babies. Parameter \\(d\\) is any real number between zero and one, \\(0 \\le d \\le 1\\). Both \\(b\\) and \\(d\\) have units of individuals per individual per unit time. They depend on that unit of time. What if offspring die before the next census? Fig. 3.3 helps us think about these things. Simplifying, we’ll assume births occur first, and then death comes to offspring and adults. Let’s define a few terms. \\(N_0\\), \\(N_1\\) - the number of flies at the start and after the first time interval. \\(N^\\prime\\), \\(N^{\\prime\\prime}\\) - distinct values of \\(N\\), just after births. \\(\\Delta N\\) - the change in \\(N\\) from one point in time to another. \\(t\\) is time, so \\(\\Delta t\\) is the time interval over which \\(N\\) may change. Let’s match these numbers to what is going on in my kitchen. For my first census count, \\(t=0\\), I counted the adults and label that number \\(N_0\\). These adults lay eggs which hatch, larvae and pupae develop, and become adults, giving us a population of \\(N^\\prime = N_0 + bN\\) Some of the eggs fail to hatch, and some of the larvae die before maturing. Many of the adults die as well. If we assume the eggs, larvae, and adults all die at the same rate, then by the end of one generation we have \\(N_1 = dN^\\prime = d(N_0 + bN)\\). Substituting and multiplying we get \\[ N_1 = N_0 + bN_0 - d\\left(N_0 + bN_0\\right)\\] We see that by the next time point, \\(t=1\\), the number of fruit flies should be equal to the number we started with, \\(N_0\\), plus the number of new individuals, \\(bN_0\\), minus the number of original adults that die, \\(dN_0\\), and minus the number of new individuals that die, \\(dbN_0\\). We can pull all of these parameters together, \\[ N_1 = N_0 + bN_0 - dN_0 - dbN_0 \\] \\[ N_1 - N_0 = N_0 \\left(b - d - db\\right) = N_0 + r_dN_0 \\tag{3.1}\\] where \\(r_d = b - d - db\\). The growth rate of the population is \\(\\Delta N / \\Delta t\\), or, at \\(t=0\\), is \\[\\frac{\\Delta N}{\\Delta t} = \\frac{N_1 - N_0}{t_1-t_0} = \\frac{(N_0 + r_dN_0) - N_0}{t_1-t_0} = r_d N_0 \\] If we generalize, we drop the zero, to get \\(r_dN\\). The per capita population growth rate is \\(r_dN/N =r_d\\)). If our time step were something other than 1, we would also divide by \\(\\Delta t\\). With the simple census data above, we can estimate \\(r_d\\) for the first time step. \\[N_1 = N_0 + r_dN_0= 2 + r_d (2) \\implies r_d=1\\] If we know that \\(r_d\\) is constant over time, we can infer a general rule to project the population forward in time an arbitrary number of time steps. We will let \\(\\lambda = 1+r_d\\). \\[N_1 = N_0 + r_dN_0 = N_0(1 + r_d) = N_0\\lambda\\] \\[N_2 = N_1\\lambda= (N_0 \\lambda)\\lambda\\] \\[N_3 = N_2\\lambda= (N_0 \\lambda)\\lambda\\lambda\\] or simply, \\[N_t = N_0\\lambda^t\\] To summarize our model of discrete population growth, we have the following statements: Projection: \\[N_t = N_0\\lambda^t\\] Population growth rate: \\[\\frac{\\Delta N}{\\Delta t} = r_dN; \\quad \\mathrm{where~} \\lambda=1+r_d\\] Per capita opulation growth rate: \\[\\frac{\\Delta N}{N\\Delta t} = r_d\\] At last, we see how this is a model of density-independent growth: per capita growth rate does not include \\(N\\). 3.2 Fruit flies with continuous overlapping generations In the reality that is my kitchen, individual fruit flies are having sex and reproducing on their own schedules. As a population, they breed continuously, so the cohorts re not synchronous. For populations like that, we need to describe instantaneous growth rates, where \\(\\Delta t\\) is no longer a fixed period of time, but is an instant, or infinity small. We return to our example above (Fig. 3.3), which we summarize in (3.1). Please take a look at that equation; here we make time explicit so that it appears in the equation. We begin by remembering that \\(b\\) and \\(d\\) have time units. Let \\(\\Delta t\\) be a small fraction of \\(t\\), so that the time step goes from \\(t\\) to \\(t + \\Delta t\\). As \\(\\Delta t \\rightarrow 0\\), \\(b\\) and \\(d\\) need to shrink as well, to \\(\\Delta t b\\) and \\(\\Delta t d\\). \\(dN/dt\\) is how we identify the differential equation that is the instantaneous rate of population growth, with lower case \\(d\\) symbolizing infinitesimally small change. We now have to solve for the limit of \\(\\Delta N /\\Delta t\\) as \\(\\Delta t\\) goes to zero. \\[\\frac{dN}{dt}=\\lim_{\\Delta t \\rightarrow 0} \\frac{N_{t+\\Delta t} - N_t}{\\Delta t} = \\lim_{\\Delta t \\rightarrow 0} \\frac{\\Delta t\\,bN_t - \\Delta t \\,dN_t - \\Delta t\\, d (\\Delta t\\, b)N_t}{\\Delta t} \\] If we divide through by \\(\\Delta t\\) and then let \\(\\Delta t \\rightarrow 0\\), we get \\[\\frac{dN}{dt}=\\lim_{\\Delta t \\rightarrow 0} bN_t - dN_t - \\Delta t\\, d bN_t = bN_t - dN_t=rN\\] To arrive at the projection equation for a continuously growing population, we integrate \\(rN\\) with respect to time. Integration is the cumulative summing of \\(y\\) across a range of \\(x\\). It even uses an exagerated “S” to indicate summation, \\(\\int\\). Here we integrate population growth across time. We start by rearranging \\[\\frac{dN}{dt} = rN \\Rightarrow \\frac{dN}{N} = r dt\\] Now we integrate \\(N\\) and \\(r\\) with respect to their start and end points: \\(N\\) from \\(N_0\\) to \\(N_t\\), and, correspondingly, \\(r\\) from \\(t=0\\) to \\(t=t\\), \\[\\int_{N_0}^{N_t} \\frac{1}{N}dN = \\int_{0}^{t}rdt\\] \\[\\ln(N_t) - \\ln(N_0) = rt - r\\,0\\] \\[\\ln(N_t) = \\ln(N_0) + rt\\] We now exponentiate (\\(e^x\\)) both sides to arrive at our projection equation. \\[N_t = e^{\\ln(N_0) + rt} = N_0 e^{rt}\\] To summarize our model of continuous population growth, we have the following statements. Projection: \\[N_t = N_0 e^{rt}\\] Population growth rate: \\[\\frac{dN}{dt} = rN\\] Per capita population growth rate: \\[\\frac{dN}{Ndt} = r\\] Once again, we see why we refer to exponential growth as density-independent: the per capita growth rate does not depend on \\(N\\). 3.3 Properties of geometric and exponential growth Compare the projection equations for geometric and exponential growth. We find that \\[\\lambda = e^{r} \\quad ; \\quad \\ln \\lambda = r\\] This gives us a few useful rules of thumb. No change: \\(r = 0\\quad;\\quad\\lambda =1\\) Growing population: \\(r &gt; 0 \\quad;\\quad \\lambda &gt; 1\\) Shrinking population: \\(r &lt; 0 \\quad;\\quad \\lambda &lt; 1\\) # Let r take on three values r &lt;- c( -1, 0, 1) # Convert to lambda exp(r) ## [1] 0.3678794 1.0000000 2.7182818 Time scaling This is a useful property if we ever want to change time units in a discrete model. We must first \\(\\lambda\\) to \\(r\\), change units in \\(r\\) and convert back to \\(\\lambda\\). For instance, if we find that the annual finite rate of increase for a population of crickets is \\(\\lambda = 1.2\\), we cannot convert that to a monthly rate of \\(1.2/12 = 0.1\\). Instead we convert to \\(r\\) and back to \\(\\lambda\\). lambda &lt;- 1.2 # Convert lambda to r r &lt;- log(lambda); r ## [1] 0.1823216 # Scale r from year to month r2 &lt;- r/12; r2 ## [1] 0.01519346 # Convert back to lambda (per month) lambda2 &lt;- exp(r2); lambda2 ## [1] 1.015309 This is very, very different than \\(\\lambda/12\\). Doubling time Sometimes we gain a more intuitive grasp of an idea when we convert to a different form of the same relationship. Exponential growth is one of those ideas that can be hard to grasp. A more intuitive way to compare or express exponential grwoth rate is through doubling time, the time required for the population to double in size. For instance, a per capita growth rate of \\(r = 0.14\\,\\mathrm{inds}\\cdot \\mathrm{ind}^{-1} \\mathrm{y}^{-1}\\) means that the population will double in less than 5 years. We determine this by letting \\(N_t = 2N_0\\). \\[2N_0 = N_0 e^{rt}\\] \\[\\ln 2 = rt\\] \\[t =\\frac{\\ln 2}{r}\\] # let r be a sequence from r &lt;- c(0.01, 0.05, 0.1, 0.5) #doubling time will be log(2)/r ## [1] 69.314718 13.862944 6.931472 1.386294 # and a picture par(mgp=c(1.2, .2, 0), mar=c(2, 2, 1, 1), tcl=-.2) curve( log(2)/x, xlab=&quot;r&quot;, ylab=&quot;Doubling time&quot;) Figure 3.4: Doubling time is inversely related to the intrinsic rate of increase, r. 3.3.1 Average growth rate In any real data set, such as from a real population of fruit flies or Song Sparrows, \\(N_{t+1}/N_t\\) will vary from year to year. How do we calculate an average growth rate for a fluctuating population? Let’s consider the case where a population increases and then decreases. For each year, we will calculate the annual rate of increase \\(R = N_{t+1}/N_t\\), and take the arithmetic average of those rates to see if it makes sense. N &lt;- c(20, 30, 15, 15) R &lt;- N[2:4]/N[1:3]; R ## [1] 1.5 0.5 1.0 The arithmetic average of those rates is \\((1.5 + 0.5 + 1.0)/3=1.0\\). If \\(R=1.0\\), then, on average, the population should stay the same, but it decreased. Why is that? Let us do the annual time steps explicitly to see what is going on. \\[N_3 = (N_0 R_0) R_1 R_2\\] # Remember that we call the first time t=0 and N0, but # when coding, these values are the first in a series, so # N0 is N[1] # Now we do the annual changes which should equal N3 N[1]*R[1]*R[2]*R[3] ## [1] 15 From this calculation, we see that when we start with \\(N_0=20\\) and do the annaul steps, we wind up with a smaller population, even though the arithmetic average is \\(R_{\\mathrm{ave}} = 1\\). How do we calculate an average of numbers that we multiply together? We want a number \\(\\bar{R}\\) such that \\[\\bar{R}^t = R_1R_2\\ldots R_t\\] To find that, we simply solve for \\(\\bar{R}\\) \\[(\\bar{R}^t)^{1/t} =\\bar{R} = \\left(R_1R_2\\ldots R_t\\right)^{1/t}\\] We take the \\(t\\)-th root of the product of all the \\(R\\). This is called the geometric average. Another way of writing this would be to use the product symbol, as in \\[\\bar{R} = \\left(\\prod_{i=1}^t R_i\\right)^{1/t}\\] R ## [1] 1.5 0.5 1.0 #arithmetic average mean(R) ## [1] 1 # geometric average t &lt;- length(R); t ## [1] 3 prod(R)^(1/t) ## [1] 0.9085603 # shows the population should decline Another way to do the same thing is to take the arithmethic mean of the log-growth rates, and back-transform, exp( mean( log(R) ) ) ## [1] 0.9085603 Now we see the effect of calculating the average growth rate correctly. This leads to a useful rule of thumb: random variation in growth rate suppresses population growth. Here we illustrate that. We start with a growing population. lambda &lt;- 1.01 # positive growth rate N0 &lt;- 100 # starting N t &lt;- 20 # 20 years Nt1 &lt;- N0*lambda^t; Nt1 ## [1] 122.019 Here \\(\\lambda &gt; 1\\), so the population grows. Now we do a simulation in which we let \\(\\lambda\\) have a mean of 1.01 but allow it to vary randomly. # create a vector to hold all N N &lt;- rep(0, t); N[1] &lt;- N0 # create t-1 random lambdas with a mean of 1.01 # ranging from 0.41 to 1.61 set.seed(3) # makes the radnom sequence repeatable random.lambda &lt;- runif(n=(t-1), min=0.41, max=1.61) # the geometric mean prod(random.lambda)^(1/length(random.lambda)) ## [1] 1.00105 # actual simulated projection for(i in 1:(t-1)) { N[i+1] &lt;- N[i] * random.lambda[i] } qplot(x=0:(t-1), N, geom=c(&quot;line&quot;, &quot;point&quot;), xlab=&quot;Time (y)&quot;) Figure 3.5: Random variation in growth rate alters the long term average growth rate. Sometimes the arithmetic average is close to the correct average, but it is never the correct approach. 3.4 Modeling with Data: Simulated Dynamics Science strives to make predictions about about the behavior of systems. Ecologists and conservation biologists frequently strive to predict the fate of populations. This is referred to as population viability analysis (PVA) and is a large field of endeavor that is vital to managing threatened populations. Here we put into practice ideas about population biology to make informed predictions about the fate of the Song Sparrow population in Darrtown, OH. We also illustrate simple computational methods for doing so. The preceding sections (the bulk of the chapter) emphasized understanding the deterministic underpinnings of simple forms of density independent growth: geometric and exponential growth. This section explores the stochastic simulation of density independent growth. Our simulation makes most of the same assumptions we made at the beginning of the chapter. In addition, we assume that the observed annual growth rates (\\(N_{t+1}/N_t\\)) are representative of future growth rates, and that the growth rate in one year is entirely independent of any other year. To make meaning full projections of future population size, we should quantify the uncertainty with our guess. Simulation is one way we can project populations and quantify the uncertainty. The way one often does that is to use the original data and sample it randomly to calculate model parameters. This way, the simulations are random, but based on our best available knowldge, i.e., the real data. The re-use of observed data occurs in many guises, and it is known often as bootstrapping or resampling. In a highly influential paper on miminmum population sizes in conservation, Shaffer (1981) identifies four different types of noise or stochasticity that are important in driving variability in populations. The first of these is demographic stochasticity. This is the random or more correctly stochastic nature of individual births and deaths. Due to this element of random chance, individuals may live or die, produce offspring or not. As a result, population size will fluctuation randomly. This is very important in small populations, and becomes increasingly unimportant in larger and larger populations. This is the same process that underlies genetic drift in small populations. Another source of variation Shaffer (1981) identifies is environmental stochasticity. This is temporal variation in birth or death rates that affects all individuals to a similar degree, due to variation in the population’s biotic or abiotic environment. The last sources of variation are genetic stochasticity and natural catastrophes. Perhaps the latter of these is the most difficult to deal with, because catastrophes are, by definition, enormously consequential and unpredictable. Given these sources of uncertainty, Shaffer (1981) defines minimum population size (MVP) thus, “A minimum viable population for any given species in any given habitat is the smallest isolated population having a 99% chance of remaining extant for 1000 y despite foreseeable effects of demographic, environmental and genetic stochasticity, and natural catastrophes.” In our simulations, we take one approach to simulating a population of Song Sparrows. The computational approaches includes a variety of tricks that you could use in a more serious approach to population projection and determining probabilities of extinction. In their supplemental documentation, Chaudhary and Oli (2019) provide an excellent list of criteria to evaluate your own or someone else’s approach to PVA. 3.4.1 Data-based approaches We could use the observed changes in population counts \\(R_t=N_{t+1}/N_t\\) as our data. We would then draw an \\(R_t\\) at random from among the many observed values, and project the population one year forward. We then repeat this into the future, say, for ten years. Each simulation of a ten year period will result in a different ten year trajectory because we draw \\(R_t\\) at random from among the observed \\(R_t\\). However, if we do many such simulations, we will have a distribution of outcomes that we can describe with simple statistics (e.g., median, mean, quantiles). A different approach would be to estimate the individual probabilities of births and deaths in the entire Darrtown population, and use those probabilities and birth rates to simulate the entire population into the future. In such an individual-based simulation, we would simulate the fates of individuals, keeping track of all individual births and deaths. There are myriad other approaches, but these give you a taste of what might be possible. In this section we focus on the first of these alternatives, in which we use observed \\(R_t\\) to simulate the dynamics of Song Sparrow counts. Do do so, in part, because we have those data, while we do not have any estimates of birth rates or death rates. Here we investigate Song Sparrow (Melospize melodia) dynamics using data from the annual U.S. Breeding Bird Survey (http://www.mbr-pwrc.usgs.gov/ bbs/). Below we will create and examine visually the data (annual \\(R\\)’s), simulate one projection, scale up to multiple simulations, simplify simulations and perform them 1000s of times, and analyze the output. 3.4.2 Creating and visualizing the data Let’s start by graphing the data18. Graphing the data is always a good idea — it is a principle of working with data. We first load the data from the primer R package, and look at the names of the data frame. We then choose to attach the data frame, because it makes the code easier to read.19 library(primer) data(sparrows) names(sparrows) ## [1] &quot;Year&quot; &quot;Count&quot; &quot;ObserverNumber&quot; attach(sparrows) Now we plot these counts through time (Fig. 3.6). ggplot(data=sparrows, aes(x=Year, y=Count)) + geom_line() + geom_point(pch=1) Figure 3.6: Observations of Song Sparrows in Darrtown, OH (http://www.mbr-pwrc.usgs.gov/bbs/). We see that Song Sparrow counts at this site (the DARRTOWN transect, OH, USA) fluctuated a fair bit between 1966 and 2003. They never were completely absent and never exceeded \\(\\sim 120\\) individuals. Next we calculate annual \\(R_t=N_{t+1}/N_t\\), that is, the observed growth rate for each year \\(t\\). # the use of [-1[ in the index tells R to exclude the first element. # length() is the length of a vector, so [-length(X)] means exclude the last obs.R &lt;- Count[-1]/Count[-length(Count)] Thus our data are the observed \\(R_t\\), not the counts per se. These \\(R\\) form the basis of everything else we do. Because they are so important, let’s plot these as well. Let’s also indicate \\(R=1\\) with a horizontal dotted line as a visual cue for zero population growth. Note that we exclude the last year because each \\(R_t\\) is associated with \\(N_t\\) rather than \\(N_{t+1}\\). qplot(x=Year[-length(Count)], y=obs.R, geom=&quot;point&quot;) + geom_hline(yintercept=1, lty=3) + labs(y=bquote(N[t+1]/N[t]), x=&quot;Year (t)&quot;) Figure 3.7: Annual growth rates (R=N[t+1]/N[t]) for Song Sparrows One thing that emerges in our graphic data display (Fig. 3.7) is we have an unusually high growth rate in the early 1990’s, with the rest of the data clustered around 0.5–1.5. We may want to remember that. 3.4.3 One simulation Our simulation will, determine the number of years we wish to simulate, create an empty vector, N, to hold our simulated \\(N\\), which is years + 1 long, draw a random sample of \\(R_t\\), one for each year (R), select a starting abundance \\(N_0\\) and put it in N[1]. multiply our first random \\(R\\), R[1], times N[1] to generate the next, N[2]. repeat step 5 for each year to simulate each N[t+1] from R[t] and N[t]. First, we decide how many years we want to simulate growth, and create an empty vector that will hold our data. years &lt;- 10 N &lt;-numeric(years+1) # rep(0,years+1) would do the same thing. Our vector of \\(N\\) has to be one longer than the number of \\(R\\) we use. This is because each \\(R\\) is sthe change from one year to the next and there will always be one more next than there is \\(R\\). Next we draw 10 \\(R\\) at random with replacement. This is just like having all 35 observed \\(R\\) written down on slips of paper and dropped into a paper bag. We then draw one slip of paper out of the bag, write the number down, and put the slip of paper back in the bag, and then repeat this 9 more times. This is resampling with replacement. In that case, we would be assuming that all of these \\(R_t\\) are important and will occur at some point, but we just don’t know when—they constitute the entire universe of possiblities. The R function sample will do this. [A random process occurs only in our imagination, or perhaps at the quantum level.20 A stochastic process is one which we treat operationally as random while acknowledging that there are complex underlying deterministic drivers. A pseudorandom process is a completely deterministic and hidden process used by computers and their programmers to generate numbers that cannot be distinguished from random; we can repeat a pseudorandom process by stipulating a key hidden starting point.] We can use set.seed() to make your pseudorandom process the same as mine, i.e., repeatable. set.seed(3) # Draw a sample of our observed R with replacement, &quot;years&quot; times. (rRs &lt;- sample(x=obs.R, size=years, replace = TRUE)) ## [1] 1.4489796 0.8125000 1.0714286 1.2857143 0.7727273 0.4805195 1.2857143 ## [8] 1.0500000 0.7204301 1.4489796 Now that we have these 10 \\(R\\), all we have to do is use them to generate the population sizes through time. For this, we need to use what programmers call a for-loop. In brief, a for-loop repeats a series of steps for a predetermined number of times. Let’s start our simulated N with the sparrow count we had in the last year. N[1] &lt;- Count[length(Count)] Now we are ready to use the for-loop to project the population. For each year \\(t\\), we multiply \\(N_t\\) by the randomly selected \\(R_t\\) to get \\(N_{t+1}\\) and put it into the \\(t +1\\) element of N. for( t in 1:years) { # starting with year = 1, and for each subsequent year, do... N[t+1] &lt;- N[t] * rRs[t] } Let’s graph the result. qplot(0:years, N, geom=c(&quot;point&quot;,&quot;line&quot;)) Figure 3.8: A single simulated population projection. It appears to work (Fig. 3.8). Let’s review what we have done. We had a bird count each year for 36 years. From this we calculated 35 \\(R\\) (for all years except the very last). decided how many years we wanted to project the population (10,y). * drew at random and with replacement the observed \\(R\\)—one \\(R\\) for each year we want to project forward. * we created an empty vector and put in an initial value (the last year’s real data). * performed each year’s calculation, and put it into the vector we made. So what does Fig. 3.8 represent? It represents one possible outcome of a trajectory, if we assume that \\(R\\) has an equal probability of being any of the observed \\(R_t\\). This particular trajectory is very unlikely, because it would require one particular sequence of randomly selected \\(R\\)s. However, it is no less likely than any other particular trajectory. As only one realization of a set of randomly selected \\(R\\), Fig. 3.8 tells us very little. What we need to do now is to replicate this process a very large number of times, and examine the distribution of outcomes, including moments of the distribution such as the mean, median, and confidence interval of eventual outcomes. 3.4.4 Multiple simulations Now we create a way to perform the above simulation several times. There are a couple tricks we use to do this. We still want to start small so we can figure out the steps as we go. Here is what we would do next. We start by creating a function that will do the steps we did above. We then do replicate independent simulations, using replicate(). Here we write a function to combine several steps. myForLoop &lt;- function(obs.R, years, initial.N) { # select all R at random rR &lt;- sample(obs.R, size=years, replace=TRUE) # create a vector to hold N N &lt;- numeric(years+1) # give it an initial population size N[1] &lt;- initial.N # Do the for-loop for( t in 1:years ) { # project the population one time step N[t+1] &lt;- N[t] * rR[t] } # return the vector of N N } # try it out with different hypothetical R myForLoop(obs.R=0:3, years=5, initial.N=43) ## [1] 43 129 0 0 0 0 Our function seems to work. Next we do ten such projection simulations, each for 50 time steps, using the sparrow data. # specify the number of simulations and for how long sims=10; years=50 set.seed(3) outmat &lt;- replicate(sims, expr=myForLoop(obs.R=obs.R, years=years, initial.N=43) ) Now let’s peek at the results (Fig. 3.9). It is fun to graph our output, but also helps us make sure we are not making a heinous mistake in our code. Note we use log scale to help us see the small populations. matplot(0:years, outmat, type=&quot;l&quot;, log=&quot;y&quot;) Figure 3.9: Using matplot() to plot a matrix vs. a single variable. Our simulated populations sometimes increase and sometimes decrease. # combine columns years, and our output junk &lt;- data.frame(years = 1:(years+1), outmat) names(junk) ## [1] &quot;years&quot; &quot;X1&quot; &quot;X2&quot; &quot;X3&quot; &quot;X4&quot; &quot;X5&quot; &quot;X6&quot; &quot;X7&quot; &quot;X8&quot; ## [10] &quot;X9&quot; &quot;X10&quot; # make sure to load &#39;tidyr&#39; if you did not already load it or tidyverse # library(tidyr) # Take the wide data frame with many columns and turn it into # a long data frame with one column to ID each simulation, and one to hold values. out.long &lt;- pivot_longer(junk, cols=X1:X10, names_to=&quot;Run&quot;, values_to=&quot;N&quot;) ggplot(data=out.long, aes(x=years, y=N, group=Run)) + geom_line() + scale_y_log10() Figure 3.10: Using ggplot() to plot one variable against vs. a single variable, organized by a grouping variable. Our simulated populations sometimes increase and sometimes decrease. # Or for colorful lines # ggplot(data=out.long, aes(x=years, y=N, linetype=Run, colour=Run)) + # geom_line(show.legend=FALSE) + scale_y_log10() What does it mean that the simulation has an approximately even distribution of final population sizes (Fig. )? If we plotted it on a linear scale, what would it look like?^[Plotting it on the log scale reveals that the relative change is independent of population size; this is true because the rate of change is geometric. If we plotted it on a linear scale, we would see that many trajectories result in small counts, and only a few get really big. That is, the median size is pretty small, but a few populations get huge.} Rerunning this simulation, with new \\(R\\) each time, will show different dynamics every time, and that is the point of simulations. Simulations are a way to make a few key assumptions, and then leave the rest to chance. In that sense it is a null model of population dynamics. 3.4.5 A distribution of possible futures Now we are in a position to make an informed prediction, given our assumptions. We will predict the range of possible outcomes and the most likely outcomes, given our set of assumptions. We will simulate the population for 50 years 10,000 times and describe the distribution of final populatin sizes. We use system.time to tell me how long it takes on my computer. sims=1e4; years=50 set.seed(3) ## system.time keeps track of how long processes take. system.time( outmat &lt;- replicate(sims, expr=myForLoop(obs.R=obs.R, years=years, initial.N=43) ) ) ## user system elapsed ## 0.133 0.009 0.142 This tells me how long it took to complete 10,000 simulations. We also check the dimensions of the output, and they make sense. dim(outmat) ## [1] 51 10000 We see that we have an object that is the size we think it should be. We shall assume that everything worked way we think it should. 3.4.6 Analyzing results We extract the last year of the simulations (last row), and summarize it with quartiles (0%, 25%, 50%, 75%, 100%, and also the mean). N.2053 &lt;- outmat[51,] summary(N.2053, digits=6) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 12.1 60.7 1306.3 297.7 2299420.0 hist(log10(N.2053)) Figure 3.11: Distribution of the 10000 final base-10 log population sizes. Note the approximately Normal distribution. The quantile() function allows us to find a form of empirical confidence interval, including, approximately, the central 90% of the observations.21 quantile(N.2053, prob=c(0.05, .95) ) ## 5% 95% ## 1.331579 2862.940808 These quantiles provide an estimate of the most likely range of possible populatin sizes, given our assumptions. 3.4.7 Inferring processes underlying growth rate The above approach relies only on the observed data. That means that the growth rates, while representative, can never be different than what was observed. A different approaach would be to assume that the growth rates can be different than observed, but drawn from the same underlying process that caused the observed rates. The observed rates are simply a visible manifestation of unseen processes. We might summarize these by asserting that the observed growth rates were samples from a continuous distribution distribution, whose prperties we can infer from the sample. For instance, it may be that these processes cause annual rates to follow a Normal, or perhaps log-normal distribution. We can fit a Normal distribution to the logarithms of our observed \\(R\\), and we see that it doesn’t do too bad a job (Fig. 3.12). mu &lt;- mean( log(obs.R) ) sigma &lt;- sd( log(obs.R) ) # a regular sequence for log-R lR &lt;- seq(-1, 1.1, by=0.01) # the probability densities for the log-R dR &lt;- dnorm(lR, m=mu, sd=sigma) # rescale the probability density to visible height to graph rdR &lt;- dR*10 hist(log(obs.R), breaks=10, ylab=&quot;Frequency&quot;) lines(lR, rdR) Figure 3.12: The logarithms of the observed R seem reasonably approximated by a Normal distribution whose mean and standard deviation are derived from the log-transformed data. The probability distribution has been rescaled to be visible on this graph. Now we will simulate populations just like before, but instead of random draws from the observed data, we do random draws from the inferred distribution. Our new function. myForLoop2 &lt;- function(mu, sigma, years, initial.N) { # select all R at random from lrR &lt;- rnorm(years, m=mu, sd=sigma) rR &lt;- exp(lrR) # create a vector to hold N N &lt;- numeric(years+1) # give it an initial population size N[1] &lt;- initial.N # Do the for-loop for( t in 1:years ) { # project the population one time step N[t+1] &lt;- N[t] * rR[t] } # return the vector of N N } Our new simulations. sims=1e4; years=50 set.seed(3) outmat2 &lt;- replicate(sims, expr=myForLoop2(mu=mu, sigma=sigma, years=years, initial.N=43) ) N2.2053 &lt;- outmat2[51,] quantile(N2.2053, prob=c(0.05, .95) ) ## 5% 95% ## 1.205509 3089.819907 quantile(N.2053, prob=c(0.05, .95) ) ## 5% 95% ## 1.331579 2862.940808 The results are very similar to those based on only the observed \\(R\\). If they were markedly different, we might ask whether our choice of distribution was appropriate. Our conclusions are based on a model of discrete density-independent population growth what assumptions are we making and are they valid? Are our unrealistic assumptions perhaps nonetheless a good approximation of reality? what would you like to add next to make the model a better approximation? 3.4.8 1/\\(f\\) environmental noise Perhaps we might explain some of the variation in annual growth rates to weather patterns in the breeding range (Darrtown, Ohio). If so, we might separate demographic effects vs. environmental effects. That would give us an even better model we could use for explanation and prediction. An important consideration in modeling more realistic time series the temporal autocorrelation that often appears in environmental data. Patterns of autocorrelation are often best characterized by “one over f-noise” (\\(1/f\\)), that is, random variation where the temporal autocorrelation follows a color spectrum. Uncorrelated noise is referred to as white noise because the correlations actually occur at all wavelengths. Red noise emphasized strong correlation at short wavelengths and low correlation at long wavelengths. As a result, red noise is more random at longer wavelengths but less random at short wavelengths . Environmental variables typically have a reddened color that we typically refer to as pink noise (Halley 1996). In this chapter, we have explored the meaning of density-independent population growth. It is a statistically demonstrable phenomenon, wherein the per captia growth rate exhibits no relation with population density. It is a useful starting point for conceptualizing population growth. We have derived discrete geometric and continuous exponential growth and seen how they are related. We have caculated doubling times. We have discussed the assumptions that different people might make regarding these growth models. Last, we have used simulation to explore prediction and inference in a density-independent context. References "],
["DID.html", "4 Density-independent Demography 4.1 A two stage matrix model 4.2 A brief primer on matrices 4.3 Decomposing A 4.4 A three stage model 4.5 Projection 4.6 Analyzing the transition matrix 4.7 Integral projection 4.8 R packges for demography 4.9 Exploring a real population", " 4 Density-independent Demography In the preceding chapter, we listed Hastings’ (Hastings 2011) key principles and assumptions of single species population growth. One of the key assumptions is that “all individuals in a population are identical.” In this chapter, we elucidate an important violation of that assumption, population structure. Figure 4.1: Demography of human populations of Mexico and Sweden. Based on 1990 data from US Census Bureau, Population Division, International Programs Center. Populations have structure. Consider the human populations of Mexico and Sweden in 1990. Mexico had a much larger fraction of their population in child bearing age classes or younger (Fig. 4.1). In addition, the age-specific fertility rate was higher in Mexico, especially for younger women (Fig. 4.1). How did this happen, and why did Mexico have so many young people? What were the consequences of this for their culture, their use of resources, their domestic and foreign policies, and their future population growth? How about Sweden? Demography is the study of populations with special attention to their structure (Lincoln, Boxshall, and Clark 1998). Originally, age-based human demography was the provenance of actuaries who helped governments keep track of the number citizens of different ages and thus, for instance, know how many would be available for conscription into the military.22 The reason we model the structure of populations is because various demographic rates vary markedly with these stages. Juveniles produce no offspring. Very few seeds survive an entire year, whereas some large adults survive very well. We use structure when that structure is associated with important differences in demographic rates: survival, fecundity, and growth. The structure to which we refer is simply the organization of populations by some character such as life history stage, age, or size. Sizes and ages are often reduced to categories such as we saw in human populations (e.g., 0–4.9,y, 5–9.9,y,…). Sizes may be based on any reliable and repeatable measure that relates to demographic rates and are similarly binned. Life history stages may include eggs, larvae, metamorphs, juveniles, and adults in amphibians, or seeds, rosettes, and reproductive stems in herbaceous plants. With a variable such as size, we don’t even need to use categories, but rather we can use size as a continuous variable; we address this briefly later in the chapter. Structured population models allow us to intertwine species-specific natural history and quantitative methods. This makes the approach especially appealing for the conservation biology of threatened and endangered species. We use structured population models to improve our better understanding of a population or improve predictions of its future dynamics, or guide the management of the population. We might learn a lot about what controls the abundance of a species if we can test ideas related to different stages, ages, or sizes. What limits the population growth of the Western toad – is it egg survival, or overwintering survival of juveniles? Where should we invest our efforts to control garlic mustard (Alliaria petiolata) – killing the first year rosettes, or the second year adults? Why are cacti generally endangered (Goettsch et al. 2015)—is the smallest size, or the largest size that is most essential to insure long-term survival? We can use structured population models to address such questions. 4.1 A two stage matrix model Figure 4.2: Like all amphibians, the Western toad (Anaxyrus boreas) has a complex life cycle, with several life history stages. Adults breed in early spring, laying eggs in water. The larvae (tadpoles) hatch and develop over the spring and summer, and then metamorphose (become metamorphs), and then juveniles. Juveniles require more than a year to mature. Adults can live up to about a decade. American toads (A. americanus) do the same thing. A matrix model of a structured population consists of stages and transitions. Vonesh and Cruz (2002) used matrix projection to assess the importance of egg mortality for declines in amphibian populations. Their model of the Western toad (Anaxyrus boreas, Fig. 4.2) comprises two stages (juveniles and adults) and four transitions. In all structured popuation models23, a transition is the annual contribution of an individual in stage \\(i\\) at time \\(t\\) to stage \\(j\\) at \\(t+1\\). In Fig. 4.2, the transition from juvenile to adult is the probability that a juvenile survives an entire year and also matures, becoming sexually viable.24 The transition from juvenile to juvenile is the probability that a juvenile survives a year and does not mature. The transition from adult to adult is the probability that an adult survives the year. These three transitions are probabilities. The transition from adult to juvenile (Fig. 4.2) is typically referred to as fecundity, and it is the product of several events. Vonesh and De la Cruz assume that this transition depends on the population sex ratio, the average clutch size of a female, egg survival, larval survival and metamorphosis, and the overwintering survival of metamorphs. They even assume that larval survival depnds on denisty. Thus what we refer to as “fecundity”25 is far more than just average clutch size because it must include all the processes that occur over the year associated with producing a clutch and the survival of that clutch. Structured population models allow us to take advantage of the natural history of our study species. For our study population, at a minimum, we need to (i) identify stages that differ in their demographic rates, and (ii) when individuals tend to breed. Consider the example of the Western toad (Anaxyrus boreas). As with all amphibians, survival and fecundity rates depend heavily or entirely on life history stages of egg, larvae (tadpole), juvenile, and adult. We would know that breeding occurs in early spring, depending on latitude and elevation. If we wanted to model juveniles and adults, we would typically sample a population prior to breeding when juveniles and adults are just starting to become active. The design of a structured population model depends on the sampling or census schedule. These models are typically assume an annual census that occurs just before, and just after seed set, egg laying, or births. We refer to these as pre-breeding or post-breeding census models. Vonesh and Cruz (2002) (Fig. 4.2) use a pre-breeding census model. This is because only juveniles and adults are present in the population at the time of sampling. If the design assumed a post-breeding census (later in the year), it would probably include three stages, with larva (tadpoles) in addition to juveniles and adults. The reasons for using a pre- vs. post-breeding census include our ability to actually identify and sample stages, and parameter estimation. For example, it may be easy to accurately estimate the abundance of juvenile and adult toads, but very difficult to estimate larval density and larval survival. In such a case, we could represent the adult to juvenile transition as a black box, estimated as the total number of new juveniles in year \\(t+1\\) divided by the number of adults in year \\(t\\). We can draw a two different types of life cycle graphs for this two-stage model in just such a population (Fig. 4.3). Some people find one more illuminating than the other. It is useful to be able to use both. Figure 4.3: Two types of life cycle graphs. These both represent an amphibian pre-breeding model. All the stages must be present during the annual census, and each arrow or transition must represent everything that happens over the entire year. Notice the transition from adult toad to juvenile toad (Fig. 4.3) includes egg production, egg survival, tadpole or larva survival and growth, and metamorphosis out of the aquatic stage. This are obviously important events. We make explicit only those stages that we count during our census; all other other events are iplicit within the transitions. Once we have a life cycle diagram (Fig. 4.3), we create a transition or projection matrix that represents mathematically all of the stages and transitions between stages (4.1). This matrix will have one row and one column for each stage, and the columns represent the stages in year \\(t\\) and the rows represent the stages in year \\(t+1\\). We refer to a single column by j and a single row by i. Each column represents stage j in year \\(t\\), and each row represents stage i in year \\(t+1\\). For our amphibian example, the transition matrix will have two rows and two columns. It will be a “two by two”, or \\(2 \\times 2\\) matrix. \\[ \\begin{equation} \\tag{4.1} \\mathbf{A} = \\left( \\begin{array}{cc} p_{11}&amp;F_{12} \\\\ p_{21}&amp;p_{22} \\end{array} \\right) \\end{equation} \\] If (4.1) represents the Western toad (Fig. 4.3), then transition \\(p_{11}\\) is the probability that juveniles survive but fail to mature, \\(p_{21}\\) is the probability that juveniles survive and also mature, \\(p_{22}\\) is the probability that adults survive, and \\(F_{12}\\) is contribution of the average adult to the juvenile stage. In addition to fecundity, survival, maturation or growth from one stage to the next, some organisms undergo regression (Fig. 4.4). Regressing means to transition from a later stage to an earlier stage. For instance, and plant can shrink in size do to physical damage, disease or herbivory. A plant can also return temporarily to a non-reproductive stage after a large bout of reproduction. These are examples of regression (Fig. 4.4). One assumption we are making is that individuals set seed, or give birth, all at once. Therefore, we refer to our model as a birth-pulse model. On the other hand, if we assume that we have continuous reproduction throughout the year, we do things differently, and would refer to this as a birth-flow model. Whether a population is breeding continuously over a year, or whether reproduction is seasonal, will influence how we estimate fecundities. Even for synchronously breeding populations, many models pool years into a single age class or stage. The interested reader should consult an authoritative text such as Caswell (2001). Figure 4.4: A transition matrix, in which each element in the matrix describes the probability that an individual of a given size \\(j\\) at time \\(t\\) appears as size \\(i\\) and time \\(t+1\\). Reproduction typically results in the minimum size, stage, or age. This matrix may be composed of a small number of rows and columns (2-10), or, in the case of integral projection, an infinite number of rows and columns. The number of rows is equal to the number of columns. A life cycle graph (Figs. 4.2, 4.3) and the corresponding transition matrix (4.1) constitute our model. The matrix A for our structured population is directly analogous to \\(\\lambda\\) for our unstructured model of discrete population growth in the previous chapter.26 Later, we will project the population in an analogous way, using \\[\\mathbf{ N_{t+1} = A N_t}\\] and to do that, we need a refresher on matrix multiplication. 4.2 A brief primer on matrices We refer to matrices by their rows and columns. A matrix with three rows and one column is a \\(3 \\times 1\\) matrix (a ``three by one’’ matrix); we always state the number of rows first. Matrices comprise elements; an element of a matrix is signified by its row and column. The element in the second row and first column is \\(a_{21}\\). The dimension of a matrix is its number of rows and columns. To add two matrices, they must have the same dimensions. Consider two matrices, A and B . To add these two matrices we simply add the elements in the same row and column of both matrices, as below. \\[\\begin{align*} \\mathbf{A} &amp;= \\left( \\begin{array}{cc} a &amp; b \\\\ c &amp; d \\end{array} \\right); \\; \\mathbf{B} = \\left(\\begin{array}{cc} m &amp; o\\\\ n &amp; p \\end{array}\\right)\\\\ \\mathbf{A+B} &amp;= \\left( \\begin{array}{cc} \\left( a+m \\right) &amp; \\left(b+o \\right)\\\\ \\left(c+n \\right) &amp; \\left(d+p \\right) \\end{array} \\right) \\end{align*}\\] Multiplying matrices is a little more complicated. To do so, we mutliply elements and then sum them: multiply each row element of the first matrix (A) times each column element of the second matrix (B), sum the element-wise products, and place this sum in the respective element of the final matrix. This process is what we refer to as a dot product or sometimes inner product. When we have two vectors of equal length \\(x\\) and \\(y\\) the dot product is \\[x \\cdot y = x_1y_1 + x_2y_2 + \\ldots + x_n y_n\\] A dot product begins with two equal length vectors and returns a single number (i.e. a scalar). Consider the matrix multiplication in (4.2). We first multiply each element of row 1 of A (\\(a\\; b\\)), times the corresponding elements of column 1 of B (\\(m\\; n\\)), sum these products, and place the sum in the first row, first column of the resulting matrix. We then repeat this for each row of A and each column of B. \\[\\begin{align} \\tag{4.2} \\mathbf{AB} &amp;= \\left( \\begin{array}{cc} \\left( am + bn \\right) &amp; \\left(ao+bp \\right)\\\\ \\left(cm + dn \\right) &amp; \\left(co + dp \\right) \\end{array}\\right) \\end{align}\\] To do this, the number of columns in the first matrix must equal the number of rows in the second matrix. It also means that the resulting matrix will have the same number of rows as the first matrix, and the same number of columns as the second matrix. Multiplying a \\(2 \\times 2\\) matrix by a \\(2 \\times 1\\) results in a \\(2 \\times 1\\). Multiplying a \\(3 \\times 3\\) matrix by a \\(3 \\times 1\\) results in a \\(3 \\times 1\\). We cannot multiply a \\(2 \\times 1\\) matrix by a \\(2 \\times 2\\) because the number of columns in the first matrix (1) does not match the number of rows in the second matrix (2). Let’s define two \\(2 \\times 2\\) matrices, M and N, filling in one by rows, and the other by columns. (M &lt;- matrix( 1:4 , nrow=2, byrow=TRUE)) ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 (N &lt;- matrix( c(10, 20, 30, 40), nrow=2)) # byrow=FALSE is the default. ## [,1] [,2] ## [1,] 10 30 ## [2,] 20 40 Adding these matrices is simple. Here we do the first element by hand, and then sum the matrices all at once. # 1 + 10 M[1,1] + N[1,1] ## [1] 11 M + N ## [,1] [,2] ## [1,] 11 32 ## [2,] 23 44 To mulitply M and N, we multiply and then sum the first row of \\(M\\) by the first column of \\(N\\), and make this element \\(a_{11}\\) of the resulting matrix product. # 1*10 + 2*20 M[1,1] * N[1,1] + M[1,2] * N[2,1] ## [1] 50 This is the dot product. In R, we must use %*% to signify that we mean matrix multiplication. M %*% N ## [,1] [,2] ## [1,] 50 110 ## [2,] 110 250 If we multiply M times a \\(2 \\times 1\\) matrix D, what should we get? D &lt;- matrix(c(100, 200), nrow=2) M %*% D ## [,1] ## [1,] 500 ## [2,] 1100 # note that we cannot perform D %*% M Make sure you could write out the multiplication and summation for each element in the resulting matrix. The transpose of M is \\(\\mathbf{M^T}\\) M; t(M) ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 We use the transpose of A to calculate reproductive value, later in the chapter. 4.3 Decomposing A A slightly different way to conceptualize our transition matrix is to consider it the three separate matrices, one each for growth, survival, and fecundity, \\[\\mathbf{ A = GS + F }\\]. Survival, S, and growth, G, have these elements: each stage \\(j\\) has its own probability of survival \\(s_j\\), which describes survival of each stage from \\(t\\) to \\(t+1\\). each survivor in stage \\(j\\) will grow or regress into a different stage, or remain in the same stage, with probability \\(g_{ij}\\). In a demographic context, fecundity, F, is the surviving number of offspring produced by the average individual in stage \\(i\\). Sometimes this is a complete black box, in which we can only count the adults in year \\(t\\) and the offspring in year \\(t+1\\). Other times, we can use estimates of the probability that an individual in stage \\(i\\) reproduces at all, the average number of offspring of an individual that does actually reproduce, and the survival and growth of the adults or the resulting offspring. It all depends on the detail we have of our study system. And, of course, it depends heavily on whether we census our population shortly before reproduction (pre-breeding census), or shortly after reproduction (post-breeding census). For our Western Toad (Fig. 4.2), this results in \\[\\begin{equation*} \\tag{4.3} \\mathbf{A = GS + F} = \\left( \\begin{array}{cc} 1-\\mathrm{P} &amp; 0 \\\\ \\mathrm{P} &amp; 1 \\end{array} \\right) \\left( \\begin{array}{cc} \\sigma_j&amp;0\\\\ 0 &amp; \\sigma_a \\end{array} \\right) + \\left( \\begin{array}{cc} 0 &amp; \\rho \\phi \\sigma_e \\sigma_t \\sigma_m \\\\ 0 &amp; 0 \\end{array} \\right) = \\left( \\begin{array}{cc} \\sigma_j (1-\\mathrm{P}) &amp; \\rho \\phi \\sigma_e \\sigma_t \\sigma_m \\\\ \\sigma_j \\mathrm{P} &amp; \\sigma_a \\end{array} \\right) \\end{equation*}\\] where \\(\\sigma_j,\\,\\sigma_a\\) are survival of juveniles and adults, and P is the probability of juvenile growth, given survival. If an adult survives it always remains an adult (\\(g_{22}=1\\)) and never regresses (\\(g_{12}=0\\)). Fecundity occurs only in adults, and it is the product of the sex ratio (\\(\\rho\\)), average clutch size per female (\\(\\phi\\)), egg survival (\\(\\sigma_e\\)), survival of tadpoles (\\(\\sigma_t\\)), and the overwintering survival of the metamorphs (\\(\\sigma_m\\)).27 Vonesh and de la Cruz went further and added density-dependence using a term for the negative effects of high tadpole density on tadpole survival and growth. We do not show that here, but regardless how complex the natural history gets, we can build natural history into our models. 4.4 A three stage model Now we describe a three-stage model of a plant population. Like our amphibian example, it is a pre-breeding model, relying on a pre-breeding census. Nonetheless, it includes a seed stage for the seed bank, where seeds may be more than one year old. Eleanor Pardini et al. (n.d.) and colleagues modeled garlic mustard (Alliaria petiolata), a biennial plant species that is an exotic invasive species in the eastern deciduous forest of the U.S. The stages they choose to represent were those present in May: seeds in the soil seed bank, 1–2 month old immature rosettes, and adults (Fig. 4.5. Figure 4.5: The life cycle of garlic mustard using a post-breeding census (Pardini et al. 2009). The census takes place in May of each year. Each arrow represents the transition from May to May. Seeds germinate in early spring and become rosettes (basal leaves near the soil surface). The rosettes experience mortality all summer, fall, and winter. Surviving rosettes become reproductive adults the following spring a summer. Adults flower and are pollinated in June, after which the fruits ripen and seeds mature. Seeds overwinter for at least six months before germinating in the spring. Not all seeds germinate, but they may remain viable in the seed bank for several years. Thus, the complete life cycle at least two years. Once the seeds germinate, the plant requires over a year to reach maturity, and produce flowers, fruits and seeds. Let’s work through these probability transitions. \\(s_1\\), a germinated seed survives as a rosette. \\(s_2\\), surviving from May to August as a rosette. \\(s_3\\), surviving from August to early May and becoming a reproductive plant. \\(v\\), a seed is viable (survives and can germinate). \\(g_1\\), a viable seed germinates in the first season, or \\(1-g_1\\) remains ungerminated. \\(g_2\\), a viable seed germinates in the second season or \\(1-g_2\\) does not. Fecundity, \\(f\\), is the average number of seeds per reproductive plant. The transition matrix A would thus be \\[\\begin{equation*} \\tag{4.4} \\mathbf{A} = \\left( \\begin{array}{ccc} 1-g_2 &amp; 0 &amp; v(1-g_1)f \\\\ g_2 s_1 &amp; 0 &amp; v g_1 s_1 f \\\\ 0 &amp; s_2 s_3 &amp; 0 \\end{array} \\right) \\end{equation*}\\] Put into your own words each of the transition elements. What about the transition from adult to rosette? Did the plant shrink? While perennial plants can get smaller, or regress, that is not what happens here. In this transition, the adult in May gets pollinated, develops fruits, the seeds mature and are deposited on the soil late that summer or fall. Those seeds are survive overwinter, germinate in early spring, and grow into rosettes that summer, and survive until the next census in May. In that way, stage 3 (adult) contributes to stage 2 (rosette) through reproduction plus survival and growth. The transition from adult to seed, \\(p_{13}\\), occurs only when the seeds do not germinate after the first winter, but spend another year in the seed bank in the soil. Once we have the transition matrix, we can use it to characterize many features of the population, including the finite rate of increase (\\(\\lambda\\)), the predicted relative abundances of the various stages, and the relative importance of each separate transition \\(p_{ij}\\) for the long term population growth rate. We will do this in a later section, but first will explore projection. It is frequently useful to acutally project the population, one year at a time, into the future. 4.5 Projection Projection is the modeling of a population through time, for prediction under one or another set of assumptions. In practice, we use matrix multiplication to project stage- or structured populations. Matrix multiplication does all these calculations for us. We let A be our square demographic transition matrix, with one row and one column for each stage. Let \\(\\mathbf{N}_t\\) be a one-column matrix of stage sizes, with one row for each stage. Matrix multiplication allows us to project the population, \\(\\mathbf{A}\\mathbf{N}_t = \\mathbf{N}_{t+1}\\). To project a population for multiple years, we use a for-loop. We used this in the previous chapter for an unstructured population. Here we multiply our transition matrix by the current year’s abundances projecting next year’s abundances. All we need to specify are the transition matrix, starting stage abundances for \\(t=0\\), and the number of years through which we want to project. Here we define a transition matrix, \\(\\mathbf{N}_0\\), and a numbers of time steps to project. A &lt;- matrix( c(.1, 2.0, .3,.4), nrow=2, byrow=T) N0 &lt;- matrix(c(100, 1), nrow=1) years &lt;- 6 To do the for-loop, we need an zeroes matrix to hold \\(n\\) for each of the years of each of the stages, including for our first year. We start by filling our matrix with zeroes and “binding” the rows in \\(\\mathbf{N}_0\\) onto the top of our zeroes matrix as the first row. N.proj1 &lt;- matrix( 0, nrow=years, ncol=nrow(A)) colnames(N.proj1) &lt;- c(&quot;Juv&quot;, &quot;Adult&quot;) N.proj2 &lt;- rbind(N0, N.proj1) Now we perform the iteration with the for-loop and plot the result. Note how we do the multiplication for the current year \\(t\\) and put the result in the next year \\(t+1\\). # Project, then... for(t in 1:years) {N.proj2[t+1,] &lt;- A%*%N.proj2[t,]} # ...rearrange and plot N.proj.data &lt;- data.frame(Year=0:years, N.proj2) npd &lt;- gather(N.proj.data, Stage, Abundance, -Year) ggplot(npd, aes(Year, Abundance, linetype=Stage)) + geom_line() Figure 4.6: Projection of a population showing transient dynamics. In the first seven years, we see the abundances of the two stages bounce around. These are transient dynamics that, in our density-independent models, will fade away over time. 4.6 Analyzing the transition matrix Projection is very important for many reasons, especially for stochastic models or for very complicated models. However, we also get some of our best insights through direct analysis the transition matrix using eigenanalysis (Caswell 2001). The features we learn about a structured population using eigenanalysis are best thought of as predictions, attractors, or long term averages, assuming that the transition elements don’t change. This is a big assumption, but understanding it helps us interpret the analysis appropriately. Once you have obtained the transition matrix, \\(\\mathbf{A}\\), you can analysis it using eigenanalysis to estimate \\(\\lambda\\), the finite rate of increase, stable stage structure, reproductive value, and sensitivities and elasticities. Below, we explain each of these quantities. 4.6.1 Eigenanalysis Eigenanalysis is a mathematical technique that summarizes multivariate data. Ecologists use eigenanalysis frequently, for (i) multivariate statistics such as ordination, (ii) local stability analyses with two or more species, and (iii) analyzing population transition matrices. Eigenanalysis is simply a method to transform a square matrix into independent, or orthogonal, pieces. These pieces are eigenvectors and their corresponding eigenvalues. There are the same number of eigenvalues (and eigenvectors) as there are columns in a matrix. In demography, the two of the most useful pieces are the dominant right eigenvalue and its corresponding right eigenvector. Eigenanalysis is a technique that finds all the solutions for \\(\\lambda\\) and \\(\\mathbf{w}\\) of \\[ \\tag{4.5} \\mathbf{Aw}=\\lambda \\mathbf{w} \\] where \\(\\mathbf{w}\\) is a column vector with the same number of rows as \\(\\mathbf{A}\\). If we write out eq. (4.5) for a \\(2 \\times 2\\) matrix, we would have \\[ \\tag{4.6} \\left( \\begin{array}{ccc} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22}\\\\ \\end{array} \\right) \\left( \\begin{array}[c]{c} w_{11}\\\\ w_{21} \\end{array} \\right) =\\lambda \\left( \\begin{array}[c]{c} w_{11}\\\\ w_{21} \\end{array} \\right) \\] For instance, we can perform eigenanalysis on this transition matrix. (A &lt;- matrix(c(0, .3, 2, .7), nrow=2)) ## [,1] [,2] ## [1,] 0.0 2.0 ## [2,] 0.3 0.7 (eA &lt;- eigen(A)) ## eigen() decomposition ## $values ## [1] 1.2 -0.5 ## ## $vectors ## [,1] [,2] ## [1,] -0.8574929 -0.9701425 ## [2,] -0.5144958 0.2425356 This gives us one eigenvalue per column of our transition matrix (values). Each eigenvalue has a corresponding eigenvector that is the corresponding column of the vectors matrix. Let’s use R to prove to ourselves that eq. (4.5) is what we say it is. Here we see for ourselves whether \\(\\mathbf{A}\\mathbf{w} = \\lambda \\mathbf{w}\\) for \\(i = 1\\). Below, we use the results of the previous eigenanalysis. (lambda1 &lt;- eA$values[1]) ## [1] 1.2 (w1 &lt;- eA$vectors[,1]) ## [1] -0.8574929 -0.5144958 cbind(A %*% w1, lambda.w=lambda1 * w1) ## lambda.w ## [1,] -1.0289915 -1.0289915 ## [2,] -0.6173949 -0.6173949 The first column is \\(\\mathbf{Aw}\\) and the second column is \\(\\lambda \\mathbf{w}\\). Sure enough, they look the same. Try doing the same exercise for the second eigenvalue and the second eigenvector, \\(i=2\\). Typically, the first eigenvalue and its corresponding eigenvector capture the most important features of the transition matrix. We call these the dominant eigenvalue, \\(\\lambda_1\\), and its corresponding eigenvector, \\(w_1\\). While first solution does not capture all of the information about our transition matrix, it is the most useful. There are an infinite number of solutions to this equation because solutions can just be simple multiples of the set found with eigenanalysis. Eigenanalysis finds a set in which the solutions are all independent of each other, and which capture all of the information in \\(\\mathbf{A}\\) in a particularly useful way. In this book, we will not delve into details of eigenanalysis beyond this. Here are some eigenanalysis takeaways: you can perform eigenanalysis only on square matrices (number of rows = number of columns). there are the same number of eigenvalues of A as there are columns of A. eigenvalues are usually complex numbers, having a real part and an imaginary part. the largest eigenvalue is the one with the largest geometric mean of the real and the imaginary parts with the sign (+,-) respected. the “dominant” eigenvalue is the largest one; R will return this as the first one. each eigenvalue has a corresponding eigenvector. the number of elements in each eigenvector is the same as the number of rows in A. What is important for us is how we use the results. Below, we describe how we use eigenanalysis to find (i) the long term asymptotic finite rate of increase \\(\\lambda\\), (ii) the stable stage distribution, and the the reproductive values of each stage. 4.6.2 Finite rate of increase The asymptotic annual growth rate or finite rate of increase is the dominant eigenvalue of the transition matrix. It has the same meaning as in geometric growth of an unstructured population. Eigenvalues are always referred to with the Greek symbol \\(\\lambda\\), and provide a solution to (4.5). The dominant eigenvalue of any matrix, \\(\\lambda_{1}\\), is the eigenvalue with the largest magnitude, and it is frequently a complex number. When we perform eigenanalysis, it is common to get complex numbers, with real and imaginary parts. The magnitude is the sum of the squared parts. With population transition matrices, \\(\\lambda_{1}\\) will always be positive and real. This will not be the case with other types of matrices we examine in later chapters. The dominant eigenvalue is the biggest one. We can find which one it is by asking R to tell us the index position \\(i\\) of the largest absolute value (the modulus) of the eigenvalues. In most cases, it is the first eigenvalue, as it is here. ( dom.pos &lt;- which.max( Mod(eA[[&quot;values&quot;]]) ) ) ## [1] 1 We use that index to extract the largest eigenvalue. We keep the real part, using Re(), dropping the imaginary part. (Note that although the dominant eigenvalue of a real transition matrix will always be real, R will include an imaginary part equal to zero (\\(0i\\)) as a place holder if any of the eigenvalues has a non-zero imaginary part). # extract the dominant eigenvalue and retain only its Real part ( L1 &lt;- Re(eA[[&quot;values&quot;]][dom.pos]) ) ## [1] 1.2 L1 is \\(\\lambda_1\\), the asymptotic finite rate of increase. This finite rate of increase has the same biological meaning as \\(\\lambda\\) in the previous chapter. 4.6.3 Stable stage distribution The predicted long term average relative abundance of the different life history stages or ages is called the stage distribution, that is, the distribution of individuals among the stages. A property of a stage structured population is that, if all the demographic rates (elements of the transition matrix) remain constant, its stage structure will approach a stable stage distribution, a stage distribution in which the relative number of individuals in each stage is constant. Note that a population can grow, so that the absolute number of individuals increases, but the relative abundances of the stages is constant; this is the stable stage distribution. If the population is not actually growing (i.e. \\(\\lambda=1\\)) and demographic parameters remain constant, then the population is stationary and will achieve a stationary stage distribution, where neither absolute nor relative abundances change. How do we find the stable stage distribution? It also turns out that \\(w_1\\) provides the necessary information. We scale the eigenvector \\(w_1\\) by the sum of its elements because we are interested in the distribution, which is defined by all stages summing to one. Therefore the stable stage distribution is \\[ \\tag{4.7} \\frac{w_1}{\\sum_{i=1}^s{w_1}} \\] where \\(s\\) is the number of stages. Once a population reaches its stable stage distribution each of the stages grows or shrinks exponentially. You might believe that if you consider that we can represent \\(\\mathbf{A}\\) with \\(\\lambda\\). 4.6.4 Calculating the stable stage distribution The dominant eigenvector, \\(w_1\\), is in the same position as the dominant eigenvalue. We extract \\(w_1\\), keeping just the real part, and divide it by its sum to get the stable stage distribution. # continuing from previous code... w1 &lt;- Re(eA[[&quot;vectors&quot;]][,dom.pos]) ssd &lt;- w1/sum(w1) round(ssd, 3) ## [1] 0.625 0.375 This shows us that if the transition matrix does not change over time, the population will eventually be composed of these relative abundances. We have claimed, without evidence, that with a constant transition matrix, the projected population will eventually reach a stable stage distribution and grow exponentially with a finite rate of increase of \\(\\lambda_1\\). Here we show an example. A &lt;- matrix(c(0, .3, 2, .7), nrow=2) # our tran. matrix N0 &lt;- c(Juveniles=1,Adults=10) # initial population steps &lt;- 8 # number of time steps # combine the stages of our initial population, and a zero matrix # with a column for each stage and a row for each time step N &lt;- rbind(N0, matrix(0, ncol=2, nrow=steps) ) # use a for-loop to project the population each year and store it. for(t in 1:steps) {N[t+1,] &lt;- A%*%N[t,]} # Sum the stages to get the total N N.total &lt;- rowSums(N) # For each year, divide each stage by the total to get # relative abundances and thus the distribution. proportions &lt;- N/N.total SD &lt;- data.frame(Year=0:steps, proportions) sdg &lt;- gather(SD, Stage, Proportion, -Year) # plot the distributions for succeeding years. ggplot(sdg, aes(Stage, Proportion)) + geom_col() + facet_wrap(~Year, nrow=3, ncol=3) If we sum the abundances of the different stages, we calculate total population sizes. With that, we can calculate an annual rate of increase \\(N_{t+1}/N_t\\). # using &quot;-&quot; in an index removes that element lambda.t &lt;- N.total[-1]/N.total[-(steps+1)] qplot(x=1:steps, y=lambda.t, geom=c(&quot;line&quot;, &quot;point&quot;)) + annotate(&quot;point&quot;, x = steps , y=L1, pch=1, size=3) Figure 4.7: Calculating an annual finite rate of increase from a projected population shows that the population will approach asymptotically a constant geometric rate of increase. Solid points are annual growth rate; the circular point is lambda(1) from eigenanalysis. Iterating the transition matrix to approximate \\(\\lambda_1\\) and \\(w_1\\) is actually called the power iteration method for eigenanalysis. 4.6.5 Reproductive value If the stage structure gives us one measure of the importance of a stage (its relative abundance), then the reproductive value gives us one measure of the importance of an individual in each stage. Reproductive value is the expected contribution of each individual to future reproduction. We characterize all individuals in a stage using the same expected reproductive value. We find the reproductive value associated with each stage by solving for the dominant left eigenvector \\(\\mathbf{v}\\), where \\[ \\tag{4.8} \\mathbf{vA}=\\lambda\\mathbf{v}. \\] Like the relation between the dominant right eigenvector and the stable stage distribution, this vector is actually proportional to the reproductive values. Unlike the stable stage distribution, we scale it so that all reproductive values are relative to that of the first stage (e.g. juveniles or seeds). \\[ \\tag{4.9} \\frac{v_1}{v_{1[1]}} \\] We find the left eigenvalues and -vectors by performing eigenanalysis on the transpose of the transition matrix. Transposition flips rows and columns, so that row 1 becomes column 1 and vice versa. We perform eigenanalysis, extracting just the dominant left eigenvector; we then scale it, so the stage 1 has a reproductive value of 1.0. tA &lt;- t(A) # transpose etA &lt;- eigen(tA) dom.pos &lt;- which.max(Mod(etA$values)) v1 &lt;- Re(etA$vectors[,dom.pos]) ( rv &lt;- v1/v1[1] ) ## [1] 1 4 Here we see that reproductive value, rv, increases with age or stage. This means that the expected reproductive value of an individual in the second stage is 4 times as great as that of an individual in the first stage. In general, reproductive value of individuals in a stage increases with increasing probability of reaching fecund stages. 4.6.6 Sensitivity and elasticity Sensitivity and elasticity tell us the relative importance of each transition (i.e. each arrow of the life cycle graph or element of the matrix) in determining \\(\\lambda\\). They do so by combining information on the stable stage structure and reproductive values. The stage structure and reproductive values each in their own way contribute to the importance of each stage in determining \\(\\lambda\\). The stable stage distribution provides the relative abundance of individuals in each stage. Reproductive value provides the expected contribution to future population growth of individuals in each stage. Sensitivity and elasticity combine these to tell us the relative importance of each transition in determining \\(\\lambda_1\\). Sensitivities are the direct contributions of each transition to determining \\(\\lambda_1\\). The sensitivity for the element \\(a_{ij}\\) of a transition matrix is the change in \\(\\lambda_1\\) that occurs when we change \\(a_{ij}\\) a small amount, or \\[\\delta \\lambda / \\delta a_{ij}\\]. It isn’t surprising, then, these are derived from the stable stage distribution and the reproductive values. Specifically, the sensitivities are calculated as \\[ \\frac{\\delta \\lambda}{\\delta a_{ij}}=\\frac{v_{1[i]}w_{1[j]}}{v_1\\cdot w_1} \\tag{4.10} \\] where \\(v_{i}w_{j}\\) is the product of each pairwise combination of elements of the dominant left and right eigenvectors, \\(v\\) and \\(w\\). Specifically, the numerator is generated by the reproductive value of the target stage and the stable stage distribution of the source stage, \\[ \\begin{pmatrix} v_1\\\\v_2 \\end{pmatrix} \\begin{pmatrix} w_1 &amp; w_2 \\end{pmatrix}= \\begin{pmatrix} v_1 w_1 &amp; v_1 w_2 \\\\ v_2 w_1 &amp; v_2 w_2 \\end{pmatrix} \\] In the denominator, the dot product, \\(\\mathbf{v} \\cdot \\mathbf{w}\\), is the sum of the pairwise products of each vector element, \\[v_{11}w_{11} + v_{12}w_{12} + \\ldots + v_{1n}w_{1n}\\]. Dividing the numerator by this sum causes the sensitivities to be relative to the magnitudes of \\(v\\) and \\(w\\). Let’s calculate sensitivities now. Because the stable stage distribution and the reproductive values are merely scaled versions of the dominant right and left eigenvectors, it doesn’t matter whether we use the unscaled eigenvectors, or the scaled stable stage distribution and reproductive values. vw &lt;- matrix(rv, nr=2, nc=1) %*% matrix(ssd, nr=1, nc=2) # or vw &lt;- v1 %*% t(w1); the numerator dot.prod &lt;- sum(rv*ssd) # or dot.prod &lt;- sum(v1 * w1) denominator (s &lt;- vw/dot.prod) ## [,1] [,2] ## [1,] 0.2941176 0.1764706 ## [2,] 1.1764706 0.7058824 These are the sensitivities, \\(\\delta \\lambda / \\delta a_{ij}\\), of each corresponding transition element. You will always get a sensitivity for every position in this matrix, even when the transition is zero, \\(a_{ij}=0\\). We just ignore those, but by convention, usually include them. These sensitivities are the relative change in \\(\\lambda_1\\) for an absolute change in the element. For instance, it is the relative effect on lambda of increasing \\(a_{21}\\) from 0.3 to 0.31, or \\(a_{22}\\) from 0.7 to 0.71. The largest of the sensitivities we just calculated is that for \\(p_{21}\\), surviving from the first stage to the second stage. This means that small changes to \\(p_{21}\\) have larger effects on \\(\\lambda_1\\) than do small changes to \\(F_2\\) or \\(p_{22}\\). As \\(\\delta \\lambda / \\delta a_{ij}\\), the sensitivities are the slope of the line relating the magnitude of \\(\\lambda_1\\) to the matrix element. Figure 4.8: Sensitivities of lambda to transition elements are slopes. The dotted line is the calculated sensitivity of lambda to A[2,1], because it is the slope evaluated at A[2,1]. Elasticities are sensitivities that have been weighted by the transition probabilities. Recall that sensitivities are the effects on lambda of a small absolute change in transition matrix elements. In contrast, elasticities are the effects on lambda of a proportional change in a transition element influences \\(\\lambda_1\\)—how does a 1% increase in seed production, or a 1% decline in juvenile survival influence \\(\\lambda_1\\)? For these answers, we need to adjust sensitivities to account for the relative magnitudes of the transition elements, and this provides the elasticities, \\(e_{ij}\\). Elasticities are relative sensitivities, and are defined as \\[ e_{ij}=\\frac{\\delta \\lambda/\\lambda}{\\delta a_{ij}/a_{ij}} = \\frac{a_{ij}}{\\lambda}\\frac{\\delta \\lambda}{\\delta a_{ij}}. \\] These are also equal to \\[e_{ij}= \\frac{\\delta \\log \\lambda}{\\delta \\log a_{ij}}.\\] Like sensitivities, we can think of elasticities as slopes. Calculating these in R is easy. e &lt;- (A/L1) * s (round(e, 3)) ## [,1] [,2] ## [1,] 0.000 0.294 ## [2,] 0.294 0.412 Now we see that survival by adults (\\(p_{22}\\)) has the biggest effect on \\(\\lambda_1\\). Why the difference between sensitivities and elasticities? Because the elasticities reflect the effect of a proportional change (e.g., 1%) of the elements, whereas sensitivities reflect the effect of a change by a constant amount (e.g., 0.01) of each element. Note that elasticities are relative to each other, in that they sum to 1.0. This is an especially nice feature of elasticities because it makes it easier to compare elasticities among different matrices and different organisms. Once we have the sensitivities and elasticities, we can really begin to see what is controlling the growth rate of a stage (or age) structured population. They provide us with the predicted effects on \\(\\lambda_1\\) of a proportional change in a demographic rate. This is particularly important in the management of invasive (or endangered) species where we seek to have the maximum impact for the minimum amount of effort and resources (Caswell 2001; Ellner and Guckenheimer 2006). We can use these to help predict how a population might respond to natural phenomena or management practices that affect one stage or another. All of these details can get very confusing, and smart people don’t always get it right. Therefore, get expert advice (Caswell 2001; Ellner and Guckenheimer 2006), and remember that the stages of life cycle graph and matrix are the stages that you collect at one point in time, and an arrow or transition element has to include everything that happens from one census period to the next. 4.7 Integral projection What do we do if our stages seem like arbitrary categories along a continuous scale? What if size is easy to measure accurately and is a really good predictor of demographic rates, and these rates vary continuously with size? How do we decide on size classes? How do we draw seemingly arbitrary divisions between different sizes? With integral projection, as opposed to matrix projection, we no longer have to worry about a particular number of stages or age classes. We select an individual-level state variable, such as body mass, length, stem diameter, or even location, that is a useful predictor of demographic rates. We use this continuously varying state variable in place of stages or age classes. We rely on statistical methods, such as linear regression, to describe the relations between the individual-level state variable and survival, growth, and fecundity. We then combine those relations to model how individuals in a population are likely to change from one generation to the next. In many organisms, size is often a relatively good predictor of survival and fecundity. Within a population, size is often associated with age, learning, and resource acquisition. Size is also related to the onset of reproductive maturity and initiation of development of reproductive structures. Among reproductive individuals, size is often strongly correlated with per capita reproductive output. Integral projection can use size to model size-dependent demography. Integral projection models (IPMs) are based on the calculus of integration across continuous variables to combine information about size-dependent demographic rates and size distributions to project population abundances and sizes in the future. In practice, we rarely use the tools of integral calculus on which IPMs so solidly grounded. Instead, we approximate integration using very large matrices. As a simple example of this approximation, consider plant height that we measure using a meter stick. We assume that plant height is, in principle, a continuous variable that could take any real value between 0 and infinity. However, imagine that we only measure height to the nearest centimeter, and thereby create 100 height categories. This measurement process chops up continuous variation into discrete categories. When implementing integral projection models, we typically combine different techniques that are associated with continuous variation (e.g., linear regression) and with discrete variation (e.g., matrix algebra). 4.7.1 A size-based IPM of smooth coneflower Rachel Collins and colleagues have been studying populations of an endangered coneflower, Echinecea laevigata, in southwest Virginia, USA. Smooth coneflower is a perennial rhizomatous herbaceous plant that is sparsely distributed across mid-Atlantic and southeastern states (plantsusda.gov). It requires open spaces with little canopy cover, such as meadows or early successional habitat. Collins marked each individual in selected populations, measured size of individual coneflower plants using total leaf area, which ranged from 3-950 cm\\(^2\\). Because she tagged individuals and tracked changes over time, she was able estimate survival and fecundity of different sized individuals. She also measured seed set (number of seeds per inflorescence) and recruitment. Recruitment is emergence from the seed, that is, germination, growth, and survival in the first year. In what follows, we see empirical data on growth, survival, and fecundity. These continuous data will allow us to produce matrices with very, very narrow size classes. The details require some understanding of probability densities, rather than probabilities, per se, but they are conceptually analogous. The continuous probability density analog of a matrix is referred to as a “kernel”. Regardless, the goal is the same – we want to use our understanding of growth, survival, and fecundity to estimate a matrix or kernel K where, \\[\\mathbf{K = GS + F}\\]. Next we show the the size-dependence of these processes, and the resulting kernels. In IPMs, it is common to use the logarithm of size rather than the original linear scale. This is because many processes scale with log-size. That is what we do here - all sizes are the natural log of leaf area. # vegetative coneflower data. data(coneflower) cf &lt;- coneflower # seed set data(coneflowerseeds) sf &lt;- coneflowerseeds # recruit sizes - not shown data(coneflowerrecruits) rs &lt;- coneflowerrecruits # recruit sizes - not shown Survival, S, from one year to the next depends on size. eda_s &lt;- ggplot(cf, aes(logA, surv)) + lims(x=c(0.5, 2.75)) + geom_jitter(height=.02, alpha=0.5) + geom_smooth(method=&quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)) + labs(title=&quot;Survival&quot;) eda_s Figure 4.9: Survival is represented as surviving (1) or not surviving (0). The probability of surviving to the next year, given a size in the first year is esitmated using logistic regression. Growth, G is really how the size of a plant in one year depends on its size in the previous year. # use only the plants alive in both years cfs &lt;- filter(cf, surv==1 &amp; !is.na(logAp)) eda_g &lt;- ggplot(cfs, aes(logA, logAp)) + geom_point() + geom_abline(intercept=0, slope=1, lty=2, col=&quot;blue&quot;) + labs(title=&quot;Growth, Stasis, Regr.&quot;) + geom_smooth(method=&quot;lm&quot;,col=&quot;red&quot;, se=) eda_g Figure 4.10: Growth is the relation between size at one time vs. size in another. The fitted estimate includes the 95% confidence interval. The dashed line is the 1:1 line; above this line is growth, while below it is regression to a smaller size. Next we tackle fecundity, F, which for us is estimated using the size-dependent probability of flowering, the size-dependent number of seeds produced by a flowering individual, the probability of a seed germinating and surviving to be a new recruit, and the size-distribution of new recruits. Typically, bigger individuals have a greater chance of flowering, and smooth coneflower is no exception. We estimate that chance using logistic regression. cff &lt;- filter(cf, surv==1 ) eda_f &lt;- ggplot(cfs, aes(logA, flower_p)) + geom_jitter(height=.02, alpha=0.5) + geom_smooth(method=&quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)) + labs(title=&quot;Flowering&quot;) eda_f Figure 4.11: Plants that are larger in the first year have a greater chance of flowering in the next year. It is also true that bigger plants might produce more seeds, although there is not a lot of evidence for that is these data. eda_sd &lt;- ggplot(sf, aes(logAs, seeds)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + labs(title=&quot;Seed set&quot;) eda_sd Figure 4.12: No compelling evidence that size influences seed set. Nonetheless, we will use this approach in estiamting fecundity, F. We also need to estimate establishment probability, or the chance that a seed germinates and survives until the following summer. Collins estimated that using seed baskets. These are mesh baskets with soil into which she placed a known number of seeds. They are placed in the ground and seedlings or recruits are counted the following year. # 50 seeds into each of baskets N &lt;- rep(50, 9) # no. of seeds planted in the fall that popped up and # survived into June success &lt;- c(5,8,11,10,1,0,4,5,5) Y &lt;- cbind(success, failure=N-success) germ.est &lt;- glm(Y ~ 1, family=&quot;binomial&quot;) # the point estimate of establishment success # backtransform from logistic regression. pr &lt;- 1/(1 + exp(-coef(germ.est)[1])) # plot the probability distribution of establishment x &lt;- sum(Y[,&quot;success&quot;]) nx &lt;- sum(Y[,&quot;failure&quot;]) # Use the Jeffreys interval, which is based on the Beta distribution # with priors of (1/2, 1/2) being the conjugate prior for the binomial. eda_pr &lt;- ggplot(data = data.frame(x = c(0, 0.5)), aes(x)) + stat_function(fun = dbeta, n = 501, args = list(shape1 = x+1/2, shape2=nx+1/2)) + labs(y=&quot;Prob(recruiting)&quot;, title=&quot;Seed basket recruitment&quot;) + scale_y_continuous(breaks = NULL) eda_pr Figure 4.13: Probability that seeds in one year establish as new recruits the following summer. We can use other data (not shown) to characterize the size distribution of new recruits, which are approximately log-normally distributed. m.log &lt;- mean(log10(rs$area17)) # mean of log-area of new recruits std.log &lt;- sd(log10(rs$area17)) # st. dev. of log-area of new recruits eda_C &lt;- ggplot(data = data.frame(x = c(0.4, 1.4)), aes(x)) + stat_function(fun = dnorm, n = 101, args = list(mean = m.log, sd = std.log)) + labs(y=&quot;Prob(recruit log-size x)&quot;, title=&quot;Distr. of recruit sizes&quot;) + scale_y_continuous(breaks = NULL) eda_C Figure 4.14: The size distribution of new recruits; we assume that this is independent of plant size in year t. First we estimate something from data, then we use it to build functions. I use code handed down on stone tablets from Ellner, Merow, and others. We start with a data frame to hold summaries. ## this sets up a list of the model parameters. These parameters will be estimated and recorded below. params=data.frame( surv.int=NA, surv.slope=NA, growth.int=NA, growth.slope=NA, growth.sd=NA, flowering.int=NA, flowering.slope=NA, seed.int=NA, seed.slope=NA, seed.sd=NA, recruit.size.mean=NA, recruit.size.sd=NA, establishment.prob=NA ) Next, we perform the analyses from which we extract means, linear relationships, and variation, and put this values into the above data frame. #survival regression surv.reg=glm(surv~logA,data=cf,family=binomial()) params$surv.int &lt;- coef(surv.reg)[1] params$surv.slope &lt;- coef(surv.reg)[2] # Growth gr.reg &lt;- lm(logAp ~ logA, data=cf) params$growth.int &lt;- coef(gr.reg)[1] params$growth.slope &lt;- coef(gr.reg)[2] params$growth.sd &lt;- sd(resid(gr.reg)) # flowering fl.reg=glm(flower_p~logA, data=cf,family=binomial()) params$flowering.int &lt;- coef(fl.reg)[1] params$flowering.slope &lt;- coef(fl.reg)[2] # seed set seed.reg &lt;- lm(seeds ~ logAs, data=sf) params$seed.int &lt;- coef(seed.reg)[1] params$seed.slope &lt;- coef(seed.reg)[2] params$seed.sd &lt;- sd(resid(seed.reg)) # recruitment params$establishment.prob &lt;- pr # recruit size distr. params$recruit.size.mean &lt;- m.log params$recruit.size.sd &lt;- std.log Here we make functions that will be able use the above relationships and the data frame to make the kernel. ## Make the kernel (cf. projection matrix) # Relies on the Riemann sum, using midpoints. Increase $n$ to decrease $h$ and improve accuracy (but reduce speed). # The variable &#39;y&#39; in the figures below is log10(Area). # 1. boundary points b, mesh points y and step size h # integration limits - these limits span the range of sizes observed in the data set, and then some. min.size=.9*min(c(log10(rs$area17), cf$logA,cf$logAp),na.rm=T) max.size=1.1*max(c(log10(rs$area17), cf$logA,cf$logAp),na.rm=T) # number of cells in the discretized kernel n=100 # boundary points (the edges of the cells defining the kernel) b = min.size + c(0:n)*(max.size-min.size)/n # mesh points (midpoints of the cells) y = ( b[1:n] + b[2:(n+1)] ) / 2 # width of the cells h = y[2]-y[1] ############# # 2. make component kernels par(mfrow=c(2,2)) # outer yields an outer product where each element is can be an arbitrary function. G=h*outer(y, y, FUN=g.zpz, params=params) # growth kernel image(y,y,t(G),main=&#39;G&#39;) # plot it P = G # placeholder;redefine P on the next line S=s.z(y,params=params) for(i in 1:n) P[,i]=G[,i]*S[i] # growth*survival kernel {image(y,y,t(P),main=&#39;GS&#39;) # plot it abline(0,1,lwd=3) }# plot 1:1, which represents stasis Fec=h*outer(y, y, f.zpz, params=params) # reproduction kernel image(y,y,t(Fec),main=&#39;F&#39;) # plot it K=P+Fec # full kernel #image(y,y,t(K),main=&#39;full kernel&#39;) # plot it # sometimes it&#39;s hard to see both because # the fecundity part of the kernel swamps the growth/survival part, # so here&#39;s a plotting trick to level out the kernel image(y,y,t(K)^.33,main=&#39;K&#39;, col=grey.colors(12, start=0, end=1, rev = TRUE)) # plot it Figure 4.15: The component kernels G, S, and F, that make up the full demographic projection kernel, K, for smooth cone flower. Unlike proection matrices, kernels scale both axes to start at size = 0 in the lower left corner. The color scaling of the full kernel differs slightly so that we can see the contributions of G, S, and F. 4.7.2 Population summaries Any question that we could answer using matrices, we can answer using kernels. We estimate the finite rate of increase, \\(\\lambda\\), the same way we did before. (lambda=Re(eigen(K)$values[1])) [1] 1.061195 The same is true for the stable size distribution, reproductive value, and elasticity. w.eigen=Re(eigen(K)$vectors[,1]) stable.dist=w.eigen/sum(w.eigen) v.eigen=Re(eigen(t(K))$vectors[,1]) repro.val=v.eigen/v.eigen[1] # The eigen-things can be combined to obtain the sensitivity and elasticity matrices. # 2. compute elasticity and sensitivity matrices v.dot.w=sum(stable.dist*repro.val)*h sens=outer(repro.val,stable.dist)/v.dot.w elas=matrix(as.vector(sens)*as.vector(K)/lambda,nrow=n) # 3. plot results par(mfrow=c(1,3)) plot(y,stable.dist,xlab=&quot;Size&quot;,type=&quot;l&quot;,main=&quot;Stable size distribution&quot;) plot(y,repro.val,xlab=&quot;Size&quot;,type=&quot;l&quot;,main=&quot;Reproductive values&quot;) image(y,y,t(elas),xlab=&quot;Size (t)&quot;,ylab=&quot;Size (t+1)&quot;,main=&quot;Elasticity&quot;) Figure 4.16: Descriptions of smooth coneflower demographics. 4.8 R packges for demography Caswell (2001) is a definitive reference text for matrix models. Ellner and Guckenheimer (2006) provides an excellent introduction, and I am sure there are many other excellent texts as well. Stubben and Milligan (2007) and Stott, Hodgson, and Townley (2018), and de la Cruz (2019) provide R packages for stage-based matrix models with methods that go well beyond this text. In addition, there are several other packages for analyzing life tables and human demography. Ellner, Childs, and Rees (2016) is probably the best source for understanding IPMs. The R package IPMpack (Metcalf et al. 2014) is an excellent package to implement and analyze IPMs. 4.9 Exploring a real population Crouse, Crowder, and Caswell (1987) performed a demographic analysis of an endangered sea turtle species, the loggerhead (Caretta caretta). Management of loggerhead populations seemed essential for their long term survival, and a popular management strategy had been and still is to protect nesting females, eggs, and hatchlings. The ground breaking work by Crouse28 and her colleagues compiled data to create a stage-based projection matrix to analyze quantitatively which stages are most important and least important in influencing long-term growth rate. This work led to US Federal laws requiring that US shrimp fishermen use nets that include Turtle Excluder Devices (TEDs, https://www.fisheries.noaa.gov/southeast/bycatch/turtle-excluder-device-regulations ). Crouse et al. determined a transition matrix, A, for their loggerhead population: \\[\\begin{array}{c} H\\\\J_s\\\\J_l \\\\sub \\\\ B_1 \\\\B_2 \\\\ M \\end{array} \\left( \\begin{array}{cccccccc} 0&amp; 0&amp; 0&amp; 0&amp; 127&amp; 4&amp; 80\\\\ 0.6747&amp; 0.7370&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0.0486&amp; 0.6610&amp; 0&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0.0147&amp; 0.6907&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0&amp; 0.0518&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 0.8091&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0.8091&amp; 0.8089 \\end{array} \\right)\\] A &lt;- matrix( c(0, 0, 0, 0, 127, 4, 80, 0.6747, 0.7370, 0, 0, 0, 0, 0, 0, 0.0486, 0.6610, 0, 0, 0, 0, 0, 0, 0.0147, 0.6907, 0, 0, 0, 0, 0, 0, 0.0518, 0, 0, 0, 0, 0, 0, 0, 0.8091, 0, 0, 0, 0, 0, 0, 0, 0.8091, 0.8089), nrow=7, ncol=7, byrow=TRUE) eigen(A)$values ## [1] 0.9450310+0.0000000i 0.7461702+0.2130565i 0.7461702-0.2130565i ## [4] 0.3716668+0.0000000i 0.2654528+0.0000000i -0.0884455+0.1195997i ## [7] -0.0884455-0.1195997i Draw by hand two different types of life cycle graphs for this loggerhead population. Include the matrix elements associated with each transition. Use eigenanalysis to determine \\(\\lambda_1\\). Explain what this tells us about the population, including any assumptions regarding the stable stage distribution. Use eigenanalysis to determine the stable stage distribution. Use eigenanalysis to determine the elasticities. Which transition(s) are most influential in determining growth rate? What is the predicted long-term relative abundance of all stages? What do we call this? If your interest is to maximize long-term growth rate, in which stage(s) should you invest protection measures? Which stages are least likely to enhance long-term growth rate, regardless of protective measures? Start with \\(\\mathbf{N} = \\left(1000\\,10\\,10\\,10\\,10\\,10\\,10\\right)\\) and graph dynamics for all stages for 20 years. References "],
["DDgrowth.html", "5 Density-dependent growth 5.1 Continuous logistic growth 5.2 Dynamics around the equilibria — stability 5.3 Other forms of density-dependent growth 5.4 Discrete Density-dependent Growth 5.5 Maximum Sustained Yield", " 5 Density-dependent growth Let’s go back to our Song Sparrow (Melospiza melodia) data that we used to illustrate density-independent growth — now we graph all the data. Figure 5.1: Song Sparrow Melospiza melodia* counts, \\(N\\), from 1966–2003 and the relation between observed counts and annual growth rate determined from those counts, fit with ordinary least squares regression. See Chapter 3 for data source.* When we plot the annual per capita growth rate, \\(r_t = \\log (N_{t+1}/N_t)\\), as a function of \\(N\\), we see a pattern emerge. At low \\(N\\), \\(r&gt;0\\), whereas at high \\(N\\), \\(r &lt; 0\\). The annual growth rate depends on the size or density of the population. This is the sort of thing we mean we we use the term density-dependent growth. What might limit the population growth of these sparrows? Space available for male territories in their successional-scrub type habitat? Availability of seeds, fruits and invertebrates? We don’t necessarily know precisely what limits it, but if it is something related to their own abundance, then we can treat density as a proxy for the amount of limitation. Density-dependent population growth is the case where the per capita population growth rate depends statistically on the density of the population. When the slope of that relation is negative as it is in Fig. 5.1, we call this negative density-dependence. Negative density dependence a characteristic of a population undergoing intraspecific competition, where individuals of the same species compete for shared resources and have negative effects on their demographic rates. So, how would we represent this algebraically?29 5.1 Continuous logistic growth When it was originally introduced to ecology by Verlhurst in the late 1800s, he described the limits to population growth in terms of an upper limit \\(K\\), \\[\\begin{equation} \\frac{dN}{dt}= rN\\left(1-\\frac{N}{K}\\right) \\tag{5.1} \\end{equation}\\] where \\(K\\) is referred to as the carrying capacity. It is the population size where the negative effects of crowding prevent additional population growth. This happens in this equation because when \\(N=K\\), population growth rate falls to zero, because \\(\\left(1-K/K\\right)=1-1=0\\). Notice that the first part of this equation is exponential growth \\(rN\\), which is then modified by a negative effect of a growing population. As \\(N\\) grows, so does \\((1-N/K)\\) and causes \\(dN/dt\\) to shrink. As \\(N\\) approaches \\(K\\), \\(dN/dt\\) approaches zero, and the population stops changing and stays at \\(N=K\\). We refer to \\(K\\) as an attractor because \\(N\\) moves in a deterministic fashion toward \\(K\\) – \\(K\\) attracts \\(N\\). We explore the meanings of attractor and related terms throughout the book. Theory alert! Recall that Alan Hastings (2011) identified principles of macroscopic theory of population growth, that (i) populations exponentially, unless (ii) something prevents exponential growth. Here we see one of those somethings – negative density dependence. Another common representation of this model, the one we use here is \\[\\begin{equation} \\frac{dN}{dt}= rN\\left(1-\\alpha N\\right) \\tag{5.2} \\end{equation}\\] where \\(\\alpha=1/K\\). In this manner, \\(\\alpha\\) represents the per capita effect of an individual on its population growth rate. More on that next. 5.2 Dynamics around the equilibria — stability The stability of a system30 is a measure of how much it tends to stay the same, in spite of external disturbances or changes in the state of the system. The term stability has been given many more specific meanings, including resilience, resistant, reactivity, and permanence. We won’t go into these here, but one could consider them different facets of stability .31 We will focus on resilience, the tendency for a population to return an equilibrium, or be attracted toward an equilibrium, if it is perturbed from it. Consider the stability of a marble inside a wok. If the wok doesn’t move, then the marble just sits in the lowest spot on the bottom. If the wok is bumped, the marble jiggles and rolls around a bit, but settles back down to the bottom. This is a stable system because there is a point at the bottom of the bowl (the attractor) toward which the marble rolls — all points inside the wok allow the marble to find the lowest point (the attractor). For this reason, we call the collection of points on the inside surface of the wok the basin of attraction. The steeper the sides, the more quickly the marble moves toward the bottom. This rate is referred to as its resilience. To translate the notion of a basin into a population, let the position of marble inside the wok be the value of \\(N\\) at any particular point. Bumping the wok is any disturbance that causes a change in \\(N\\). The slope of the sides of the wok reflects the biology and its mathematics that cause \\(N\\) to move quickly or slowly back toward the bottom. For the logistic model, this rate is determined by \\(r\\) and \\(\\alpha\\), and also by \\(N\\) itself. The attractor at the very bottom of the bowl is the population’s carrying capacity, \\(K=1/\\alpha\\).32 When we imagine a marble in a wok, it becomes easy to envision \\(K\\) as an attractor at the bottom of the bowl. That is why we consider the carrying capacity a stable equilibrium point, or attractor, even if other factors, such as a disturbance, may cause \\(N\\) to deviate from it. The equilibrium we have focused on has been \\(K\\), but recall that \\(N=0\\) is also an equilibrium. This equilibrium is actually the edge of the wok — the slightest jiggle, and the marble falls in and moves toward the center of the wok, \\(K\\). The biological analog of this “jiggle” is the additional of one or a very small numbers of individuals to an otherwise extinct population. For example, consider that a sterile Petri dish with nutrient agar has an E. coli population size of zero. If that E. coli \\(N=0\\) gets “perturbed” with a single added cell, the population will move quickly toward its carrying capacity \\(K\\). In this sense, \\(N=0\\) is an equilibrium, but it is an unstable equilibrium. We also call such an unstable equilibrium a repeller. 5.2.1 Analytical linear stability analysis We are interested in the dynamics or stability of \\(N\\) at each of the equilibria, \\(N^*\\). Here we use analytical linear stability analysis to show mathematically what we described above with the marble and the wok. While somewhat limited in its scope, linear stability is nonetheless a powerful technique for dynamic model analysis. In a nutshell, what we do is determine whether the growth rate, which is zero at each equilibrium, becomes positive or negative in response to a small change in \\(N\\). That is, if \\(N\\) takes a tiny step away from the equilbrium, does that tiny step shrink, or grow? If a tiny step results in a shrinking of that step, back toward the equilibrium, that demonstrates stability. If a tiny step results in growth and a bigger step, that demonstrates instability. That is what analytical stability analysis tells us. Consider a plot of the growth rate, \\(dN/dt\\) vs. \\(N\\) (Fig. 5.2). The equilibria, \\(N^*\\), are the \\(N\\) (\\(x\\)-axis) at which \\(dN/dt=0\\) (points a, d). Note where population growth rate is positive and where it is negative. What will happen to this population if it finds itself at \\(N=50\\)? It will grow, moving along the \\(x\\)-axis, until population growth rate slows so much that it comes to rest where \\(N=1/\\alpha=K=100\\). Thus, \\(N\\) changes until it converges on the equilibrium, \\(N^*\\), where \\(dN/dt=0\\). Alternatively at \\(N=110\\), \\(dN/dt\\) is negative, and so \\(N\\) shrinks back down to \\(K\\) (point d). This return toward \\(K\\) means that \\(K\\) is an attractor and a stable equilibrium. Next, consider \\(N=0\\), at point a; it cannot change on its own. However, if “perturbed” at all, with the addition of one or more individuals, then this “perturbation” will grow, sending \\(N\\) across the \\(x\\)-axis, away from \\(N=0\\), toward \\(N=K\\). This stasis at \\(N=0\\), and movement away from \\(N=0\\) with the slightest perturbation means that \\(N=0\\) is a repeller and an unstable equilibrium. Linear stability analysis will calculate the degree of attraction or repulsion at a local point. # Plot the phase portrait - use the phaseR package logisticPP &lt;- phasePortrait(logistic, ylim = c(-5, 105), parameters = c(1, 100), ylab=&quot;Population Growth Rate (dN/dt)&quot;, xlab=&quot;N&quot;) N &lt;- c(0, 10, 50, 100, 115) pop.growth.rate &lt;- expression( N * (1 - N/100) ) points(N, eval(pop.growth.rate), cex=1.5) text(N, eval(pop.growth.rate), letters[1:5],adj=c(.5,2)) Figure 5.2: Population growth rate, \\(dN/dt\\), as a function of \\(N\\). This kind of graph is called a phase portrait or phase plane. Points a–e are labelled for convenience. At values of \\(N\\) associated with points \\(a\\) and \\(d\\), population growth rate equals zero. At values of \\(N\\) associated with \\(b\\) and \\(c\\) growth rate is positive, and for \\(e\\) growth rate is negative. Note this is growth rate as a function of \\(N\\) (time is not explicitly part of this graph) How fast will \\(N\\) return to \\(N^*=K\\), if perturbed? Let’s start by imagining that we have two populations with different intrinsic rates of increase (\\(r=1,\\,0.5\\)), and focus in on the growth rate at \\(N^*=K\\) (Fig. 5.3). For which one of these populations will \\(dN/dt\\) go to zero more quickly? If each population loses a few individuals and declines by \\(x\\) to \\(N^*-x\\), which population will return to \\(N^*\\) more quickly? Not surprisingly, it is the population with the higher \\(r\\) — when \\(r=1\\), its population growth rate (\\(y\\)-axis) is greater than when \\(r=0.5\\), and therefore will return at a faster rate. Note also that this same population (\\(r=1\\)) has a negative growth rate of greater magnitude at \\(N^*+x\\). Regardless of whether it gains or loses individuals, it will return to \\(N^*\\) more quickly than the population with the lower \\(r\\). Figure 5.3: Very close to an equilibrium, a population recovers from a perturbation, moving toward the equilibrium attractor, at rate \\(e^{-r}\\). Left, slopes of population growth \\(vs.\\) \\(N\\) near the equilibrium; around the equilibrium attractor, small decreases in \\(N\\) lead to positive growth rate, whereas small increases lead to negative growth rate; the population with the steeper slope changes faster. Right, regardless of the particular \\(r\\) of a population, a population recovers from a perturbation, moving toward the equilibrium attractor, at rate \\(e^{-r}\\) How do we quantify the rate of return at \\(N^*\\) so that we can compare two or more populations? The slope of the curve at \\(N^*\\) quantifies the rate of return, because the slope is the exponential return rate. To calculate the slope of a curve we use calculus, because the slope of a curve is a derivative. In this case, we need the derivative of the growth rate (\\(dN/dt\\)) with respect to the variable on the \\(x\\)-axis, \\(N\\). Such a derivative is called a partial derivative. Therefore we need the partial derivative of growth rate, with respect to \\(N\\). This will be the slope of the growth rate with respect to \\(N\\). To find the partial derivative, let us denote the population growth rate as \\(\\dot{N}=dN/dt\\) (“N-dot”), \\[\\begin{equation} \\label{eq:dot} \\dot{N} = rN\\left(1-\\alpha N\\right). \\end{equation}\\] \\(\\dot{N}\\) is a common symbol for a time derivative such as a growth rate, and we use it here merely to simplify the notation. Given \\(\\dot{N}\\), its partial derivative with respect to \\(N\\) is \\[\\begin{equation} \\tag{5.3} \\frac{\\partial \\dot{N}}{\\partial N} = r - 2r\\alpha N. \\end{equation}\\] Further, we are interested in the equilibrium, where \\(N = 1/\\alpha\\). If we substitute this into eq. and simplify, this reduces to \\[\\begin{equation} \\label{eq:pdlog2} \\frac{\\partial \\dot{N}}{\\partial N} = -r \\, . \\end{equation}\\] At \\(N^*=1/\\alpha\\), the slope is \\(-r\\). *This negative slope at the equilibrium demonstrates the stability of this equilibrium. Near \\(N^*\\), population growth rate is \\(-rx\\).33 That is, the rate of change of \\(x\\) (Figs. 5.3) is \\[\\begin{equation} \\tag{5.4} \\frac{dx}{dt} = -rx \\end{equation}\\] This allows us to pretend that the perturbation will diminish exponentially, because the growth rate is constant. We say “pretend,” because we realize that this rate applies only in the small region where we can assume the slope is a straight line. We can describe the size of \\(x\\) at any time \\(t\\) by integrating this well-known differential equation with respect to time as \\[\\begin{equation} \\tag{5.5} x_t = x_0e^{-r t} \\end{equation}\\] where \\(x_0\\) is the size of the initial displacement relative to the equilibrium, and \\(x_t\\) is the size of the displacement at time \\(t\\) relative to the equilibrium. If we choose an \\(x_t\\) carefully, and do so for any and all such analyses, we can determine the time required to reach \\(x_t\\) and we call that time the characteristic return time. To determine the characteristic return time, we will let \\(x_t=x_0/e\\), thus defining the characteristic return time as the amount of time required to reduce the perturbation by 63% (i.e. \\(1/e\\)). We can solve for \\(t\\) by dividing through by \\(x_0\\) and taking the \\(\\log\\) of both sides, \\[\\begin{align} \\tag{5.6} \\frac{x_0}{e} &amp;= x_0e^{-r t}\\\\ \\log\\left(e^{-1}\\right) &amp;= -r t\\\\ t &amp;= -\\frac{1}{\\left(-r\\right)}. \\end{align}\\] Thus we see return time, \\(t\\), here is a positive number, with the same units as \\(r\\), and depends on the slope of the the growth rate with respect to \\(N\\). It also depends on the assumption of linearity very close to the equilibrium. To review, we took the partial derivative of \\(dN/dt\\) with respect to \\(N\\), and then evaluated the partial derivative at \\(N^*\\) to get the rate of change of the perturbation, \\(x\\). A negative value indicates that the perturbation will decline through time, indicating a stable equilibrium or attractor. A positive value would indicate that the perturbation will grow over time, thus indicating an unstable equilibrium, or a repellor. We can use R’s minimal symbolic capabilities to get derivatives. Here we get the partial derivative and then evaluate it for the two equilibria (Fig. 5.2). alpha &lt;- 0.01; r &lt;- 1 pop.growth.rate &lt;- expression( r * N * (1 - alpha*N) ) # find the partial derivative of dNdt dF.dN &lt;- D(pop.growth.rate,&quot;N&quot;) dF.dN # here it is ## r * (1 - alpha * N) - r * N * alpha # set N equal to zero and the carrying capacity N &lt;- c(0, 1/alpha) # calculate the slopes of dN/dt vs. N at those two points eval(dF.dN) ## [1] 1 -1 The first value, 1, corresponds to the first value of \\(N\\), which is \\(N=0\\). Because it is positive, this indicates that the perturbation will increase with time, meaning that \\(N=0\\) is a repellor. The second value, \\(-1\\), is negative, and so indicates that the perturbation will decrease with time, meaning that \\(N=1/\\alpha\\) is an attractor. 5.2.2 Projection with numerical integration In simple density-independent growth, we were able to project a population using the integral of the exponential growth equation, \\(N_t=N_0 e^{rt}\\). As our models become more complex, we are no longer able to to do that. Instead, we use numerical integration to project models of continuous growth through time. We use numerical techniques that turn the infinitely small intervals of calculus (\\(dx\\), \\(dy\\)) into very, very small, but finite steps. Mathematicians and computer scientists have devised very clever ways of doing this very accurately and precisely. In R, the best package for this is deSolve, which contains several solvers for differential equations that perform numerical integration. We will access these solvers (i.e. numerical integraters) using the ode function in the deSolve package. This function, ode, is a wrapper for the underlying suite of functions that do the work. When we have an ordinary differential equation (ODE) such as logistic growth,\\(dN/dt = rN(1-\\alpha N)\\) we say that we “solve” the equation, over a particular time interval given a set of parameters and particular initial conditions or initial population size. For instance, we say that we solve the logistic growth model for time at \\(t=0,\\, 1 \\ldots \\, 20\\), with parameters \\(r=1\\), \\(\\alpha=0.001\\), and \\(N_0=10\\). Let’s do an example with ode, using logistic growth. We first have to define a function in a particular way. The arguments for the function must be, in order: time, a vector of populations, and a vector or list of model parameters. Note that this function is already in the primer package as clogistic(), so you don’t have to run this code to use the function. clogistic &lt;- function(time, y, parameters){ # y is a single value of N; if we have more than one population, # e.g. competition, then y would have two values, one for # each population. # parameters is a vector of...parameters.... # Both y and parameters have names for each element, # e.g., y &lt;- c(N=10) - see the text. with(as.list(c(y, parameters)), { # &quot;with&quot; creates an &quot;environment&quot; within which R looks for values # c() combines the two vectors into one # as.list() turns the resulting vector into a list # our differential equation for growth dN.dt &lt;- r * N * (1 - alpha * N) # making the function create output, which must be a list with # one element return( list( dN.dt ) ) } ) } While it isn’t necessary, we use with() to allow us to use the names of variables and parameters (Petzoldt 2003). This works only when y and p are vectors with named variables and parameters. Finally, we use return to cause the function to produce the derivative in a list. The following is equivalent, but slightly less readable or transparent. logistic2 &lt;- function(t, y, p){ dN.dt &lt;- p[1] * y[1] * (1 - p[2] * y[1]) return( list( dN.dt ) ) To solve the ODE, we will need to specify parameters–we wil have to tell R the values we want to use for \\(r\\) and \\(\\alpha\\). p &lt;- c(r=1, alpha = 0.001) We also need to tell R the size of the population to start with, at \\(t=0\\), or \\(N_0\\). We refer to this as the initial condition, and we will start with a population size of \\(N_0=1\\). We also need to supply the time steps we want as output. R will project the population size for all times up until and including the last time step we specify. # We name the state variable and the parameters y0 &lt;- c(N=1) t &lt;- 0:20 Now you put it all into ode(), with the correct arguments. The output is a matrix, with the first column being the time steps, and the remaining being your state variables. Because you loaded primer, the deSolve package should be loaded already.34 out &lt;- ode(y=y0, times=t, func=clogistic, parms=p) out[1:5,] ## time N ## [1,] 0 1.000000 ## [2,] 1 2.713627 ## [3,] 2 7.342179 ## [4,] 3 19.709440 ## [5,] 4 51.820737 We can plot the output as well. The deSolve package directs R to use special methods to plot output from ode. plot(out) Figure 5.4: Output from a numerical integration of logistic growth, where N0==10, r=1, alpha=0.001. Here we see the classic S-shaped curve of logistic growth. Regardless where we start, the population will always settle down on \\(K=1/\\alpha\\). Before reading on, predict the shape of this curve if: \\(r\\) is smaller, or larger. \\(\\alpha\\) is smaller, or larger. the initial population size is above \\(K\\) t=seq(0, 20, by=0.01); r &lt;- c(.5, 1.5) alpha &lt;- c(0.002, 0.001); N0 &lt;- c(10, 1500) input &lt;- expand.grid(r=r, alpha=alpha, N=N0) outdf &lt;- NULL #outdf &lt;- data.frame(time=NULL, N=NULL, N0=NULL, r=NULL, alpha=NULL) for(i in 1:nrow(input)) { y &lt;- c(N=input[i,&quot;N&quot;]) p &lt;- c(r=input[i,&quot;r&quot;], alpha=input[i,&quot;alpha&quot;] ) out &lt;- ode(y, times=t, fun=clogistic, p) out2 &lt;- cbind(out, N0=y, r=p[&quot;r&quot;], alpha=p[&quot;alpha&quot;]) outdf &lt;- rbind.data.frame(outdf, out2) } outdf$N0 &lt;- as.factor( outdf$N0 ) outdf$alpha &lt;- as.factor(outdf$alpha ) ggplot(outdf, aes(time, N, colour=N0, linetype=alpha) ) + geom_line() + facet_grid(r~., labeller=label_both) + theme_bw() Figure 5.5: How variation in logistic growth parameters influence the dynamics. We see that the refer to \\(K\\) as an attractor because \\(N\\) moves in a deterministic fashion toward \\(K\\). We explore the meanings of attractor and related terms throughout the book. The phaseR package has some sweet plotting functions for systems of 1 or two ODEs. We used it above for the phase portrait, and here we use it for the trajectories. # Plot the velocity field, nullclines and several trajectories ## These create arrows (vectors) whose length and direction ## reveal the velocity at different points logistic_flowField &lt;- flowField(logistic, xlim = c(0, 5), ylim = c(-1, 3), parameters = c(1, 2), points = 21, system = &quot;one.dim&quot;, add = FALSE) ## A logistic_nullclines &lt;- nullclines(logistic, xlim = c(0, 5), ylim = c(-1, 3), parameters = c(1, 2), system = &quot;one.dim&quot;) logistic_trajectory &lt;- trajectory(logistic, y0 = c(-0.5, 0.5, 1.5, 2.5), tlim = c(0, 5), parameters = c(1, 2), system = &quot;one.dim&quot;) Figure 5.6: A velocity field is kind of like a magnetic field, showing what rate and direction of trajectories throughout this space. A nullcline is an isocline where the rate of change is zero (the straight horizontal lines in this figure). Here r = 1, and K=2. 5.3 Other forms of density-dependent growth There are many forms of density-dependent growth, some of which will we describe below. Let’s start by decoupling the density-dependence of birth and death rates (Gotelli 2001). 5.3.1 Effects of N on birth and death rates Recall from chapter 3 that \\(r=b-d\\). Now we will let \\(b\\) and \\(d\\) be functions of population size \\(N\\) (\\(b=F(N)\\), \\(d=G(N)\\)). We could let \\(F(N)\\) and \\(G(N)\\) take a wide variety of different forms. For now, however, let’s say that \\(N\\) has linear effects on these rates so that \\[\\begin{align} b &amp;=b_0 - aN\\\\ d &amp;= d_0 + cN \\end{align}\\] which appear in Fig. 5.7. Figure 5.7: Per capita birth and death rates can be functions of density (dashed lines). The carrying capacity (K) occurs at the point where the per capita birth and death rates are equal. The solid line represents the per capita population growth rate, which is zero when N=K. Now population growth rate is \\[\\begin{align} \\frac{dN}{dt} &amp;= [(b_0-aN)-(d_0 + cN)] N\\\\ &amp; =[(b_0-d_0) - (a+c)N] N\\\\ &amp; = (b_0-d_0)(1-\\frac{a+c}{b_0-d_0}N)N \\end{align}\\] where the net negative effect of \\(N\\) on per capita population growth rate is \\[\\alpha = \\frac{a+c}{b_0-d_0}\\] where the numerator is the total direct negative effect of \\(N\\) on birth and death rates, and the denominator is \\(r\\), the net maximum per capita growth rate which occurs as \\(N\\) approaches zero. 5.3.2 Theta-logistic growth Here we explore a simple extension of the logistic model, the theta-logistic model, which adds a parameter to increase flexibility and generality. \\[\\begin{equation} \\tag{5.7} \\frac{dN}{dt} = rN\\left(1 - \\left(\\alpha N\\right)^\\theta \\right) \\end{equation}\\] Here \\(\\theta\\) is strictly positive (\\(\\theta&gt;0\\)); \\(\\theta=0\\) means zero growth, and \\(\\theta &lt; 0\\) would mean negative growth below \\(K\\), and unbounded positive growth above \\(K\\). Approximations of eq. (5.7) that allow \\(\\theta \\leq 0\\) are possible (Sibly et al. 2005), but the interpretation becomes strained. Here we make a function that we can use with ode(), the numerical integration function. You’ll need to run this code to use it later. thetalogistic &lt;- function(times, y, parms) { ## with() and as.list() create an environment in which R will see ## the named elements in `parms`. n &lt;- y[1] with(as.list(parms), { dN.dt &lt;- r * n * (1-(alpha*n)^theta) return( list( c(dN.dt) ) ) } ) } By varying \\(\\theta\\), we can change the linear density dependence of the simple logistic model to curvilinear density dependence (Fig. ). This curvilinearity arises because when \\(\\alpha N &lt; 1.0\\) (i.e. \\(0 &lt; N &lt; K\\)), \\[\\begin{align*} \\tag{5.8} \\left(\\alpha N\\right)^\\theta &amp;&lt; \\alpha N,\\quad \\theta &gt; 1\\\\ \\left(\\alpha N\\right)^\\theta &amp;&gt; \\alpha N,\\quad \\theta &lt; 1. \\end{align*}\\] In contrast, when \\(\\alpha N=1.0\\), then \\(\\left(\\alpha N\\right)^\\theta &lt; \\alpha N\\). This means that \\(\\theta\\) does not affect \\(K\\). When \\(\\theta &gt; 1\\), this weakens density dependence at low \\(N\\), so the population grows faster than logistic, all else being equal. When \\(\\theta &lt; 1\\), this strengthens density dependence at low \\(N\\), causing the population to grow more slowly than logistic, all else being equal. The effects of \\(\\theta\\) on density dependence controls the shape of relation between growth rate \\(vs\\). \\(N\\) (a.k.a. the production function, Fig. ). First, note that for a given \\(r\\), growth rate for \\(N&lt;K\\) increases with \\(\\theta\\). Second, note that the position of peak of the production function shifts to the right as \\(\\theta\\) increases. That is, as \\(\\theta\\) increases, the \\(N\\) at which the maximum growth rate occurs also increases. If we wanted to shift the peak growth rate to a higher \\(N\\) without also increasing the height of the peak, we could decrease \\(r\\) simultaneously. We could speculate on biological meaning of \\(\\theta\\) and the shape of the denisty dependence. For instance, very high \\(\\theta\\) suggests a threshold, wherein the population exhibits little density dependence until very close to \\(K\\). Perhaps this is related to territoriality, or a spatial refuge from predators. Alternatively, low \\(\\theta\\) might suggest resource preemption, wherein a small number of individuals can sequester large amounts of resources, but increasing \\(N\\) results in reduced preemption. For organisms with very plastic body sizes (plants, fish), this could mean that at low \\(N\\), average body size is large, but as \\(N\\rightarrow K\\), average body size decreases. While \\(\\theta\\), per se, is devoid of mechanism, discovering the magnitude of \\(\\theta\\) for different types of species could lead to the generation of new testable hypotheses about what controls populations. r &lt;- .75; alpha &lt;- 0.01; theta &lt;- c(.5, 1, 2); N &lt;- 0:110 ## Per capita PGR theta.out &lt;- sapply(theta, function(th) {1-(alpha*N)^th}) matplot(N, theta.out, type=&#39;l&#39;, col=1) abline(h=0) legend(&#39;topright&#39;, legend=paste(&quot;theta =&quot;, c(2, 1, 0.5) ), lty=3:1, bty=&#39;n&#39;) ## PGR thetaGR.out &lt;- sapply(theta, function(th) {r*N*(1-(alpha*N)^th)}) matplot(N, thetaGR.out, type=&#39;l&#39;, col=1) abline(h=0) ## r &lt;- 3.4 lines(N, r*N*(1-(alpha*N)^theta[1])) text(12, 24, &quot;r=3.4&quot;) prms &lt;- c(r = 0.75, alpha = 0.01, theta=1) t &lt;- seq(0,20, by=.1) thetaN &lt;- sapply(theta, function(th) {prms[&quot;theta&quot;] &lt;- th ode(y=1, times=t, thetalogistic, prms)[,2] } ) matplot(t, thetaN, type=&#39;l&#39;) Figure 5.8: Theta-logistic per capita rates, population growth rates, and dynamics for $ heta&lt;1$, $ heta=1$, and $ heta&gt;1$. In a review of population dynamics, Sibly et al. (2005) use theta-logistic density dependence to show that populations most frequently have a concave-up, $ heta &lt; 1$, pattern. 5.3.3 Allee effect The Allee effect is a positive relation between average individual fitness and population size (Drake and Kramer 2011). For us, this translates as a positive relation between per capita population growth rate and population size. An Allee effect is likely to arise in sexually reproducing populations. This occurs because at very low population sizes, male and female individuals are less likely to encounter each other and so mating frequency is very low. As population size increases, females and males are more likely to encounter each other, and mating increases. One way to represent this is with an additional term in our model, which incorporates a threshold population size, below which population growth rate is negative. Here \\(a\\) is the threshold population size, \\[\\begin{equation} \\frac{dN}{dt}= rN\\left(1-\\alpha N\\right)\\left(1 - \\frac{a+\\tau}{N+\\tau}\\right) \\tag{5.9} \\end{equation}\\] so that if the population size falls below the threshold, it cannot recover (\\(N&lt;a\\), \\(dN/dt &lt; 0\\)). Parameter \\(\\tau\\) is greater than 0, and controls how severe the consequence is for \\(N&lt;a\\). The smaller \\(\\tau\\) is, the more negative population growth becomes. A function to project this dynamic is available in primer as alogistic(). ## for simplicity, we let r=1 so we can ignore it here. pgrA &lt;- function(N, alpha, a, tau){ N*(1-alpha*N)*(1-(a+tau)/(N+tau)) } myData &lt;- data.frame( N=c(0, 110) ) # ggplot requires a data frame p &lt;- ggplot(data=myData, aes(x=N)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=pgrA, geom=&quot;line&quot;, n=1001, args=list(alpha = 0.01, a=20, tau=.1)) + labs(y=&quot;Population growth rate (dN/dt)&quot;, x=&quot;Population size (N)&quot;) + #theme_classic() + geom_hline(yintercept=0, lty=3)+ scale_x_continuous(expand = c(0, 0)) p Figure 5.9: The Allee effect the a positive relation bewteen population growth rate and population size, often best envisioned as a negative consequence of small population size. Here, the threshold population size is 20, meaning that \\(dN/dt &lt; 0\\), when \\(N &lt; 20\\). 5.3.4 The integral of logistic growth We might as well add that there is an expression for \\(N_{t}\\), analogous to \\(N_{t}=N_{0}\\exp(rt)\\) for exponential growth. If we integrate eq. (5.2) with respect to time, we have \\[\\begin{equation} N_{t}=\\frac{N_{0}e^{rt}}{1+\\alpha N_{0}\\left(e^{rt}-1\\right)}. \\label{fig:clogisticNt} \\end{equation}\\] Note the resemblance to the exponential equation. We have the exponential equation in the numerator, divided by a correction factor which starts at 1 when \\(t=0\\). The correction factor then grows with time, at a rate which is virtually the same as exponential growth but adjusted by \\(\\alpha\\) and scaled by \\(N_{0}\\). Thus when \\(t=0\\), and if \\(N_0\\) is small, we have near-exponential growth, decreased merely by a factor of \\(\\alpha N_0\\). 5.4 Discrete Density-dependent Growth The continuous logistic equation is probably our simplest example of population growth, aside from pure exponential growth. Here we describe the discrete-time version. Recall that the discrete time version of population growth rate is \\[\\frac{\\Delta N}{\\Delta t}=\\frac{N_{t+1}-N_t}{(t+1) - t}=N_{t+1}-N_t\\] because our time step is one (1) entire time unit (typically a year). The discrete time logistic function is therefore \\[\\begin{equation} N_{t+1} - N_t = r_d N_t\\left(1-\\alpha N_t\\right) \\tag{5.10} \\end{equation}\\] Here \\(r_d\\) has the same meaning it did in chapter 3, where \\(r_d = b-d-bd\\). When \\(r_d\\) is quite small in a slow growing population, this is very similar to the continuous form. However, as \\(r_d\\) becomes larger in a faster growing population, the dynamics can get quite exciting. Let’s explore the dynamics of this numerically by writing a function to project discrete logistic growth. A pre-written function is available in primer by the same name. To project a discrete time model, we have to project entire one year at a time. We did this for structured demographic models, and unstructured geometric growth and our sparrow simulation. We will do it here using a function in the deSolve package that imposes a one year time step, specifically for discrete time models, including difference equations.35 We set up the model as we did with the continuous time model. dlogistic &lt;- function (t, y, p) { N &lt;- y[1] with( as.list(p),{ N.diff &lt;- rd * N * (1 - alpha * N) return(list(N.diff)) }) } We then specific the parameters, the initial state or population size, and the time steps. Note that for a discrete time model the time steps must be annual increments. We then project the population. p &lt;- c(rd=1, alpha=.01) y &lt;- c(N=10) years &lt;- 0:10 outd &lt;- ode(func = dlogistic, y = y, times = years, parms = p, method = &quot;euler&quot;) outd &lt;- as.data.frame(outd) ggplot(outd, aes(x=time, N)) + geom_line() + geom_point() + annotate(&quot;text&quot;, x=1, y =1/p[&quot;alpha&quot;]+2, label=&quot;K = 1/alpha&quot;) Figure 5.10: Discrete growth can look a lot like continuous growth as long as the per capita growth rate is low. 5.4.1 Effects of \\(r_d\\) Changing \\(\\alpha\\) or \\(K\\) does not change radically the dynamics of this model. However, increasing \\(r_d\\) changes the dynamics a lot. This is in contrast to what happens in continuous logsitic growth. When we increase \\(r_d\\) sufficiently, we get stable limit cycles and if we raise \\(r_d\\) high enough, we get chaos.36. rd.v &lt;- seq(1.3, 2.8, by=.3) N0 &lt;- c(N=10); t = 0:20 Ns &lt;- sapply(rd.v, function(r) { p &lt;- c(rd=r, alpha=0.01) outd &lt;- ode(func = dlogistic, y = N0, times = t, parms = p, method = &quot;euler&quot;)[,2] } ) out &lt;- data.frame(t=t, Ns) names(out) &lt;- c(&quot;t&quot;, paste(&quot;rd=&quot;,rd.v, sep=&quot;&quot;)) out.l &lt;- pivot_longer(out, cols=-1, names_to=&quot;r.d&quot;, values_to=&quot;N&quot;) ggplot(out.l, aes(t, N) ) + geom_line() + facet_wrap(~r.d) Figure 5.11: How variation in \\(r_d\\) influences dynamics of discrete logistic growth. At low \\(r_d\\), we have simple asymptotic approach to \\(K\\). As \\(r_d\\) increases, we see the population overshoot the carrying capacity and exhibit damped oscillations. When \\(2 &lt; r_d &lt; 2.449\\), the population is attracted to two-point limit cycles. In this case, these two points are stable attractors. Regardless where the population starts out, it is attracted to the same two points, for a given \\(r_d\\). As \\(r_d\\) increases further, the number of points increases to a four-point limit cycle (e.g., at \\(r_d=2.5\\)), then an eight-point cycle, a 16-point limit cycle, and so on. These points are stable attractors. As \\(r_d\\) increases further , however, stable limit cycles shift into chaos (\\(r_d&gt;2.57\\)). Chaos is a non-repeating, deterministic fluctuating trajectory, that is bounded, and sensitive to initial conditions. May (1974) shocked the ecological community when he first demonstrated stable limit cycles and chaos using this model. His groundbreaking work, done on a hand calculator, showed how very complicated, seemingly random dynamics emerge as a result of very simple deterministic rules. Among other things, it made population biologists wonder whether prediction was possible at all. In general, however, chaos seems to require very special circumstances, including very high population growth. Is there a biological interpretation of these fluctuations? Consider some simple environment, in which small vegetation-eating animals with high reproductive rates eat almost all the vegetation in one year. The following year, the vegetation will not have recovered, but the animal population will still be very high. Thus the high growth rate causes a disconnect between the actual population size, and the negative effects of those individuals comprising the population. The negative effects of the actions of individuals (e.g., resource consumption) are felt by the offspring of those individuals, rather than the individuals themselves. We won’t belabor the point here, but it is certainly possible to extend this delayed density dependence to a wide variety of populations. The discrete logistic model has a built in delay, or time lag, of one time step, because the growth increment makes a single leap of one time step. This delay is missing from the analogous continuous time model because the growth increment covers an infinity small time step, thanks to the miracles of calculus.37 5.4.2 Bifurcations Up until now, we have examined \\(N\\) as a function of time. We have graphed it for different \\(\\alpha\\) and \\(N_0\\), but time was always on the \\(x\\)-axis. Now we are going to examine \\(N\\) as a function of \\(r_d\\), so \\(r_d\\) is on the \\(x\\)-axis. Specifically, we will plot the stable limits or attractors \\(vs\\). \\(r_d\\) (Fig. ??). What does it mean? For \\(r_{d} &lt; 2\\), there is only a single \\(N\\). This is what we mean by a stable point equilibrium, or point attractor. As long as \\(r_d\\) is small, \\(N\\) always converges to a particular point.38 When \\(2&lt;r_{d}&lt;2.45\\), then all of a sudden there are two different \\(N\\); that is, there is a two-point stable limit cycle. Note that when \\(r_d\\approx 2\\) these oscillations between the two point attractors around \\(K\\) are small, but as we increase \\(r_d\\), those two points are farther apart. The point at which the limit cycle emerges, at \\(r_d=2\\), is called a bifurcation; it is a splitting of the single attractor into two attractors. At \\(r_{d}\\approx 2.45\\), there is another bifurcation, and each the two stable attractors split into two, resulting in a total of four unique \\(N\\). At \\(r_{d}\\approx 2.53\\), there are eight \\(N\\). All of these points are periodic attractors because \\(N\\) is drawn to these particular points at regular intervals. As \\(r_d\\) increases the number of attractors will continue to double, growing geometrically. Eventually, we reach a point when there becomes an infinite number of unique points, that are determined by \\(r_{d}\\).39 This completely deterministic, non-repeating pattern in \\(N\\) is a property of chaos. Chaos is not a random phenomenon; rather it is the result of deterministic mechanisms generating non-repeating patterns. Here we perform more comprehensive simulations, and plot the point and periodic attractors vs. \\(r_d\\). First we pick some constraints for the simulation: the number of different \\(r_d\\), the sequence of \\(r_d\\) values, and the number of time steps. ## Iff you are interested.... num.rd &lt;- 1001 # the number of rd&#39;s you want rd.s &lt;- seq(1.5,3, length=num.rd) # the actual rd values t &lt;- 0:1000 # how long to run each population N0 &lt;- c(N=99) # N-zero ## do all the dynamical simulations putting each run ## into a column of a matrix. Ns &lt;- sapply(rd.s, function(r) { p &lt;- c(rd=r, alpha=0.01) outd &lt;- ode(y = N0, times = t, func = dlogistic, parms = p, method = &quot;euler&quot;)[,2] } ) out &lt;- data.frame(t=t, Ns) # put times to the front of the matrix names(out) &lt;- c(&quot;t&quot;, paste(&quot;rd=&quot;,rd.s, sep=&quot;&quot;)) # relabel columns out.last &lt;- subset(out, t &gt; 0.8*max(t)) # keep only the last 20% ## put the data in the &quot;long format&quot; out.l &lt;- pivot_longer(out.last, cols=-1, names_to=&quot;r.d&quot;, values_to=&quot;N&quot;) out.l &lt;- arrange(out.l, r.d, t) # re-order the data ## extract text out of the &#39;r.d&#39; label that is the numeric value text.values &lt;- substr(out.l$r.d, regexpr(&quot;=&quot;, out.l$r.d)+1, 100) ## convert the characters of &quot;1.5&quot; to the number 1.5 out.l$rd &lt;- as.numeric( text.values ) ## plot the stable limits to show the bifurcations ggplot(out.l, aes(rd, N)) + geom_point(pch=&quot;.&quot;) + theme_bw() Figure 5.12: Illustration of the long term dynamics of discrete logistic population growth. When a small change in a continuous parameter results in a change in the number of attractors (e.g. a single point equilibrium to a stable 2-point limit cycle), we call this a bifurcation. out.l.chaotic &lt;- subset( out.l, rd &gt; 2.6 ) ggplot(out.l.chaotic, aes(rd, N)) + geom_point(pch=&quot;.&quot;) + theme_bw() Figure 5.13: Illustration of the long term dynamics of discrete logistic population growth. When a small change in a continuous parameter results in a change in the number of attractors (e.g. a single point equilibrium to a stable 2-point limit cycle), we call this a bifurcation. There has been a great deal of effort expended trying to determine whether a particular model or real population exhibits true chaos. In any practical sense, it may be somewhat unimportant whether a population exhibits true chaos, or merely a higher order periodic attractor (Ellner and Turchin 2005). The key point here is that very simple models, and therefore potentially simple mechanisms, can generate very complex dynamics. Another very important characteristic feature of chaotic populations is that they are very sensitive to initial conditions. Thus emerges the idea that whether a butterfly in Sierra Leone flaps its wings twice or thrice may determine whether a hurricane hits the southeastern United States in New Orleans, Louisiana, or in Galveston, Texas.40 If we generate simulations where we vary initial population size by a single individual, we find that this can have an enormous impact on the similarity of two populations’ dynamics, and on our ability to predict future population sizes (Fig. @(fig:DDGChaosInitN)). Note how the populations start with similar trajectories, but soon diverge so that they experience different sequences of minima and maxima (Fig. @(fig:DDGChaosInitN)). This is part of what was so upsetting to ecologists about May’s 1974 paper — perhaps even the simplest deterministic model could create dynamics so complex that we could not distinguish them from random (May 1974). Over time, however, we came to learn that (i) we could distinguish random dynamics from some chaos-like dynamics, and (ii) the hunt for chaos could be very exciting, if most frequently disappointing (Becks et al. 2005; Constantino et al. 1995; Kendall, Prendergast, and Bjornstad 1998). We start with three populations, all very close in initial abundance, \\(N_0 \\in \\{97,98,99\\}\\). We then project the population with a \\(r_d\\) to generate chaos for 30 time steps. N.init &lt;- c(97,98,99) t &lt;- 0:30 p &lt;- c(rd=2.7, alpha=0.01) out &lt;- NULL for(i in 1:3){ # project the population N0 &lt;- c(N=N.init[i]) a &lt;- ode(y=N0, times=t, dlogistic, parms=p, method=&quot;euler&quot;) # fill a column with the initial value b &lt;- data.frame(a, N0=as.factor(N0)) # b now has cols: t, N, rd # store data in rows of out &quot;bind rows&quot; with rbind out &lt;- rbind.data.frame(out, b) } ggplot(data=out, aes(time, N, colour=N0, linetype=N0)) + geom_line() Figure 5.14: Effects of differences in initial population size on the short term and long term dynamics, and their correspondence, of three populations. One last issue that we should note is the extent to which our populations are bounded. A population may have complex dynamics, but we may be able to characterize a given population by its upper and lower bounds. In spite of the differences created by the initial conditions, the upper and lower bounds of our chaotic populations were very similar (Fig. 5.14). Note also as \\(r_d\\) increases (Fig. ??) the oscillations increase very systematically. One way to see the deterministic nature of chaos is to trace population size from each time point to the next time point. We put \\(N_t\\) on the \\(x\\)-axis and \\(N_{t+1}\\) on the \\(y\\)-axis, and connect all successive points. N0 &lt;- c(N=2); t &lt;- 0:1000 p &lt;- c(rd = 2.8, alpha = 0.01) out &lt;- ode(N0, t, dlogistic, p, method=&quot;euler&quot;) n &lt;- out[901:1000, 2] ntp1 &lt;- n[-1] nt &lt;- n[-length(n)] qplot(nt, ntp1, geom=c(&quot;point&quot;, &quot;path&quot;) ) + labs(y=&quot;N[t+1]&quot;, x=&quot;N[t]&quot;) Figure 5.15: A chaotic discrete logistic population shows certain highly predictable patterns including population sizes limited to a quadratic form revealed here. In general, we can describe many characteristics of populations, even if we cannot predict exactly what the population size will be five years hence. For instance, we can describe the shape of density dependence (linear, nonlinear), and characteristics of \\(N\\), such as the average, the variance, the periodicity, the upper and lower bounds, and the color (i.e. degree of temporal auto-correlation). Indeed, these characteristics may vary among types of organisms, body sizes, or environments. 5.4.2.1 Ricker and more There are many more models of density dependent growth. Some, like the theta-logistic and the Richards models, are more flexible and have more parameters. Others, like the Gompertz model, are used more widely in other fields, such as cancer research for tumor growth, von Bertalanffy for body size growth, and the Ricker model for fisheries. The Ricker model looks a lot like our friend, exponential growth, but where \\(r\\) is modified by density. Here we see them side by side. \\[\\begin{equation} N_{t+1} = N_t e^{r} \\quad ; \\quad N_{t+1}=N_t e^{r_d \\left(1-N_t/K\\right)} \\end{equation}\\] Like discrete logistic growth, the Ricker model41 will also exhibit chaos at high per capita growth rates (\\(r_d&gt;&gt;1\\)). 5.5 Maximum Sustained Yield The classical model of harvesting fisheries and wildlife populations is based on a particular conceptualization of maximum sustained yield (MSY). Maximum sustained yield is historically defined as the population size where both population growth rate and harvest rate are at a maximum. For the logistic growth model, this is half the carrying capacity. We can solve this by finding the maximum of the production function. To do this we use calculus (differentiation) to find where the slope of the production function equals zero. Starting with the partial derivative with respect to \\(N\\) (eq. (5.3)), we solve for zero. \\[\\begin{align} \\tag{5.11} 0 &amp;= r - 2r\\alpha N\\\\ N &amp;= \\frac{r}{2r\\alpha} = \\frac{K}{2} \\end{align}\\] Similarly, we could determine this peak for the \\(\\theta\\)-logistic model as well. \\[\\begin{align} \\tag{5.12} \\frac{\\partial \\dot{N}}{\\partial N} &amp;=r - \\left(\\theta+1\\right)r\\left(\\alpha N\\right)^\\theta\\\\ 0 &amp;= \\frac{K}{\\left(\\theta+1\\right)^{1/\\theta}} \\end{align}\\] When \\(\\theta=1\\), this reduces to \\(K/2\\), as for the logistic model. As we saw above, \\(\\theta &lt; 1\\) causes this value to be less than \\(K/2\\). Even if we assume the logistic model is appropriate for a given population, harvests in practice seldom reduce populations to \\(K/2\\), because often \\(N\\) and \\(K\\) vary with time and are difficult to estimate. Moreover, economic forces often lead to over-harvesting. More contemporary models of harvesting incorporate these concepts (Roughgarden and Smith 1996) but still may not prevent fisheries collapse driven by social and political pressures. We should note that when more detailed information is available on age- or stage-specific survivorship and reproduction, age- or stage-structured models of harvesting are the preferred method (e.g., Chapter 2). For many populations, such as marine fisheries, however, data are often available only on stock size (\\(N\\)) and total catch (\\(H\\)). In some fisheries models, the total catch is fixed and does not vary with \\(N\\). This leads to highly unstable population dynamics and fortunately is no longer practiced in most fisheries. Usually the total catch \\(H\\) is modeled as a function of \\(N\\). Let us assume that total catch or harvest, \\(H\\), is a simple linear function of \\(N\\); the total harvest rate \\(FN\\) is usually described this way.42 In this case, a maximum sustained yield can be determined from the logistic growth-harvest model. This basic model is then \\[\\begin{align} \\tag{5.13} \\frac{dN}{dt}&amp;=rN(1-\\frac{N}{K})-FN \\end{align}\\] where \\(FN=H\\) harvest rate, and \\(F\\) is the per capita fishing mortality rate. Here we assume a fixed per capita catch mortality \\(F\\) so that total harvest is \\(H=F\\times N\\). Maximum sustained yield should then occur at \\(K/2\\) (Fig. 5.16). Therefore would like to know the value of \\(F\\) for which a new \\(N^* = K/2\\) rather than \\(K\\). We can determine the value of \\(F\\) for which this is true by finding when \\(dN/dt=0\\) and \\(N=K/2\\). \\[\\begin{align} 0 &amp;= r\\frac{K}{2}\\left(1-\\frac{\\frac{K}{2}}{K}\\right)-F\\frac{K}{2}\\\\ F &amp;= \\frac{r}{2} \\tag{5.14} \\end{align}\\] pgrlog &lt;- function(N, r, alpha){ r*N*(1-alpha*N) } r &lt;- 0.5; alpha &lt;- 0.01 myData &lt;- data.frame( N=c(0, 110) ) # ggplot requires a data frame p &lt;- ggplot(data=myData, aes(x=N)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=pgrlog, geom=&quot;line&quot;, n=1001, args=list(r=r, alpha = alpha)) + labs(y=&quot;Population growth rate (dN/dt)&quot;, x=&quot;Population size (N)&quot;) + geom_abline(intercept=0, slope=r/2, lty=2) + ylim(c(-5, 15)) p pgrH &lt;- function(N, r, alpha, f){ r*N*(1-alpha*N) - f*N } f &lt;- r/2 myData2 &lt;- data.frame( N=c(0, 60) ) # ggplot requires a data frame h &lt;- ggplot(data=myData2, aes(x=N)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=pgrH, geom=&quot;line&quot;, n=1001, args=list(r=r, alpha = alpha, f = f)) + labs(y=&quot;PGR w/ harvesting (dN/dt)&quot;, x=&quot;Population size (N)&quot;) + ylim(c(-5, 15)) h Figure 5.16: To find the predicted population growth rate with harvesting, we start with Logistic growth rate (solid line) and then substract harvest rate (dashed line). If harvesting occurs at a rate of \\(F&lt;r/2\\), the slope of the harvest line is shallower than in Fig. 5.16, and we refer to this as under-harvesting. If the rate is \\(F&gt;r/2\\), then the slope is steeper than in Fig. 5.16, and we refer to this as over-harvesting. Roughgarden and Smith (1996) show that under-harvesting is the most ecologically stable, whereas over-harvesting is frequently thought to be the economically optimal approach if we don’t care about the long-term wellbeing of the fishing industry. Typically the economically optimal approach leads to over-harvesting because the marginal income on a fishery is related to the interest rate on invested income, \\(F= (r + \\rho)/2\\), where \\(\\rho\\) is the interest rate (usually \\(\\rho\\) is set to 0.05). We can substitute this into eq. (5.13) and solve for \\(N\\) (ignoring \\(N=0\\)). \\[\\begin{align*} \\tag{5.15} 0&amp;=rN(1-\\frac{N}{K})-\\frac{r + \\rho}{2}N\\\\ N\\frac{r}{K}&amp;=r -\\frac{r}{2} -\\frac{\\rho}{2}\\\\ N &amp;=\\frac{K}{2}\\left(1-\\frac{\\rho}{r}\\right) \\end{align*}\\] Thus, unless \\(\\rho=0\\), the typical economic optimum \\(N_{e}^*\\) will be smaller than \\(N*=K/2\\). This makes intuitive economic sense if we consider income from invested profits. The margin of error, however, is much smaller, putting the fisheries population, and the investment of fishing fleets and associated econmoies at greater risk. Roughgarden and Smith (1996) showed that ecological stability of a fishery is likely to beget economic and cultural stability. They show that the supposed “economic optimal” harvesting rate was so low that it increased the extinction risk of the harvested population to unacceptably high levels. The collapse of a fishery is, of course, both economically and culturally devastating. References "],
["meta.html", "6 Populations in Space 6.1 Source-sink Dynamics 6.2 Metapopulations 6.3 Hanski’s incidence function", " 6 Populations in Space Figure 6.1: A frequency distribution of the number of plant species (y-axis) that occupy different numbers of grassland remnants (x-axis). Note the U-shaped (bimodal) distribution of the number of sites occupied. Other years were similar (Collins and Glenn 1991). Over relatively large spatial scales, it is not unusual to have some species that seem to occur everywhere, and many species that are found in only one or a few locations. For example, Scott Collins and Susan Glenn (Collins and Glenn 1991) showed that in grasslands, each separated by up to 4\\(\\,\\)km, there were more species occupying only one site (Fig. 6.1, left-most bar) than two or more sites, and also that there are more species occupying all the sites than most intermediate numbers of sites (Fig. 6.1, right-most bar), resulting in a U-shaped frequency distribution. Illke Hanski (Hanski 1982) coined the rare and common species “satellite” and “core” species, respectively, and proposed an explanation. Part of the answer seems to come from the effects of immigration and emigration in a spatial context. In this chapter we explore mathematical representations of individuals and populations in space, and we investigate the consequences for populations and collections of populations. 6.1 Source-sink Dynamics In Chapters 3-5, we considered closed populations. In contrast, one could imagine a population governed by births plus immigration, and deaths plus emigration (a BIDE model). Ron Pulliam (Pulliam 1988) proposed a simple model that includes all four components of BIDE which provides a foundation for thinking about connected subpopulations. We refer to the dynamics of these as source-sink models. Examples include subpopulations of birds inhabit low quality forest patches only because of immigration from high quality forest patches (Robinson et al. 1995), or understory palms that inhabitat distinct microhabitats in which seeds move from high to low quality patches (Berry et al. 2008). Figure 6.2: The simplest source-sink model, where m21 &gt; m12 so that net movement of individuals is from the source to the sink. begins with the assumption that spatially separated subpopulations occupy distinct patches, which each exhibit their own intrinisic dynamics due to births and deaths (Fig. 6.2). We can characterize each subpopulation with its own population growth rate, \\(\\lambda_i\\). In addition, individuals migrate between patches. Therefore, the number of individuals we observe in a particular patch is due to both internal dynamics of births and deaths, and also migration. Source populations are those with more births than deaths (\\(\\lambda &gt; 1\\)) and with more emigration than immigration. Sink populations are those with fewer births than deaths (\\(\\lambda &lt; 1\\)) and with more immigration than emigration. When we consider causes of variation in \\(\\lambda\\), we often refer to the quality of patches or habitats. High quality patches have are those with high growth rates (\\(\\lambda&gt;1\\)), whereas low quality patches are those with low growth rates (\\(\\lambda &lt; 1\\)). We might also study factors associated with growth rate, such as the frequency of nesting sites, predator densities, or soil fertility, factors which we predict would regulate growth rates. Pulliam envisioned two linked bird populations where we track adult reproduction, adult and juvenile survival, and estimate \\(\\lambda_i\\) separately for each population. The size of the source population, at time \\(t+1\\) is \\(n_{1,t+1}\\) and is the result of survival and fecundity. Adult survival \\(P_A\\) and fecundity results from reproduction, \\(\\beta_1 n_{1,t}\\), times survival of the juveniles \\(P_J\\). The sink population was modeled the same way. \\[\\begin{align} \\tag{6.1} n_{1, t+1} = P_A n_{1,t} + P_J (\\beta_1 n_{1,t}) = \\lambda_1 n_1\\\\ n_{2, t+1} = P_A n_{2,t} + \\beta_2 P_J n_{1,t} = \\lambda_2 n_2 \\end{align}\\] Pulliam then assumed that the two populations vary only in fecundity (\\(\\beta\\)), which created differences in growth rates, such that \\(\\lambda_1 &gt; 1 &gt; \\lambda_2\\). birds in excess of the number of territories in the source population emigrated from the source habitat to the sink habitat, \\(m_{21} = \\lambda_1 - 1\\). These assumptions result in the source population maintaining a constant density, while all the excess fecundity migrates to the sink population. We can use a matrix model to investigate source-sink populations (e.g., Berry et al. 2008). We place each rate in the respective element in a two-stage matrix model. We assume a pre-breeding census, in which we count only adults. The population dynamics would thus be governed by . \\[\\begin{equation} \\tag{6.2} \\mathbf{A} = \\left( \\begin{array}{cccc} P_{A1} + P_{J1}\\beta_1 &amp; M_{12} \\\\ M_{21} &amp; P_{A2} +P_{J2}\\beta_2 \\end{array} \\right) \\end{equation}\\] where the upper left element (row 1, column 1) reflects the within-patch growth characteristics for patch 1. The lower right quadrant (row 2, and column 2) reflects the within-patch growth characteristics of patch 2. Source-sink models assume net migration flows from the source to the sink (\\(M_{21}&gt;M_{12}\\)). We will assume, for simplicity, that migration is exclusively from the source to the sink (\\(M_{21}&gt;0\\), \\(M_{12}=0\\)). We further assume that \\(\\lambda_1 &gt; 1\\) but all excess individuals migrate to patch 2, so \\(M_{21} = \\lambda_1 - 1&gt;0\\). Then simplifies to \\[\\begin{equation} \\tag{6.3} \\mathbf{A} = \\left( \\begin{array}{cccc} 1 &amp; 0 \\\\ \\lambda_1-1 &amp; \\lambda_2 \\\\ \\end{array} \\right) \\end{equation}\\] We first assign \\(\\lambda\\) for the source and sink populations, and create a matrix. lambda1 &lt;- 1.2; lambda2 &lt;- .4 A &lt;- matrix(c(1, 0, lambda1-1, lambda2), nrow=2, byrow=TRUE) A ## [,1] [,2] ## [1,] 1.0 0.0 ## [2,] 0.2 0.4 We can then use eigenanalysis, as we did in Chapter 4 for stage structured populations. The dominant eigenvalue will provide the long term asymptotic total population growth. We can calculate the stable stage distribution, which in this case is the distribution of individuals between the two habitats. eA &lt;- eigen(A) eA$values ## [1] 1.0 0.4 # calculate the stable stage distr. (ssd &lt;- eA$vectors[,1]/sum(eA$vectors[,1]) ) ## [1] 0.75 0.25 From the dominant eigenvalue, we see Pulliam’s working assumption that the total population growth (for the two popuations combined) is \\(\\lambda=1\\). Upon calculating the stable distribution, we also see that the source population contains more individuals than the sink population. Pulliam explored the consequences of these assumptions for the relative abundances in the two populations. He varied \\(\\lambda_1\\) over a range of values and calculated the relative abundance of the source population. We let p1 be the proportion of the total population in the source. # a range of lambdas lambda1 &lt;- seq(1, 3, by=0.01) # proportion of total N in the source habitat p1 &lt;- sapply(lambda1, function(l1) { # replace lambda1 A[2,1] &lt;- l1-1 # extract the dominant eigenvalue dom.ev &lt;- eigen(A)$vectors[,1] # calculate the relative abundance of the first pop. dom.ev[1]/sum(dom.ev) }) # plot the result qplot(x=lambda1, y=p1, geom=&quot;line&quot;, ylab=&quot;Fraction of total population\\n in the source population&quot;, xlab=expression(lambda[1]) ) Figure 6.3: The declining relative abundance in the high quality habitat in a source-sink model. The proportion of the total population (\\(n_1/(n_1+n_2)\\)) in the source population may decline with increasing habitat quality and growth rate. One of his main theoretical findings was that relative abundance and population density can be misleading indicators of habitat quality (Fig. 6.3). If we assume that excess individuals in the source migrate to the sink, then as habitat quality and reproduction increase in the source population, the source population comprises an ever decreasing proportion of the total population! That is, as \\(\\lambda_1\\) gets larger, \\(n_1/(n_1+n_2)\\) gets smaller. Thus, density can be a very misleading predictor of long-term population viability, if the source population is both productive and exhibits a high degree of emigration. 6.1.1 Complications and cases are special cases with counterintuitive dynamics. Pseudosinks are patches in which immigration is so high that it pushes the subpopulation over its carrying capacity and depresses growth rates (e.g., Breininger and Oddy 2004). In the absence of immigration, population growth rates would sustain the population (\\(\\lambda &gt; 1\\)). Ecological traps are habitats that are preferred by animals, but are actually low quality (\\(\\lambda &lt; 1\\)). These can occur, espcially in the face of human-induced rapid environmental change. In many cases, there is a mismatch between sensory traits of organisms and novel environments (Robertson, Rehage, and Sih 2013). Like a moth to a flame, as it were. of individuals among patches. For both types, we assume that the quality of unoccupied habitats varies among patches. We also assume that individuals have negative effects on quality, for example, through territory occupation or resource use. This means that current habitat quality depends on the original quality of unoccupied habitat and the also the number of occupants. An ideal free distribution of individuals among patches results when individuals distribute themselves in perfect proportion to habitat quality. The net result is that all current patches have equal quality because high quality patches suffer from proportionally more individuals. In contrast, an ideal despotic distribution arises when individuals always prefer habitat that has higher original quality, until the habitat is full, at which point they use low quality habitat. This is thought to occur where animals are territorial, and prefer the better habitat as long as there is a single territory available. arises when migration occurs at similar rates among patches of similar quality (\\(\\lambda \\approx 1\\)) but where patches vary in size and population size. This results in the unexpected obervation that migration for small patches with few individuals into large patches occurs nearly as often as the reverse. This means that per capita emigration rates are higher for small patches than large patches. It is not clear why this occurs, but it could could occur if the higher edge:area ratio of smaller patches boosts migration rate (Hambäack et al. 2007) and the evolution of dispersal characteristics in populations of different sizes (Legrand et al., n.d.; McPeek and Holt 1992). 6.2 Metapopulations The logistic model (Chapter 5) is all well and good, but it has no concept of space built into it. In many, and perhaps most circumstances in ecology, space has the potential to influence the dynamics of populations and ecosystem fluxes (Lehman and Tilman 1997; Leibold et al. 2004; Loreau, Mouquet, and Holt 2003). The logistic equation represents a closed population, with no clear accounting for emigration or immigration. In particular cases, however, consideration of space may be essential. What will we learn if we start considering space, such that sites are open to receive immigrants and lose emigrants? Figure 6.4: Collections of sites, where each site (A-F) may be a spot of ground potentially occupied by a single plant, or it may be an oceanic island potentially occupied by a butterfly population. Sites may also be colonized via both internal and external sources. (Fig. 6.4). Modeling metapopulations emerged from work in pest management when Levins (1969) wanted to represent the dynamics of the proportion of fields infested by a pest. He assumed that a field was either occupied by the pest, or not. In this framework, we keep track of the proportion of all populations that remain occupied. He assumed that the metapopulation is closed, in the sense that all migration occurs there exists a finite number of sites which may exchange migrants. Whether we consider a single spatial population, or single metapopulation, we can envision a collection of sites connected by dispersal. Each site may be a small spot of ground that is occupied by a plant, or it may be an oceanic island that is occupied by a population. All we know about a single site is that it is occupied or unoccupied. If the site is occupied by an individual, we know nothing of how big that individual is; if the site is occupied by a population, we know nothing about how many indiviuals are present. The models we derive below keep track of the proportion of sites that are occupied. These are known loosely as metapopulation models. Although some details can differ, whether we are modeling a collection of spatially discrete individuals in single population or a collection of spatially discrete populations, these two cases share the idea that there are a collection of sites connected by migration, and each is subject to extinction. The most relevant underlying biology concerns colonization and extinction in our collection of sites (Fig. 6.4). In this chapter, we will assume that all sites experience equal rates. In the one model, we assume that the collection of sites receives propagules from the outside, from some external source that is not influenced by the collection of sites (Fig. 6.4). In all cases, we will consider how total rates of colonization, \\(C\\), and extinction, \\(E\\), influence the the rate of change of \\(p\\), the proportion of sites that are occupied, \\[\\frac{dp}{dt}=C-E.\\] We will consider below, in a somewhat orderly fashion, several permutations of how we represent colonization and extinction of sites (Gotelli and Kelley 1993; Gotelli 1991). 6.2.1 The classic Levins model Levins (1969) proposed what has become the classic metapopulation model, \\[\\begin{equation} \\label{eq:intcol} \\frac{dp}{dt} = c_{i}p\\left(1-p\\right) - ep \\end{equation}\\] This equation describes the dynamics of the proportion, \\(p\\), of a set of fields invaded by a pest. The pest colonizes different fields at a total rate governed by the rate of propagule production, \\(c_i\\), and also on the proportion of patches that contain the pest, \\(p\\). Thus, propagules are being scattered around the landscape at rate \\(c_i p\\). We use the subscript \\(i\\) to remind us that the colonization is coming from within the sites that we are studying (i.e. internal colonization). The rate at which \\(p\\) changes is also related to the proportion of fields that are unoccupied, \\((1-p)\\), and are therefore available to become occupied and increase \\(p\\). The total rate of colonization is \\(c_ip(1-p)\\). The pest has a constant local extinction rate \\(e\\), so the total extinction rate in the landscape is \\(ep\\). The parameters \\(c_i\\) and \\(e\\) are very similar to \\(r\\) of continuous logistic growth, insofar as they are dimensionless instantaneous rates. However, they are sometimes thought of as probabilities. The parameter \\(c_i\\) is approximately the proportion of open sites colonized per unit time. For instance, if we created or found 100 open sites, we could come back in a year and see how many became occupied over that time interval of one year, and that proportion would be a function of \\(c_i\\). The parameter \\(e\\) is often thought of as the probability that a site becomes unoccupied per unit time. If we found 100 occupied sites in one year, we could revisit them a year later and see how many became *un}occupied over that time interval of one year. With internal colonization, we are modeling a closed spatial population of sites, whether “site” refers to an entire field (as above), or a small patch of ground occupied by an individual plant (Tilman et al. 1994). An R function for a differential equation requires arguments for time, a vector of the state variables (here we have one state variable, \\(p\\)), and a vector of parameters. levins &lt;- function(t, y, parms) { p &lt;- y[1] with(as.list(parms), { dp &lt;- ci * p * (1-p) - e * p return(list(dp)) }) } By using with, we can specify the parameters by their names, as long as parms includes names. The function levins() returns a list that contains a value for the derivative, evaluated at each time point, for each state variable (here merely \\(dp /dt\\)). We then use levins in the numerical integration function ode in the deSolve package. prms &lt;- c(ci=0.15, e=0.05) Initial.p &lt;- 0.01 out.L &lt;- data.frame(ode(y=Initial.p, times=1:100, func=levins, parms=prms )) We then plot the result (Fig. 6.5). qplot(x=out.L[,1], y=out.L[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 25, .75, label=bquote(over(dp,dt)==cp(1-p)-ep)) Figure 6.5: Levins metapopulation model Can we use this model to predict the eventual equilibrium? Sure — we just set (??) to zero and solve for \\(p\\). This model achieves and equilibrium at, \\[\\begin{align*} \\tag{6.4} 0 &amp;=c_{i}p-c_{i}p^2 - ep\\\\ p^* &amp;= \\frac{c_{i}-e}{c_{i}}=1-\\frac{e}{c_{i}}. \\end{align*}\\] When we do this, we see that \\(p^* &gt; 0\\) as long as \\(c_i &gt; e\\) (e.g., Fig. 6.5). When is \\(p^* = 1\\), so that all the sites are filled? In principle, all sites cannot be occupied simultaneously unless \\(e=0\\). 6.2.2 Propagule rain From where else might propagules come? If a site is not closed off from the rest of the world, propagules could come from outside the collection of sites that we are actually monitoring. For now, let us assume that our collection of sites is continually showered by propagules from an external source. If only those propagules are important, then we could represent the dynamics as, \\[\\begin{equation} \\tag{6.5} \\frac{dp}{dt} = c_{e}\\left(1-p\\right) - ep \\end{equation}\\] where \\(c_{e}\\) specifies the rate of colonization coming from the external source. Gotelli (1991) refers to this model as a metapopulation model with propagule rain, or as the island–mainland model. He calls it this because it describes a constant influx of propagules which does not depend on the proportion, \\(p\\), of sites occupied for propagule production. Extinction here is mediated only by the proportion of sites occupied, and has a constant per site rate. An R function for a differential equation requires arguments for time, a vector of the state variables (here we have one state variable, \\(p\\)), and a vector of parameters. gotelli &lt;- function( t, y, parms) { p &lt;- y[1] with(as.list(parms), { dp &lt;- ce * (1-p) - e * p return(list(dp)) }) } prms &lt;- c(ce=0.15, e=0.05) Initial.p &lt;- 0.01 out.G &lt;- data.frame(ode(y=Initial.p, times=1:100, func=gotelli, parms=prms )) We then plot the result (Fig. 6.6). qplot(x=out.G[,1], y=out.G[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 50, .25, label=bquote(over(dp,dt)==c[e](1-p)-ep)) Figure 6.6: Propagule rain metapopulation model We can solve for this model’s equilibrium by setting eq. equal to zero. \\[\\begin{align*} 0 &amp;= c_{e}-c_{e}p - ep\\\\ p^*&amp;=\\frac{c_{e}}{c_{e}+e}. \\end{align*}\\] Of course, we might also think that both internal and external sources are important, in which case we might want to include both sources in our model, \\[\\begin{align} \\label{eq:genmod} \\frac{dp}{dt} &amp;= (c_{i}p+c_{e})\\left(1-p\\right) - ep \\end{align}\\] As we have seen before, however, adding more parameters is not something we take lightly. Increasing the number of parameters by 50% could require a lot more effort to estimate. 6.2.3 The rescue effect and the core-satellite model Thus far, we have ignored what happens between census periods. Imagine that we sample site “A” each year on 1 January. It is possible that between 2 January and 31 December the population at site A becomes extinct and then is subsequently recolonized, or “rescued” from extinction. When we sample on 1 January in the next year, we have no way of knowing what has happened in the intervening time period. We would not realize that the population had become extinct and recolonization had occurred. We can, however, model total extinction rate \\(E\\) with this rescue effect, \\[\\begin{equation} \\tag{6.6} E = - ep\\left( 1-p \\right). \\end{equation}\\] Note that as \\(p \\rightarrow 1\\), the total extinction rate approaches zero. Total extinction rate declines because as the proportion of sites occupied increases, it becomes increasingly likely that dispersing propagules will land on all sites. When propagules happen to land on sites that are on the verge of extinction, they can ``rescue’’ that site from extinction. Brown and Kodric-Brown (1977) found that enhanced opportunity for immigration seemed to reduce extinction rates in arthropod communities on thistles. They coined this effect of immigration on extinction as the rescue effect. MacArthur and Wilson (1963) also discussed this idea in the context of island biogeography. We can even vary the strength of this effect by adding yet another parameter \\(q\\), such that the total extinction rate is \\(-ep\\left( 1-qp \\right)\\) (Gotelli and Kelley 1993). Assuming only internal propagule supply and the simple rescue effect results in what is referred to as the the core-satellite model, \\[\\begin{align} \\tag{6.7} \\frac{dp}{dt} &amp;= c_ip\\left(1-p\\right) - ep\\left( 1-p \\right) \\end{align}\\] This model was made famous by Illka Hanski (Hanski 1982). It is referred to as the core-satellite model because Hanski showed that it predicts precisely the pattern we saw in Fig. 6.1 at the beginning of the chapter. A function for a differential equation requires arguments for time, a vector of the state variables (here we have one state variable, \\(p\\)), and a vector of parameters. hanski &lt;- function( t, y, parms) { p&lt;- y[1] with(as.list(parms), { dp &lt;- ci * p * (1-p) - e * p *(1-p) return(list(dp)) }) } prms &lt;- c(ci=0.15, e=0.05) Initial.p &lt;- 0.01 out.H &lt;- data.frame(ode(y=Initial.p, times=1:100, func=hanski, parms=prms )) We then plot the result (Fig. 6.7). qplot(x=out.H[,1], y=out.H[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 50, .25, label=bquote(over(dp,dt)==c[i]*p(1-p)-ep(1-p))) Figure 6.7: The core-satellite metapopulation model. What is the equilibrium for the Hanski model (6.7)? We can rearrange this to further simplify solving for \\(p^*\\). \\[\\begin{align} \\label{eq:CoreSat2} \\frac{dp}{dt} &amp;= \\left(c_i-e \\right) p \\left(1-p\\right) \\end{align}\\] This shows us that for any value of \\(p\\) between zero and one, the sign of the growth rate (positive or negative) is determined by \\(c_i\\) and \\(e\\). If \\(c_i&gt;e\\), the rate of increase will always be positive, and because occupancy cannot exceed 1.0, the metapopulation will go to full occupancy (\\(p^*=1\\)), and stay there. This equilibrium will be a stable attractor or stable equilibrium. What happens if for some reason the metapopulation becomes globally extinct, such that \\(p=0\\), even though \\(c_i&gt;e\\)? If \\(p=0\\), then like logistic growth, the metapopulation stops changing and cannot increase. However, the slightest perturbation away from \\(p=0\\) will lead to a positive growth rate, and increase toward the stable attractor, \\(p^*=1\\). In this case, we refer to \\(p^*=0\\) as an unstable equilibrium and a repellor. Let’s explore the stability of these equilibria by plotting the metapopulation growth rate as a function of \\(p\\) (Fig. 6.8). When we set \\(c_i&gt;e\\), and examine the slope of that line at \\(p^*=1\\), we see the slope is negative, indicating a stable equilibrium. At \\(p^*=0\\) the slope is positive, indicating an unstable equilibrium. dpdtCS &lt;- expression((ci-e)*p*(1-p)) ci &lt;- 0.15; e &lt;- 0.05 p &lt;- seq(0,1, length=50) dp.dt &lt;- eval(dpdtCS) qplot(p, dp.dt, geom=&quot;line&quot;, ylab=&quot;dp/dt&quot;) Figure 6.8: Metapopulation growth rate as a function of \\(p\\), in the core-satellite model when \\(c_i &gt; e\\). We see that growth rate falls to zero at full occupancy (i.e., at \\(p^*=1\\)). At that point, the slope is negative, indicating that this equilibrium is stable. If \\(c_i&lt;e\\), the rate of increase will always be negative, and because occupancy cannot be less than 0, the metapopulation will become extinct (\\(p^*=0\\)), and stay there. Thus \\(p^*=0\\) would be a stable equilibrium or attractor. What is predicted to happen if, for some odd reason this population achieved full occupancy, \\(p=1\\), even though \\(c_i&lt;e\\)? In that case, \\((1-p)=0\\), and the rate of change goes to zero, and the population is predicted to stay there, even though extinction is greater than colonization. How weird is that? Is this fatal flaw in the model, or an interesting prediction resulting from a thorough examination of the model? How relevant is it? How could we evaluate how relevant it is? We will discuss this a little more below, when we discuss the effects of habitat destruction. What happens when \\(c_i=e\\)? In that case, \\(c_i - e = 0\\), and the population stops changing. What is the value of \\(p\\) when it stops changing? It seems as though it could be any value of \\(p\\), because if \\(c_i-e=0\\), the rate change goes to zero. What will happen if the population gets perturbed — will it return to its previous value? Let’s return to question in a bit. To analyze stability in logistic growth, we examined the slope of the partial derivative at the equilibrium, and we can do that here. We find that the partial derivative of (6.7) with respect to \\(p\\) is \\[\\begin{equation} \\label{eq:CoreSatPD1} \\frac{\\partial \\dot{p}}{\\partial p} = c - 2cp - e + 2ep \\end{equation}\\] where \\(\\dot{p}\\) is the time derivative (6.7). A little puzzling and rearranging will show \\[\\begin{equation} \\label{eq:CoreSatPD2} \\frac{\\partial \\dot{p}}{\\partial p} = \\left(c_i - e\\right)\\left(1-2p\\right) \\end{equation}\\] and make things simpler. Recall our rules with regard to stability (Chapter 5). If the partial derivative (the slope of the time derivative) is negative at an equilibrium, it means the the growth rate approaches zero following a perturbation, meaning that it is stable. If the partial derivative is positive, it means that the change accelerates away from zero following the perturbation, meaning that the equilibrium is unstable. So, we find the following guidelines: What if \\(c_i=e\\)? In that case, both the time derivative (\\(d p / dt\\)) and the partial derivative (\\(\\partial \\dot{p}/ \\partial p\\)) are zero for all values of p. Therefore, if the population gets displaced from any arbitrary point, it will remain unchanged, not recover, and will stay displaced. We call this odd state of affairs a neutral equilibrium. We revisit neutral equilibrium when we discuss interspecific competition and predation. 6.2.4 Parallels with Logistic Growth It may have already occurred to you that the closed spatial population described here sounds a lot like simple logistic growth. A closed population, spatial or not, reproduces in proportion to its density, and is limited by its own density. Here we will make the connection a little more clear. It turns out that a simple rearrangement of (??) will provide the explicit connection between logistic growth and the spatial population model with internal colonization (Roughgarden 1998). Imagine for a moment that you are an avid birder following a population of Song Sparrows in Darrtown, OH, USA (Ch. 5). If Song Sparrows are limited by the number of territories, and males are competing for territories, then you could think about male Song Sparrows as ``filling up’’ some proportion, \\(p\\), of the available habitat. Each territory is thus like a local population, but where a pair of sparrows either occupies a site, or not, and the proportion of all territories that are occupied is \\(p\\). You therefore decide that you would like to use Levins’ spatially-implicit metapopulation model instead (??). How will you do it? You do it by rescaling logistic growth, \\(dN/dt = rN(1-\\alpha N)\\). Let us start by defining our logistic model variables in other terms. First we define \\(N\\) as \\[\\begin{equation*} N=Hp \\end{equation*}\\] where \\(N\\) is the number of males defending territories, \\(H\\) is the total number of possible territories, and \\(p\\) is the proportion of possible territories occupied at any one time. At equilibrium, \\(N^*=K=Hp^*\\), and \\(\\alpha=1/(Hp^*)\\). Recall that for the Levins model, \\(p^*=(c_i-e)/c_i\\), so therefore, \\[\\alpha = \\frac{c_i}{H\\left(c_i - e\\right)}\\] We now have \\(N\\), \\(\\alpha\\), and \\(K\\) in terms of \\(p\\), \\(H\\), \\(c_i\\) and \\(e\\), so what about \\(r\\)? Recall that for logistic growth, the per capita growth rate goes to \\(r\\) as \\(N \\to 0\\) (Chapter 3). For the Levins metapopulation model, the per patch growth rate is \\[\\begin{align} \\frac{1}{p}\\frac{dp}{dt}&amp;=c_{i}\\left(1-p\\right) - e. \\end{align}\\] As \\(p \\to 0\\) this expression simplifies to \\(c_i-e\\), which is equivalent to \\(r\\). Summarizing, then, we have, \\[\\begin{gather} \\label{eq:5} r=c_i-e\\\\ N=Hp\\\\ \\alpha = \\frac{1}{K} = \\frac{1}{Hp^*} = \\frac{c_i}{H\\left(c_i-e\\right)} \\end{gather}\\] Substituting into logistic growth (\\(\\dot{N} = rN(1-\\alpha N)\\)), we now have \\[\\begin{align} \\tag{6.8} \\frac{d(pH)}{dt} &amp;= \\left(c_i-e\\right)pH\\left(1-\\frac{c_i}{H\\left(c_i-e\\right)}Hp\\right)\\\\ &amp;= \\left(c_i-e\\right)pH - \\frac{ c_i-e }{c_i-e}c_ip^2H\\\\ &amp;= H\\left(c_ip\\left(1-p\\right) - ep \\right) \\end{align}\\] which is almost the Levins model. If we note that \\(H\\) is a constant, we realize that we can divide both sides by \\(H\\), ending up with the Levins model (??). 6.2.5 Levins \\(vs\\). Hanski Why would we use Levins’ model instead of Hanski’s core-satellite model? To explore this possibility, let’s see how the Hanski model might change gradually into the Levins model. First we define the Hanski model with an extra parameter, \\(a\\), \\[\\begin{equation} \\label{eq:7} \\frac{p}{dt} = c_ip\\left(1-p\\right) - ep\\left(1-ap\\right). \\end{equation}\\] Under Hanski’s model, \\(a=1\\) and under Levins’ model \\(a=0\\). If we solve for the equilibrium, we see that \\[\\begin{equation} \\label{eq:8hanski} p^*=\\frac{c-e}{c-ae} \\end{equation}\\] so that we can derive either result for the two models. In the context of logistic growth, where \\(K=Hp^*\\), this result (??) implies that for the Hanski model, \\(K\\) fills all available habitat, whereas the Levins model implies that \\(K\\) fills only a fraction of the total available habitat. That fraction results from the dynamic balance between \\(c_i\\) and \\(e\\). 6.2.6 Habitat Destruction Other researchers have investigated effects of habitat loss on metapopulation dynamics (Kareiva and Wennergren 1995; Nee and May 1992; Tilman et al. 1994). Taking inspiration from the work of Lande (Lande 1987, 1988), Kareiva and Wennergren (1995) modeled the effect of habitat destruction, \\(D\\), on overall immigration probability. They incorporated this into Levins’ model as \\[\\begin{equation} \\label{eq:D} \\frac{dp}{dt}=c_ip(1-D-p) - ep \\end{equation}\\] where \\(D\\) is the amount of habitat destroyed, expressed as a fraction of the original total available habitat. To turn eq. (??) into a function we can use with ode, we have, lande &lt;- function(t, y, parms) { with(as.list(c(y,parms)), { dp &lt;- ci * p * (1-D-p) - e * p return(list(dp)) }) } prmsD &lt;- c(ci=0.15, e=0.05, D=.2) Initial.p &lt;- c(p=0.1) out.D &lt;- data.frame(ode(y=Initial.p, times=1:100, func=lande, parms=prmsD )) qplot(x=out.D[,1], y=out.D[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 25, .75, label=bquote( over(dp,dt)==c[i]*p(1-D-p)-ep) ) Figure 6.9: Habitat destruction metapopulation model Habitat destruction, \\(D\\), may vary between 0 (\\(=\\) Levins model) to complete habitat loss 1.0; obviously the most interesting results will come for intermediate values of \\(D\\), which we illustrate next. 6.2.7 Illustrating the effects of habitat destruction We can plot the dynamics for three levels of destruction, starting with none (\\(D=0\\)). We first set all the parameters, and time. t &lt;- 1:200 prmsD &lt;- c(ci=0.15, e=0.05, D=0) Initial.p &lt;- c(p=0.01) t &lt;- 1:200 D0 &lt;- ode(y=Initial.p, times=t, func=lande, parms=prmsD ) prmsD[&quot;D&quot;] &lt;- 0.2 D.2 &lt;- ode(y=Initial.p, times=t, func=lande, parms=prmsD ) prmsD[&quot;D&quot;] &lt;- 0.5 D.5 &lt;- ode(y=Initial.p, times=t, func=lande, parms=prmsD ) ps &lt;- rbind.data.frame(D0, D.2, D.5) ps$D &lt;- as.character( rep(c(0, .2, .5), each=length(t)) ) Last, we plot it and add some useful labels. ggplot(ps, aes(time, p, linetype=D)) + geom_line() Figure 6.10: Three different levels of habitat destruction What is the equilibrium under this model? Setting eq. to zero, we can then solve for \\(p\\). \\[\\begin{gather} \\label{eq:Deq} 0=c_i-c_iD-c_ip - e\\\\ p^* = \\frac{c_i-c_iD - e}{c_i} = 1 - \\frac{e}{c_i} - D \\end{gather}\\] Thus we see that habitat destruction has a simple direct effect on the metapopulation. 6.2.8 Different assumptions lead to different predictions about rates of extinction Let us return now to the case in the core-satellite model where \\(c_i &lt; e\\) and \\(p=1\\). Recall that in this case, \\(p=1\\) is an unstable equilibrium (\\(p=0\\) is the stable equilibrium for \\(c_i&lt;e\\)). Imagine that at one time, a metapopulation is regulated by the mechanisms in the core-satellite model, including the rescue effect, and \\(c_i&gt;e\\). We therefore pretend that, the metapopulation occupies virtually every habitable site (let \\(p=0.999\\)). Now imagine that the environment changes, causing \\(c_i&lt;e\\). Perhaps climate change enhances extinction rates. All of a sudden, our metapopulation is poised near an unstable equilibrium, with \\[p=0.999\\quad ; \\quad c_i &lt; e\\]. What will happen and how might it differ with and without the assumption of the rescue effect? When \\(c_i &gt; e\\), we see that \\(p^*=1\\) is the stable attractor (Fig. 6.11). If extinction rates rise so that \\(c_i &lt; e\\), we see the inevitable march toward extinction predicted by the core-satellite model (Fig. 6.11). The decline starts slowly and remains slow, until it begins to gradually accelerate. Do all metapopulation models make the same predictions? If we try this experiment with the Levins model, we see something very different. The Levins model predicts very rapid decline once \\(c_i &lt; e\\). Both models predict extinction, but the rescue effect delays the appearance of that extinction. It appears that the rescue effect (which is the difference between the two models) may act a bit like the ``extinction debt’’ (Tilman et al. 1994) wherein deterministic extinction of a dominant species in a multi-species community is merely delayed, but not postponed indefinitely. Perhaps populations influenced by the rescue effect might be prone to unexpected collapse, if the only stable equilibria are 1 and 0. Thus simple theory can provide interesting insight, resulting in very different predictions for superficially similar processes. Here we show the unexpected collapse of core populations, starting at or near equilbrium. The first two use the Hanski model, while the third uses Levins. The second and third use \\(c_i &lt; e\\). C1 &lt;- ode(y=c(p=0.999), times=t, func=hanski, parms=c(ci=0.2, e=0.01)) C2 &lt;- ode(y=c(p=0.999), times=t, func=hanski, parms=c(ci=0.2, e=0.25)) L2 &lt;- ode(y=c(p=0.999), times=t, func=levins, parms=c(ci=0.2, e=0.25)) coll &lt;- rbind.data.frame(C1, C2, L2) coll$model &lt;- factor(rep(c(&quot;c&gt;e&quot;, &quot;c&lt;e&quot;, &quot;c&lt;e (Levins)&quot;), each=nrow(L2)), levels=c(&quot;c&gt;e&quot;, &quot;c&lt;e&quot;, &quot;c&lt;e (Levins)&quot;)) ggplot(coll, aes(time, p, linetype=model)) + geom_line() Figure 6.11: Metapopulation dynamics, starting from near equilibrium for \\(c_i=0.20\\) and \\(e=0.01\\). If the environment changes, causing extinction rate to increase until it is greater than colonization rate, we may observe greatly delayed, but inevitable, extinction (e.g., \\(c_i=0.20, e=0.25\\)) 6.3 Hanski’s incidence function The above models of metapopulation dynamics provide an outline for understanding metapopulation dynamics. However, they do not necessarily provide a direct means to interrogate data or use data illuminate our understanding. One of the main reasons for this is that they do not address two important ecological realities: that patches will be differ in area and thus differ in population sizes, and that they are different distances from each other. MacArthur and Wilson (1963) argued persuasively that extinction risk should be related to area, and that distance from a source should influence the probability of colonization. IIkka Hanski (1994) provided an approach using incidence functions, which predict the probability of occurrence. They allow us to incorporate area and distance in our model, and uses easily acquired patch occupancy data (presence/absence data) to evaluate metapopulation characteristics. The incidence of occupancy is determined by colonization and extinction probabilities. We will assume that if a patch \\(i\\) is empty in year \\(t\\), it will be recolonized in year \\(t+1\\) with a probability \\(C_i\\). This also means it will remain empty with probability of \\(1-C_i\\). If a patch \\(j\\) is occupied in year \\(t\\), it will become extinct in year \\(t+1\\) with probability \\(E_i\\). This also means that it will persist with probability \\(1-E_i\\). The two states for one patch are illustrated with the code and figure below. Each column of the matrix is the probabilities for one state. Te first column comprises the probabilities of remaining empty or changing from empty to occupied. The second column comprises the probabilities that an occupied patch becomes empty or remains occupied. C &lt;- .3; E &lt;- .5 M &lt;- matrix(c(1-C, E, C, 1-E), ncol=2, byrow=TRUE) colnames(M) &lt;- rownames(M) &lt;- c(&quot;empty&quot;, &quot;occupied&quot;) M ## empty occupied ## empty 0.7 0.5 ## occupied 0.3 0.5 { plotmat(M, pos=2) #requires the diagram package title(&quot;The two states of one patch&quot;) } The probability, \\(J_i\\), that a patch is occupied at any given time is, \\[J_i = \\frac{C_i}{C_i + E_i}.\\] We can show this by calculating the stable distribution of these states using eigenanalysis in the way we did for demographic matrices. # J (J &lt;- C/(C+E)) ## [1] 0.375 # The stationary distributions for the two states, empty and occupied eM &lt;- eigen(M) eM$vectors[,1]/sum(eM$vectors[,1]) ## [1] 0.625 0.375 We see that \\(J_i\\) is the stable state for being colonized. Extinction probability, \\(E\\), is determined by patch area \\(A_i\\) in our simple model. This is because we will assume that all patches have a similar quality and so support equal densities (individuals per unit area). Larger areas have more individuals and thus have lower risk of extinction. IIkka Hanski (1994) described this mathematically as \\[\\begin{align*} E_i = \\frac{e}{A_i^x} \\quad &amp;\\mathrm{if} A_i &gt; e^{1/x}\\\\ E_i = 1 \\quad &amp;\\mathrm{if} A_i \\le e^{1/x} \\end{align*}\\] where \\(e\\) and \\(x\\) are constants letting \\(E_i\\) vary for different systems. Parameter \\(x\\) controls the effect of area, where larger values \\(x&gt;1\\) mean that large patches have very low extinction risk. Smaller values of \\(x\\) (\\(x&lt;1\\)) mean that patches have to become exceedingly larger to appreciably reduce extinction risk. The parameter \\(e\\) is the area-independent measure of extinction risk, and so is related to intrinsic population dynamics and environmental stochasticity. We can illustrate extinction probability with toy code. # Extinction probability E.p &lt;- function(A, e=0.01, X=1.009){ Ei &lt;- ifelse(A &gt; e^(1/X), e/(A^X), 1) Ei } curve(E.p(x), 0, 0.2, ylim=c(0,1)) Figure 6.12: Extinction probabliity for a butterfly population (silver spotted skipper, Hanski 1994). ## The ggplot way # myData &lt;- data.frame( A=c(0, .2) ) # ggplot requires a data frame # ggplot(data=myData, aes(x=A)) + # set the basic properties of the plot # # in the stat_function, we indicate the parameters in our equation. # stat_function(fun=E.p, geom=&quot;line&quot;, # args=list(e = 0.01, X = 1.009)) Note that \\(A_0 = e^{1/x}\\) is the critical patch size where a population is not expected to persist a year. Colonization probability, \\(C_i\\), is more complicated. It is a function of the number of arriving migrants, which are themselves a function of distances from other patches and the area (and thus population sizes) of those patches. It is \\[C_i = \\frac{1}{1+\\left(\\frac{y^\\prime}{S_i}\\right)^2}\\] where \\(y^\\prime\\) is colonizing ability of the species, and \\(S_i\\) can be thought of as a measure of isolation of patch \\(i\\) from the rest of the patches. Formally, this is \\[S_i = \\sum_{j=1}^n\\left(p_j \\mathrm{exp}(-\\alpha d_{ij}) A_j\\right)\\] where there are a total \\(n\\) other patches \\(j\\) that are habitats, \\(p_j\\) is an indicator of whether a patch is currently occupied (0,1), \\(d_{ij}\\) is the distance from patch \\(j\\) to patch \\(i\\), \\(\\alpha\\) is the effect of distance, and \\(A_j\\) is the area of patch \\(j\\) and thus an index of population size. We can illustrate extinction probability with toy code. # Colonization probability from one patch to another, as a function of distance C.p &lt;- function(d, yprime, alpha, area){ Sij &lt;- exp(-alpha*d ) * area Ci &lt;- 1/(1 + (yprime/Sij)^2 ) Ci } # parameters yprime &lt;- 2.663; ha &lt;- 0.94; alpha &lt;- 2 km &lt;- seq(0, 1.5, by=0.01) C &lt;- sapply(km, function(d) {C.p(d=d, yprime=yprime, alpha=alpha, area=ha)}) qplot(km, C, geom=&quot;line&quot;) Figure 6.13: Colonization probabliity for a butterfly population (silver spotted skipper, Hanski 1994). There are additional details about the colonization function that I have buried, but the interested reader could consult sources of these ideas (I. Hanski 1994; IIkka Hanski 1994). Combining \\(C_i\\) and \\(E_i\\), we can define the incidence function, \\[J_i = \\frac{1}{1+ \\left(1+\\left[\\frac{y^\\prime}{S_i}\\right]^2\\right)\\frac{e}{A_i^x}}.\\] To use this model, we need the following data for each patch areas, \\(A_i\\), of each patch, locations of each patch, from which to calculate the distances between each pair of patches \\(i,j\\), presence or absence of the species in each patch, the distance parameter \\(\\alpha\\). From the distances, \\(\\alpha\\), and presence/absences, we calculate \\(S_i\\) for each patch. There are a couple of ways to estimate \\(\\alpha\\) but perhaps the best way is to do this using mark-recapture methods, but we will not explain those here. Other parameters, \\(e,\\,x,\\,y^\\prime\\), are estimated using nonlinear regression methods; we use these below. References "],
["references.html", "7 References", " 7 References "]
]
