[
["index.html", "Primer of Ecology using R Preface", " Primer of Ecology using R Hank Stevens 2020-10-05 Preface This book is dedicated to Dr. Zac Long, whose desire to publish with Robert Peters and Donald Strong has inspired me to continue to strive for my goals. In spite of the presumptuous title, my goals for this book are modest. I wrote it as the manual I wish I had in graduate school, and a primer for our graduate course in Population and Community Ecology at Miami University.1 To install the latest version of the primer R package, install it directly from GitHub. To do this, install the devtools package. To successfully do that on a Windows operating system, I think you need to install Rtools: https://cran.r-project.org/bin/windows/Rtools/ Once you have done all that, use this code: devtools::install_github(\"HankStevens/primer\") Miami University is located in the Miami River valley in Oxford, Ohio, USA; the region is home to the Myaamia tribe that dwelled here prior to European occupation.↩︎ "],
["theory.html", "1 Theory in Ecology 1.1 Examples of theories 1.2 An example: Metabolic Theory of Ecology 1.3 Power law scaling implies constant relative differences", " 1 Theory in Ecology In this chapter, we introduce a perspective on ecological theory, and provide an example of an efficient theory, metabolic scaling. Scientific theory is a body of knowledge that provides an organized and mechanistic view of how the world works (Scheiner 2010). Theories concerning gravity, general relativity, and evolution by natural selection provide structured ways of connecting observations, patterns, and processes that provide insight into why the world is the way it is. This stands in stark contrast to the colloquial use of theory that implies a lack of knowledge, as when someone says “oh, that’s just a theory”, referring to a guess without much evidence. Scientific theory is a set of explanations whose validity has been tested repeatedly by experiments and new data. 1.1 Examples of theories Ecology has lots of theories, of all different types. Below I discuss some which may be prevalent, important, useful, or some combination. 1.1.1 Hierarchy theory An early and persistent organizing theory in ecology is based on hierarchy theory (O’Neill et al. 1986; Rose et al. 2017, and references therein). It posits that ecological systems are structured hierachically, such that each entity comprises subunits. For instance, an entity such as a population of big bluestem grass (Andropogon gerardii) is part of a larger ecology community of many species. The population of big bluestem comprises subpopulations separated in space, a subpopulation comprises separate individuals, that each individual comprises multiple ramets and a set of organ systems and tissues, which comprise different cell types. This theory posits that each entity gives rise to emergent properties to the hierarchical level above it, and influences processes within each smaller sub-entity in the hierachical level below it. As a disciplinary organizing principle, this approach structures nearly all of the ecology curriculum. Hierarchy theory gets more complicated when the levels of a hierarchy start to include fundamentally different types of entities. The big bluestem hierarchy above included only biotic components–a individual is part of a population which is part of a community of individuals of multiple species, and is made up of organ systems and tissues. Ecology, however, includes both the biotic and the abiotic parts of environments. An ecosystem includes a community of species, but also the nutrients, water, light, and other abiotic components, along with the spatial arrangement of all of these things. Different hierarchies are useful for different questions. An individual organism can play very different roles in different hierarchies. Consider and individual bunch grass. To understand how a population evolves, we need to count individuals within a population, because evolutionary fitness is tracked by the number of independent reproductive units. In contrast, to understand competitive interactions, it may be much more important to weigh the biomass of groups of individuals in a population, because biomass is more closely related of resource uptake. 1.1.2 A general theory of ecology Good scientific theories exist within a hierarchy of disciplinary knowledge (Scheiner and Willig 2011). They explain phenomena within a domain of knowledge which is organized around principles and assumptions. Scheiner and Willig posit a theory of biology that explains phenomena relating to the “diversity and complexity of living systems”. One of the ten principles on which this theory depends is that “the cell is the fundamental unit of life”. Subsumed within their theory of biology is the theory of cells whose domain is “cells and the causes of their structure, function, and variation.” This theory in turn is based on principles and has theories to organize our understanding of cells and what cells do. Models are specific and explicit manifestations of more general theories. In this book, we focus on popular mathematical models that are specific manifestions of theories of ecology. Scheiner and Willig (2011) propose a theory of ecology, some of which we cover in this book. Here is part of this theory: The General Theory of Ecology Domain: The spatial and temporal pattern of the distribution and abundance of organisms, including causes and consequences. Principles: Organisms are distributed in space and time in a heterogeneous manner. Organisms interact with their abiotic and biotic environments. Variation in the characteristics of organisms results in heterogeneity of ecological patterns and processes. The distributions of organisms and their interactions depend on contingencies. Environmental conditions as perceived by organisms are heterogeneous in space and time. Resources as perceived by organisms are finite and heterogeneous in space and time. Birth and death rates are a consequence of interactions with the abiotic and biotic environment. The ecological properties of species are the result of evolution. These principles constitute what we know is true about ecological systems. Some of these principles provide the focus for a single chapter while other principles apply broadly to many chapters in this book. Here is my own perspective on a general theory of ecology: Domain: The house of life2: its constituent entities, causes, and consequences. Principles: Entities3 are open systems with inputs and outputs. Entities have internal complexity. Entities include self-replicating components (living elements). Entities interact via inputs, outputs, and behavior. Rates of change, including inputs and outputs, are influenced directly by physical factors: space, temperature, and concentration. You will see elements of these principles throughout this book as well. 1.1.3 Efficient theory Marquet et al. (2014) argue that the best theories are those which are efficient. Such theories tend to be based on first principles, which are observations and laws that are fundamental assumptions in a scientific domain. In biology, such principles can include the laws of thermodynamics, and mathematical properties such as the central limit theorem. Theories built upon first principles are thus well-grounded in reality as we understand it and lead logically to refinements. Marquet and his colleagues also claim that efficient theory is expressed in mathematics. Mathematics is a universal language that is unamibiguous. It forces us to be as clear as possible about what we mean when we state a theory.4 Last, efficient theories are those that make a large number of predictions using only a small number of free parameters.5 Examples of efficient theories we cover in this book include metabolic scaling, exponential growth, density dependence, and ecological neutral theory. Marquet et al. and Scheiner and Willig emphasize slightly different features of the definition of “theory”. Scheiner and Willig emphasize relatively broad ideas that are well-supported by experiments and repeated observation. Marquet and colleagues tend to mean something fairly specific and narrow, typically something that can be expressed mathematically. Scheiner and Willig might refer to such theory as constitutive theory or even simply a model. Next, I describe the Metabolic Theory of Ecology. This theory is based on first principles, and its central tenets are expressed mathematically. It’s core equation has a very small number of free parameters (fitted constants) and makes a very large number of testable predictions. Parts of this theory are supported by a very large number of observations. It fits everyone’s definition of theory. 1.2 An example: Metabolic Theory of Ecology Metabolic rate is central to how rapidly individuals forage for, consume and use resources, reproduce and die. The metabolic theory of ecology (Brown et al. 2004) is a well-supported body of knowledge about the underlying mechanisms, and the resulting profound and wide-ranging consequences for populations and ecosystems. Body size and temperature are fundamental properties of organisms and the environment. The study of how body shape and body processes scale with body size is allometry. Because body size affects metabolic rate, body size indirectly helps determine population growth rates and how species interact with each other. Temperature affects how molecules vigorously molecules vibrate and move, and so increasing temperature tends to speed up chemical reactions. As metabolism is really just a complex network of biochemical reactions, temperature influences metabolic rate. The core of this theory is expressed in a simple mathematical equation that describes how body size and temperature govern metabolic rate. 1.2.1 Body-size dependence There is a profoundly simple and general rule describing the effect of interspecific variation in body size on metabolism.6 This biological law is referred to as the Kleiber law (Kleiber 1932), or quarter power scaling (Brown et al. 2004). When we compare the basal (i.e. resting) metabolic rates of different species, across a wide range of body sizes spanning many orders of magnitude, we find that whole-organism resting metabolic rate increases with organism mass raised to the three-quarter power, or, \\[ B = aM^{z} \\quad;\\quad z = 3/4 \\] In this equation, \\(B\\) is basal, or resting, metabolic rate, \\(M\\) is body mass, \\(a\\) is a proportionality constant, and \\(z\\) is the power law scaling coefficient. The proportionality constant \\(a\\) varies depending on the type of organism such as arthropods, fish, or mammals. Plants scale in the same manner (Niklas and Enquist 2001), although size or mass is a little trickier to measure. The scaling coefficient, \\(z\\), is the seemingly magical constant that many have argued does not vary substantially among different types of organisms. Ecologists typically describe metabolism-mass relations and other power law behavior using logarithmic scales. When we do that, power law relations become linear. Using our rules for exponents and logarithms, metabolic scaling becomes \\[ \\log B = \\log a + z\\log M\\] so that \\(\\log B\\) increases linearly with \\(\\log M\\) with a slope of \\(3/4\\). Our brains can process and compare linear relations much more easily than curvilinear ones. Here we plot the curvilinear relation in R using curve() in the graphics package of R that is included in the base installation as one of the core packages. The function curve() can plot any curve that be expressed as a function of x. Below, we draw a curve of a dotted 1:1 line for comparison, and then add the power function \\(x^{3/4}\\). Figure 1.1: Metabolic rate increases predictably with species body sizes. ## using curve, let your variable be &#39;x&#39;. curve(1*x, from = .01, to=100, ylab = &quot;Metabolic rate (B)&quot;, xlab=&quot;Body mass (M)&quot;, lty=3) curve(x^(3/4), from = .01, to = 100, add=TRUE) To help us grasp the implications of this, let’s consider mass-specific metabolic rates. “Mass-specific” means on a per-gram basis.7 Mass-specific metabolic rate is basal metabolic rate of an individual divided by its mass, or \\(B/M\\). The mass-specific metabolic rate allows us to compare directly, for example, the metabolic rate of a cell in a shrew vs. a cell in an elephant. Which cell is burning fuel faster? We can estimate this from the above metabolic scaling principle and the using rules exponents \\[ \\frac{B}{M} = a \\frac{M^z}{M^1} = a M^{z-1} = aM^{-1/4}\\] From this, we now have the rule that mass-specific metabolic rate declines with organisms mass raised to the negative one quater power eq1 = function(M, a){a*M^-0.25} # create the function, F(M) ggplot(data=data.frame(x=c(0.1, 100)), aes(x=x) ) + stat_function(fun=eq1, geom=&quot;line&quot;, args=list(a=1)) + xlab(&quot;Mass (M)&quot;) + ylab(&quot;Mass-specific metabolic rate (B/M)&quot;) Figure 1.2: Mass-specific metabolic rate declines predictably with species body sizes. Over the years, there has been heated debate about (i) the precise value of the scaling coefficient \\(z\\), and (ii) the underlying mechanism. Early arguments suggested that \\(z \\approx 2/3\\) because the rate heat dissipation scales with the amount surface area. Why \\(2/3\\)? Let’s envision the volume of an organism having three linear dimensions, so the volume scales to the cube of linear dimensions, while the surface area scales to the square of these linear dimensions,8 \\[V \\propto L^3\\] \\[A \\propto L^2\\] The early explanation was that metabolic rate, \\(B\\), scales linearly with area, \\[B \\propto A^1 \\propto L^2\\]. With substitution we get, \\[L^2 \\propto V^z \\propto (L^3)^z\\] implying that the exponents \\(2 = 3z\\) or \\(z=2/3\\), so we get, \\[B=V^{2/3}\\], and, for the most part, mass scales linearly with volume for mammals or any other such group. This early theory was because it started with first principles (heat dissipation and geometry) and resulted in the prediction of a single parameter. It could then be used to make predictions about how metabolic rate scales with body mass. Metabolic rate governs a huge amount of biology and ecology, including resource consumption rates, lifespan, and maximum population growth rates. Therefore, this theory and this model could be powerful tools for understanding the world and making testable predictions. The above model is good because it could be tested. That is what has been done, and scientists found that there was a consistent mismatch between observations and the theory. Investigators showed that the value of the exponent appeared closer to 3/4 raher than 2/3. In the 1990s, a group including Jim Brown and Geoffrey West (West, Brown, and Enquist 1997) proposed an underlying mechanism that explained why it should be 3/4. They assumed that organisms must distribute resources from a single source through a branching, fractal-like, space-filling network to all parts of the body, the size of the smallest branch ( a capillary) was the same for organisms of all sizes. the energy required to distribute the resources must be minimized, that less energy-efficient designs would be lost through natural selection. The prediction that resulted from these assumptions was that the exponent would be 3/4. This theory and model begin with different first principles and makes a different prediction. Soon Jayanth Banavar and his colleagues offered an alternative (Banavar, Maritan, and Rinaldo 1999; Banavar et al. 2002), arguing that the assumption of the fractal-like network was not correct, and in any event, was not necessary and did not apply to all organisms. They proposed different theory with less restrictive assumptions and found nonetheless that the exponent was also predicted to be 3/4. At the base of all these arguments is the geometry of the resource distribution system. All organisms take in limiting resources and have to distribute those resources to each part of each cell in the body. The key point is that the larger the organism, the greater the portion of the resources are in transit at any instant in time. This leads to an increasingly inefficient system, in which the metabolism of larger organisms has to run more slowly per unit resource: Larger organisms can process more resources per unit time (\\(B=aM^{3/4}\\)), but do so less and less efficiently (\\(\\frac{B}{M}=aM^{-1/4}\\)) due to resources in transport. Banavar, Brown and others eventually collaborated to address quarter power scaling in animals in particular which led to additional novel predictions (Banavar et al. 2010). This theory remains a fertile and active area of research (Glazier 2018). The interested reader should be careful to distinguish between patterns observed across many species of very different sizes, versus patterns observed in a single species with individuals of different sizes versus other types of patterns. Subtly different patterns may be driven be very different mechanisms. 1.2.2 Temperature dependence In addition to body size, temperature plays the other key role in regulating metabolic rate. The Arrhenius equation connects the macroscopic property of temperature to the kinetic energy of molecules and the rates they govern. Metabolic rate is proportional to these rate determining processes, \\[B = a e^{\\frac{-E_a}{kT}}\\] where \\(a\\) is just a constant, \\(e\\) is the exponential, \\(E_a\\) is the average activation energy of rate-limiting enzymes (units, eV), \\(k\\) is Boltzmann’s constant (units eV\\(\\,\\)K\\(^{-1}\\)), and \\(T\\) (units deg K). Bolztmann’s constant (\\(\\backsim 8.6 \\times 10^-5\\)\\(\\,\\)eV\\(\\,\\)K\\(^{-1}\\)) converts the macroscopic property of temperature to kinetic energy of molecules. Individual biochemical reactions combine to determine basal metabolic rate, so Gillooly (2000) have taken this as a foundation for the metabolic theory of ecology (Brown et al. 2004). In 2000, they suggested that the average activation energy is approximately \\(E_a = 0.23\\,\\)eV . Subsequent work has described this as “temperature sensitivity”, where larger numbers imply that organisms respond more strongly to temperature variation. The Arrhenius equation is a little more complicated that a simple power law, but not too much. Over the range of biologically relevant temperatures, it is dominated by a largely exponential increase in metabolic rate with increasing temperature (Fig @(fig:arrh)). # with base R # base R: curve(10^4*exp(-0.23/(8.5 * 10^-5 *x)), 276, 316), ylab=&quot;B&quot;, xlab=&#39;T&#39;) # or ggplot2 # the function, with default parameter values eq.t &lt;- function(t,a=10^4,E=0.23,k=8.6 * 10^-5){a*exp(-E/(k*t))} # the data used in our function temps &lt;- data.frame(t=276:316) ggplot(data=temps, aes(x=t)) + # set the basic properties of the plot stat_function(fun=eq.t, geom=&quot;line&quot;) + # set the function to plot xlab(&quot;Temperature (K)&quot;) + ylab(&quot;Metabolic rate (B)&quot;) Figure 1.3: The effect of body temperature on ectothermic metabolic rates can be approximated with the Arrhenius function, \\(B = a e^{-E_a/(kT)}\\). Here \\(a = 10^4\\), and \\(E_a = 0.23\\). It is similar in shape to a power law with z &gt; 1, over the range of biologically relevant temperatures. # add labels When we linearize the relation between metabolic rate and temperature, we get \\[ \\begin{aligned} B &amp;= a e^{\\frac{-E_a}{kT}}\\\\ \\log(B) &amp;= \\log{a} - E_a\\frac{1}{kT}\\\\ \\end{aligned} \\] where the dependent variable is \\(1/(kT)\\), \\(-E_a\\) is the slope, and \\(\\log a\\) is the intercept. Thus, the negative slope of this relation describes theoretical prediction for the effect of temperature on metabolic rate. So, there you have it. The metabolic theory ecology is the algebraic product of body size- and temperature-dependence: \\[B = a M^{3/4} e^{\\frac{-E_a}{kT}}\\] This theory makes quantitative predictions regarding all kinds of ecology phenomena (Brown et al. 2004), including home range size population growth population size resource uptake predation and other species interactions, and ecosystem cycling. Note that these relations are based on first principles of geometry and thermodynamics, and that they depend on only a small number of parameters (\\(a\\), \\(-E_a\\), and perhaps \\(z=3/4\\)), and makes a tremendous number of predictions. Therefore, Marquet et al. (2014) propose that this is “good” theory, and very efficient. 1.3 Power law scaling implies constant relative differences In power law scaling, relative change is constant. That is, a proportional change in one variable results in a proportional change in the other. For instance, when we compare a smaller species to a larger species with \\(100 \\times\\) the body mass, we can expect to see metabolic rate increase by \\(31.6 \\times\\), regardless of the mass of the smaller species. For now, we will verify this numerically for some limited cases. # define body mass and metabolic rate m &lt;- c(.01, 1, 100, 10000) b &lt;- m^.75 Now we will divide each mass \\(i\\) by the next smallest mass \\(i-1\\). We do that using a vector by dividing each mass except the first one, by each mass except the last one. # round(x, digits=0) rounds number to zero decimal places round( m[-1]/m[-length(m)], digits = 0) round( b[-1]/b[-length(b)], digits = 1) When we do these divisions, we see the constant relative change (1.1). Table 1.1: As we increase mass by a constant multiplier (10x), power law scaling results in a constant proportional change in basal metabolc rate. Small Med. Big Huge Mass 0.01 1.00 100.00 10000.00 Basal.metabolic.rate 0.03 1.00 31.62 1000.00 Relative.change.m NA 100.00 100.00 100.00 relative.change.b NA 31.62 31.62 31.62 We can verify this generally using algebra, not just in the particular case above. We will show that if mass increases by a constant multiplier, metabolic rate will also, regardless of the particular masses involved. Let mass \\(m_2\\) be greater than mass \\(m_1\\) by a factor of \\(c\\), so that \\(m_2 = c m_1\\), and \\[\\frac{m_2}{m_1} = c\\]. We would like to show that the ratio of the metabolic rates \\(b_2 / b_1\\) is also a constant. Since \\(m_2 = cm_1\\), we can say that \\[b_1 = a m_1^{3/4}\\] \\[b_2 = a (cm_1)^{3/4} = ac^{3/4}m_1^{3/4}\\] \\[\\frac{b_2}{b_1} = \\frac{ac^{3/4}m_1^{3/4}}{am_1^{3/4}}\\] When we reduce this fraction, we a left with \\[\\frac{b_2}{b_1} = c^{3/4}\\] This shows that with power law scaling, increasing \\(x\\) by a constant multipier (or proportion), \\(y\\) increases by the same proportion raised to that power. Let’s represent this graphically in a couple of ways, reusing data we made up previously in this chapter. First, we just change the axes themselves, so that the units of the scales are multiples of 10 (often in scientific notation). # using base R par(mar=c(5,4,0,0), mgp=c(1.5,.4,0) )# set figure margins in &quot;lines&quot; curve(x^(3/4), from = .01, to = 100, log=&quot;xy&quot;, ylab=&quot;Basal metabolic rate&quot;, xlab=&quot;Mass&quot;) text(10, 80^.7, expression(M^0.75)) Figure 1.4: changing the scales of the axes to linearize power law relations. Note scales are logarithmic, using the original linear values. References "],
["oft.html", "2 Optimal Foraging 2.1 A prey model 2.2 The patch model 2.3 A simulation of a prey model", " 2 Optimal Foraging Figure 2.1: Optimal foraging theory (OFT) generates testable quantitative predictions that allow a less ambiguous description and explanation for observed patterns and processes. Here, a simplistic model of Great Tit (Parus major) foraging that includes only gross energy intake underestimates the time spent in patches (dashed). In contrast, a model that includes energetic costs of traveling and searching matches predictions far better (solid). From Cowie (1977). It can be useful to think of natural selection as an optimizing process: phenotypes diversify, winners replicate and losers don’t, and the phenotypes of winners tend to get passed on to the replicants. Therefore, we often assume, as did Dr. Pangloss, that the species that exist now are the best of all possible species, that is, they are of optimal design. And like Dr. Pangloss, we would be woefully mistaken if we stopped there. Nonetheless, optimization, that is, the tendency toward an optimum, helps us generate testable hypotheses and we consider some of these below. Optimal Foraging Theory (OFT) helps us consider what organisms would do if they foraged optimally. All organisms–plants, fungi, archaea, and even animals–forage, and they are all subject to natural selection. Therefore, their phenotypes work pretty well, but probably not optimally and definitely not optimally for all times and places. Nonetheless, OFT is an efficient theory about the behavior of an organism, in the absence of other complications. Therefore, it allows us to study the relative importance of those “other complications.” Foraging is a key link between the individual, and communities and ecosystems (Beckerman, Petchey, and Morin 2010). All organisms interact with their environment via consumption, and the choices they make influence population dynamics, species interactions, nutrient cycling, and even the physical structures of terrestrial and aquatic habitats. The text and logic of this chapter rely heavily on Stephens and Krebs (1986) and Ellner (2009). In Scheiner and Willig’s edited volume on The Theory of Ecology, Andy Sih (Sih 2011) proposes that the following propositions form the basis of foraging theory: Foraging patterns maximize fitness or a correlate of fitness. Foraging patterns depend on the range of options available to the forager and on how each available option affects fitness or a correlate of fitness. Foraging behaviour balances conflicting demands–tradeoffs are important in shaping foraging behaviour. These properties are the outcome of natural selection operating on foraging behavior. Our understanding of foraging itself considers these three features (Stephens and Krebs 1986): currency (what is being optimized), constraints (features of behaviour that limit optimality), and the resulting decision rules. Currency is that quantity that is optimized by the forager. This currency is assumed to be a quantity that limits fitness, such as energy or a particular consumable resource. We measure it as a rate, for instance, as the energy gained per unit time (E/T) or the uptake of a critically limiting resource per unit time (R/T). Constraints are limitations that we assume about organisms. These might include distances between resource patches, the time and costs associated with extracting a resource from a substrate or subduing prey. They also include constraints imposed by other species including competitors and predators. Constraints can get complicated quickly; however, simple quantitative theory makes predictions against which we can evaluate more complicated assumptions. Decision rules are what we ascribed to a forager’s choices. A decision rule concern the probability of attacking prey if encountered, or when to leave one resource patch in order to search for another. An additional way to think about all this is where, when, and what. A great deal of effort has focused on understanding patch use: where foragers should explore for resources, and when they should give up and go in search of another patch (Charnov 1976). These are patch use models, and are based on economic models and the marginal value theorem. Another avenue of inquiry concerns what animals should eat. For instance, should they go after big prey that may be hard to catch and difficult to subdue, or just snack on what is easy? These are prey models or diet models, and attempt to explain why organisms consume what they do. A note on “prey”. All organisms forage for resources. Plants extend branches toward the light, and proliferate leaves and roots into resource rich patches, and rhizomes grow longer faster through resource-poor soils. Bumblebees search for and learn where to find nectar-rich flowers, and wolves hunt in packs to take down large ungulates. Some bacterivorous nanoflagellates intercept particles selectively depending on the perceived nutritional value of particles (Boenigk et al. 2002). So, depending on the forager, its “prey” may be \\(\\mathrm{NO}_{3}^-\\) ions, nectar, moose, or bacteria. Therefore, we will refer to these resources variously as prey, prey items, resources, and resource items. Some of these ideas are best handled with patch-based models (Charnov 1976) where a “resource patch” is a more intuitive and useful unit. A note on “handle”. All organisms pays costs to consume resources. In OFT, “handle” typically means expending energy an time to attack and subdue prey (predators), proliferate into resource rich areas (plants), exude extra cellular enzymes (fungi); ingest the item(s), and then resume searching. 2.1 A prey model …in which a forager asks, “should I eat this?”9 Let’s start where this field started, with a prey-centered model (MacArthur and Pianka 1966; Emlen 1966). The goal is to optimize the currency. 2.1.1 Our intuition Figure 2.2: The amount of energy, E (y-axis), that is lost and gained by a foraging ant–it may decline slowly over time (x-axis) while searching, and decline quickly while handling a food item. Our ant gains energy when it consumes an item. Below: Our ant. She expends energy while searching for food. Upon encountering a food item, she may choose to ‘handle’ it (encounters 1 and 3) and gain energy, or not handle it (encounter 2) and save the added cost of handling it. It seems reasonable that if a forager encounters food, it should eat it. However, if handling it costs more than the forager gets back in energy, then it isn’t worth it. We might think of this as the ratio as profitability, \\[\\frac{e_i}{h_i}\\] where \\(e_i\\) is the energy in an item of type \\(i\\), and \\(h_i\\) is the cost of handling said item. If \\(e_i/h_i&lt;1\\), then it doesn’t make sense to select the item. Further, handling an item means that the forager is not looking for a better food item. This suggests that even if \\(e_i/h_i&gt;1\\), a forager may not want to handle it if it is likely to soon encounter food items of higher energy content. On top of this, the act of searching may expose a forager to a risk of running into competing foragers, or even being eaten by a bigger forager. Clearly, a forager faces tradeoffs as it searches and when it encounters resources. 2.1.2 Mathematical support One of the reasons to represent ideas mathematically is that we make concrete assumptions, and then the math can tell us what the predictions are. That is what we will do here. Let’s assume that natural selection tends to maximize the currency as Gain per unit Time, \\(G/T\\). Our model will use these parameters and variables: \\(i =\\) index for prey type \\(S =\\) total time spent searching (units = seconds, \\(s\\)). \\(\\lambda_i =\\) rate of encounter with prey of type \\(i\\) (units = # encountered/s = \\(\\#/s\\); note this can also be #/area × area/s, if we like)10 \\(p_i =\\) probability that a forager attacks prey if encountered (units are number handled per number encountered, or #/#; this is a dimensionless parameter) \\(h_i =\\) handling time for an item of type \\(i\\), (units = s/#). \\(T =\\) total elapsed time (units = s) From these definitions we can calculate other important quantities. Total number of items encountered of type \\(i\\) is \\[S \\lambda_i\\] The units are \\(s\\, \\#\\,s^{-1} = \\#\\). Total number of type \\(i\\) items handled is the proportion, \\(p_i\\), of those encountered that the foragers chooses to go after, or \\[S\\lambda_i p_i\\] The units are \\(\\#\\). Total time spent handling all items of type \\(i\\) is \\[H=S\\lambda_i p_i h_i\\] The units are \\(s\\).11 Total elapsed time is time spent searching plus time spent handling, which is \\[T=S + \\sum_i^n S\\lambda_i h_i p_i\\] where we use the summation to add together the total handling times for each prey or resource type \\(i = \\{1,\\,2, \\ldots ,\\,n\\}\\). Let \\(e_i =\\) net energetic gain from catching and consuming a single type-i prey item (units = Joules, J). This includes the gross energy of the item minus handling costs plus energy not lost by searching during that time. \\(c =\\) energy cost per unit of time while searching (units = J). Total energy gain from eating all the items is the number of items of each type \\(i\\) handled times the net amount of energy per item of type \\(i\\), \\(e_i\\), \\[\\sum_{i=1}^n S\\lambda_i p_i e_i\\] where units are \\(\\# (\\mathrm{J}/ \\#) = \\mathrm{J}\\). Therefore, rate of energy intake (J/\\(s\\)) while handling and eating is \\[\\mathrm{intake} = \\frac{\\sum_{i=1}^n S\\lambda_i p_i e_i}{S + \\sum_{i=1}^n S\\lambda_i h_i p_i}\\] If we then subtract the cost of searching, we arrive at the quantity we want to maximize, \\[G/T=\\frac{\\sum_{i=1}^n \\lambda_i p_i e_i}{1 + \\sum_{i=1}^n \\lambda_i p_i h_i}-c\\] A major question in OFT is whether a forager should include a particular prey type. Say we rank the prey types, \\(i=\\{1,2,...,m,...,n\\}\\), in terms of energy content, where type \\(i=1\\) has the most energy per item, \\(i=m\\) is intermediate, and type \\(i=n\\) has the least. Which items should a forager include in her diet? Should it be only the most energy-dense, or should it include the second as well, or should it be all of them? Part of the answer rests on the ratio of energy gain versus handling costs, or profitability, \\(e_i/h_i\\). If we maximized \\(G/T\\) with respect to \\(p_j\\), we would be able to determine whether to include item \\(j\\). Doing so leads to several predictions. Prediction 1 A less energy-dense item should be added if its net energy content is greater than the realized energy gain from all the other items, \\[\\begin{equation} \\frac{e_{m+1}}{h_{m+1}} &gt; \\frac{\\sum_{i=1}^m \\lambda_i e_i}{1 + \\sum_{i=1}^{m} \\lambda_i h_i} \\tag{2.1} \\end{equation}\\] where the diet already includes items 1-\\(m\\), and the realized energy content of the diet takes into account average encounter rates of each item type. It means that a foraging will always select a particular type (\\(p_j =1\\)), or never select it (\\(p_j=0\\)); this is known as the “zero-one rule”. Prediction 2 Foragers will rank prey types by their profitability, \\(e/h\\). Prediction 3 When encounter rates increase (as with increasing abundances), selectivity increases. Note that encounter rates are in the right hand side, so as they increase, so will that fraction on the right. That will make it harder for the above inequality to be true, and a forager will be pickier. If you don’t believe it, try this simplified version (Fig. 2.3). G.T = function(lambda, h=1, e=1){lambda*e/(1+lambda*h)} # create the function you want myData &lt;- data.frame( lambda=c(0, 10) ) # data you need ggplot(data=myData, aes(x=lambda)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=G.T, geom=&quot;line&quot;) + ylab(bquote(over(lambda*e, 1 + lambda*h))) + xlab(bquote(lambda)) # add labels Figure 2.3: Selectivity increases with average encounter rates. Prediction 4 Inclusion of type \\(m+1\\) in the diet does not depend on its encounter rate. Thus, a particular type should be included if the instantaneous net gain of that type is greater than the realized long term average net gain of all the more profitable types. Note that encounter rate appears on the right hand side, but not the left. So how does this model fair in the real world? Well, the zero-one rule doesn’t work at all; it turns out that for a variety of reasons, foragers do not completely ignore low-profit prey. However, there is great support for the other predictions (above) (Stephens and Krebs 1986). Most importantly, in all cases, the theory has provided a clear framework to generate testable predictions from unambiguous assumptions, and that is what we want from efficient theory. The model itself helped guide research, and inclusion of greater complexity has led to deeper understanding of behavior and its consequences for species interactions. 2.2 The patch model …in which omniscient rationale agents roam free. Here the forager asks, “how long should I stay here?” In the simple prey model, a forager searches for and then encounters prey one at a time, makes a decision to consume or not, and then resumes searching. In a simple patch model, a forager searches for and encounters patches one at a time, first consumes resources and then makes a decision to leave or not. Perhaps the single most important prediction of the simple patch model is that a forager should leave a patch when its current rate of energy gain drops down to the average or expected rate of energy gain for the habitat at large. In what follows, we rely on Charnov (1976), who applies the marginal-value theorem to explain optimal behavior. Here, as in economics, “marginal value” refers to a rate - the slope of a function. In calculus, this is a derivative. Here, it is the derivative (i.e. slope) of the relation between energy gain and time. Let’s assume the simplest of all patch models: one patch type, all patches are the same, and they are distributed randomly in the habitat. Assume also that a forager uses time to travel between patches (travel time, \\(t_t\\)) and time searching within a patch (residence time, \\(t_r\\)). A forager encounters patches at random, with a rate of \\(\\lambda\\), and as such, would have a mean time to next encounter of \\(1/\\lambda\\). The patch is characterisized by its gain function \\(g(t_r)\\) (Fig. 2.4) which is the expected12 cumulative net energy gained, given time \\(t_r\\) spent in the patch. The gain function is a cumulative total net amount. We can imagine different types of gain functions. Figure 2.4: Net energy gain as a function of patch residence time may take different forms. Net energy gain increases through time but slows (decelerates) as a greater fraction of the resources in the patch are consumed. The top line (solid) assumes that there are diminishing returns as a patch is depleted, but the forager continues to find resources in excess of metabolic losses. The lower line (dashed) represents the net energy gain that could arise as a patch is depleted more fully and the costs continue unabated. Try this: Draw a gain function where the prey remain well hidden at first, but the forager becomes increasingly able to find more and more prey. Draw a gain function where there is no cost to foraging, and where the forager eventually depletes all the prey. In one graph, draw two gain functions for a resource rich patch and for a resource poor patch. So, our currency is long-term average energy intake, \\(R\\), and we want to maximize this. The decision our forager needs to make is how long to stay in a patch. The forager’s constraints share some similarity with the prey model (Stephens and Krebs 1986). between-patch travel time and within-patch hunting time are distinct, and … … independent of each other, a forager encounters patches sequentially and randomly, in a given patch, net expected energy gain is a function of time spent in the patch… …that is zero when \\(t=0\\), and …increases with time, but then decelerates the forager is omniscient - it knows everything about available patches and does not learn anything new as it forages (because it already knows everything). The forager must decide how long to stay in the patch to maximize \\(R\\). Let \\[R=\\frac{g(t_r)}{t_t + t_r}\\] where \\(t_t + t_r\\) is the total time from leaving one patch, traveling to the next patch, foraging in the second patch, and then leaving the second patch. Think of this as benefit (\\(g(t)\\)) per unit time. This fraction is the slope of the straight line in Fig. 2.5. Intuitively, we can imagine that the long term average rate of energy gain \\(R\\) is unimodal (hump-shaped) in the following scenario (Fig. 2.4). Upon encountering a patch the forager has no resources and thus \\(R\\) is actually negative due to the costs of traveling to the new patch. As \\(t_r\\) passes and and the forager gains energy (\\(g(t_r)\\) increases), \\(R\\) will increase and become positive. An assumption of the theory (and reality) is that the gain function, \\(g(t_r)\\), decelerates–the rate of energy intake declines as the patch is depleted. With increasing time in the patch and lower rate of energy intake, \\(R\\) starts to decline. When \\(t_r\\) is too short, \\(R\\) is not yet maximizes. When \\(t_r\\) is too long, \\(R\\) begins to decline. Because \\(R\\) is hump-shaped, we can use calculus to find its maximum. This will occur when its slope is zero, and the slope of a function, \\(F\\), is its derivative, \\(F^\\prime\\). If we asssume that travel time is constant, then we can take the partial derivative of \\(R\\) with respect to just the residence time, \\(t_r\\), \\(\\delta R / \\delta t_r\\). First, recall the product rule of differentiation: \\[F(x) = g(x)f(x)\\quad ; \\quad F^\\prime(x) =f^\\prime(x)g(x) + f(x)g^\\prime(x)\\] With that we can find the necessary derivative. \\[\\frac{\\delta R}{\\delta t_r} = - \\frac{1}{(t_t+t_r)^2} g(t_r) + \\frac{1}{t_t+t_r}g^\\prime(t_r)= g^\\prime(t_r) - \\frac{g(t_r)}{t_t+t_r}=0\\] Because this derivative equals zero when the slope of the gain function (\\(g^\\prime(t_r)\\)) equals \\(R\\), that tells use that \\(R\\) is maximized at that point. Therefore, it predicts that in order to maximize the long-term average rate, we should stay in a patch until the instantaneous rate, \\(g^\\prime(t_r)\\) drops to the long term average rate, \\(R\\) (Fig. 2.5). Figure 2.5: Energy gain vs. time: The origin is when the forager enters the patch; to the left is time spent traveling from one patch to the next, and to the right is time spent in the patch. The graph represents two different habitats, one in which the patches are easy to get to (habitat 1), and another where it takes more time to get from patch to patch (habitat 2). In all cases, the patches are identical, having the same gain function. The curved line is the gain function, the net energy gain as a function of time spent in the patch. The slope of that curve is the derivative of the gain function. Its slope at any single time point is the instantaneous rate of gain. The two straight lines are the expected gains averaged over time for each habitat as a whole. Lambda is the rate at which a forager randomly encounters patches - because it is a Poisson process, the mean or expected time is 1/lambda. The forager should leave the patch when the instantaneous rate of gain in the patch equals the long term average rate of gain for the habitat as a whole. The simple patch model predicts that when average travel time is greater, foragers will stay longer in a patch. Similarly, the model predicts that when patch quality is lower, foragers stay longer in each patch. Use Fig. 2.5 to construct explanations for these predictions. Just a starting point The simple prey and patch models have been extended a great deal to help understand a broad range of foraging situations (Sih 2011). Simultaneous, rather than sequential, encounters can lead to different predictions. In these cases, energy alone, \\(e_i\\), rather than profitability, \\(e_i/h_i\\), may determine prey selection that maximizes the long term mean average rate. Travel time and encounter rates interact with this to explain contrasting situations. Central place foragers play by slightly different rules (Stephens and Krebs 1986). Central place foragers are located in a single location, and remain there. For instance, a parent bird (or dinosaur) finds patches and returns repeatedly to the nest, bringing one or multiple prey items. With parent birds, their fitness depends on offspring viability, and so selection tends to optimize in a manner similar to an organism foraging for themselves. These cases have been built upon patch models, where the question is how to exploit patches that exist at different distances from the nest. Another example of a central place forager is a spider that acts as a ambush or sit-and-wait predator who remains stationary until a prey item gets close enough to attack. One approach to the spider problem is to consider the distance to the prey as a handling cost and search costs are negligible. These simple foraging models provide the starting points for a field of inquiry spanning many decades. The interplay between these models, the natural history of species, and experiments have led to greater appreciation of why organisms behave as they do, and the consequences for their evolution and the food webs and ecosystems in which they reside. 2.3 A simulation of a prey model Next, we embark on a simulation of the simple prey model. We will start with these assumptions: two prey types, \\(i = {1,2}\\) ranked effective energy contents, \\(e_1 &gt; e_2\\) equal handling times, \\(h_1=h_2=1\\) equal relative abundances, \\(r_1=r_2=0.5\\) encounter rates determined by an overall prey encounter rate, \\(\\lambda\\), and the relative abundances where \\(\\lambda_i = \\lambda r_i\\). equal probability of attack if prey is encountered, \\(p_1=p_2=1\\). search cost is constant, \\(c_s=0.01\\) In addition to these properties, our simulation needs several bookkeeping parameters and variables in order to track the forager energy content. It will need to run for a finite amount of time; we’ll control that with the total search time, Total. Remember that encounter rates are means but that actual encounters are random or stochastic. As a result, our forager may go through lean periods in which their net energy intake is negative. We need to keep track of total elapsed time, and for each cycle, the search time, search cost, handling time, and energy gain. optimal.forager &lt;- function( e = c(2, 1), # energy content of the prey types h = c(.5, .5), # handling times r = c(.5, .5), # relative abundance of prey types: sum(r) = 1 lambda = 0.4, # overal encounter rate, for all prey combined p = c(1,1), # prob. of attack if encountered cs = 0.4, # cost of searching per unit time Total = 10 # limit to foraging time ) { ############### ### begin foraging ec &lt;- NULL # an object to tally gains and costs. cycle &lt;- 0 # the cycle count (= search, choose and maybe attack and eat) ct &lt;- 0 # start time of the cyclesan object to tally cycle times. elapsed.time &lt;- 0 # total time spent foraging while( elapsed.time &lt; Total ) { # count which search cycle we&#39;re on (cycle &lt;- cycle + 1) # a random amount of search time, t.s, until it finds something. (lambda.r &lt;- lambda * r) (ts &lt;- rexp(2, rate=lambda.r)) if(ts[1] &lt; ts[2]) i &lt;- 1 else i &lt;- 2 i # cost of searching for that time (cost.s &lt;- ts[i] * cs) # choose to attack the encountered item with probability p (gain &lt;- if(p[i] &gt; runif(1)){e[i]} else {0}) # observed handling time if(gain &gt; 0 ){ h.obs &lt;- h[i] h.obs } else { h.obs &lt;- 0 } h.obs (cycle.time &lt;- ts[i] + h.obs ) ct &lt;- c(ct, cycle.time) (elapsed.time &lt;- elapsed.time + cycle.time) (ec &lt;- c(ec, gain - cost.s)) } df &lt;- data.frame(net.e = ec, cycle.start = cumsum(ct[1:cycle])) params &lt;- list(e=e, h=h, r=r, lambda=lambda, p=p, cs=cs, Total=Total) out &lt;- list(N = cycle, G = sum(ec), Tt = sum(ct), series = df, params = params) return(out) } Here we let the forager forage for 60 minutes and then examine the structure of the output object. myOut &lt;- optimal.forager(Total=60) str(myOut) ## List of 5 ## $ N : num 20 ## $ G : num 4.14 ## $ Tt : num 69.6 ## $ series:&#39;data.frame&#39;: 20 obs. of 2 variables: ## ..$ net.e : num [1:20] -0.3417 0.9405 -0.0851 1.7481 0.8854 ... ## ..$ cycle.start: num [1:20] 0 3.85 7 10.22 11.35 ... ## $ params:List of 7 ## ..$ e : num [1:2] 2 1 ## ..$ h : num [1:2] 0.5 0.5 ## ..$ r : num [1:2] 0.5 0.5 ## ..$ lambda: num 0.4 ## ..$ p : num [1:2] 1 1 ## ..$ cs : num 0.4 ## ..$ Total : num 60 N is the number of foraging cycles G is net energy gain Tt is total elapsed time series is a dataframe with two variables: net.e is energy gain minus search costs for each cycle, and cycle.start is the elapsed time at which each cycle starts params is a list that includes all the parameters we used in this run Now let’s graph something, because graphs are fun. ggplot(myOut$series, aes(x=cycle.start, y=cumsum(net.e))) + geom_line() Figure 2.6: The cumulative energy capital of a forager goes down while searching and handling resource items, but increases each time the prey is assimilated. Use this simulation to help solidify in your own mind predictions of the simple prey model. How should we do that? What is the prediction we are interested in? Prediction: Include type 2 if \\[\\begin{equation} \\frac{e_2}{h_2} &gt; \\frac{\\lambda_1 e_1 }{1 + \\lambda_1 h_1} \\tag{2.2} \\end{equation}\\] Figure 2.7: The right hand side of our prediction To get a sense of what our prediction (2.2) means, we should graph the righthand quantity as a function of one relevant variable, such as energy content of type 1, or the encounter rate (Fig. 2.7). The parameters that determined these curves are: unlist( myOut$params ) ## e1 e2 h1 h2 r1 r2 lambda p1 p2 cs Total ## 2.0 1.0 0.5 0.5 0.5 0.5 0.4 1.0 1.0 0.4 60.0 2.3.1 Lab exercise Do these parameter values suggest that our forager should or should not include prey type 1 in her diet? Create parameter combinations for which the forager (i) should and (ii) should not include prey type 2. Use the simulation optimal.forager() to confirm your predictions. References "],
["expo.html", "3 Simple density-independent growth 3.1 Discrete growth rates of fruit flies in my kitchen 3.2 Fruit flies with continuous overlapping generations 3.3 Properties of geometric and exponential growth 3.4 Modeling with Data: Simulated Dynamics", " 3 Simple density-independent growth Figure 3.1: Song Sparrow (Melospiza melodia) counts in Darrtown, OH, USA. From Sauer, J. R., J.E. Hines, and J. Fallon. 2005. The North American Breeding Bird Survey, Results and Analysis 1966–2004. Version 2005.2. USGS Patuxent Wildlife Research Center, Laurel, MD. Figure 3.2: Song Sparrow (Melospiza melodia) annual changes in population size as a function of population size. Between 1966 and 1971, Song Sparrow (Melospiza melodia) abundance in Darrtown, OH, USA, seemed to increase very quickly, perhaps unimpeded by any particular factor (Fig. @ref{fig:Melospiza1}, @ref{fig:Melospiza2}). In an effort to manage this population, we may want to predict its future population size. We may also want to describe its growth rate and population size in terms of mechanisms that could influence its growth rate. We may want to compare its growth and relevant mechanisms to those of other Song Sparrow populations or to other passerine populations. To do this, we start with the simplest of all population phenomena, geometric and exponential growth. Geometric and exponential growth are examples of density-independent growth. This captures the fundamental process of reproduction (e.g., making seeds or babies) results in a geometric series.13 For instance, one cell divides to make two, those two cells each divide to make four, and so on, where reproduction for each cell results in two cells, regardless of how many other cells are in the population—that is what we mean by density-independent. This myopically observed event of reproduction, whether one cell into two, or one plant producing many seeds, is the genesis of a geometric series. Therefore, most models of populations include this fundamental process of geometric increase. Second, populations can grow in a density-independent fashion when resources are plentiful. It behooves us to start with this simple model because most, more complex population models include this process. Hastings (2011) proposes that we can approach single species poulation growth from either a microscopic or macroscopic point of view. The microscopic approach begins with two propositions. The first is that if we know the location, timing, and traits of all individuals, we can predict perfectly population dynamics; the second is that we can never predict dynamics perfectly because births and deaths are fundamentally random and can be described only with probabilities.14 With this microscopic approach, we would seek a very detailed description of individuals and build a complex model to understand the consequences of the characteristics of all these interacting individuals, including the growth of the population. In this chapter, I choose to start with Hastings’ macroscopic approach. These propositions appear simpler. A population grows exponentially in the absence of other forces. There are forces that can prevent a population from growing exponentially. These are the consequences of the following assumptions. all individuals in a population are identical. there is no migration in or out of the population. the number of offspring per individual (or the per capita birth and death rates) are constant through time, and (ii) independent of the number of individuals in the population. Deviations from these assumptions lead to all of the most interesting parts of single species population dynamics (Hastings 2011). The only deviation we play with in this chapter concerns assumption c; we model stochastic variation in population growth rate to investigate extinction risk. It is also worth mentioning that, although propositions 1 and 2 follow from assumptions a-d, they are not strictly necessary (Hastings 2011). For instance, individuals need not be identical, and we deal with a big exception in the next chapter where we introduce structured population growth. Also, migration is admissable, provided immigration = emigration and it does not alter growth rates. Nonetheless, other deviations from a. and b. can have very important consequences for single species population dynamics. Here we define Density-independence in a real population as a lack of a statistical relation between the density of a population, and its per capita growth rate15. The power to detect a significant relation between any two continuous variables depends on those factors which govern statistical power, such as the number of observations, the range of the predictor variable, and the strength of the underlying relation. Therefore, our conclusion, that a particular population exhibits density-independent growth, may be trivial if our sample size is small, with few generations sampled, or if we sampled the population over a very narrow range of densities. Nonetheless, it behooves us to come back to this definition if, or when, we get caught up in the biology of a particular organism. In this chapter, we’ll introduce density-independent population projection, growth, and per capita growth, for populations with synchronous reproduction (discrete models), and continuous reproduction (continuous models). 3.1 Discrete growth rates of fruit flies in my kitchen Summertime, and the living is easy. Fruit flies in my kitchen, and their number’s quite high. Flies love my ripe fruit, and my red wine. They drown in the wine–I am not sure if that is good or bad. For now, we’ll treat fruit flies as if they grow in discrete generations. This is very common for populatilons that live in seasonal habitats - their reproduction is timed to the season, and they breed altogether in one bout.16 I count the number of flies every week, and I find these numbers: t &lt;- c(0, 1, 2, 3) N &lt;- c(2, 4, 8, 16) qplot(x=t, y=N, geom=c(&quot;line&quot;, &quot;point&quot;) ) There are several ways we can describe fruit fly population growth. We begin by thinking about the proximate causes of change to population size per unit time: births, immigration, death and emigration (Fig. 3.3). Those are the only options, and we state it thus: \\[\\frac{\\Delta N}{\\Delta t} = \\frac{B + I - D - E}{\\Delta t}\\] that is, the pop growthe rate17 is determined by the numbers of births, deaths, and migrants per unit time. Over the past month, I suspect the fruit flies are increasing primarily through reproduction in my kitchen. Clearly, at some point in the past, a fly or two (or three) must have immigrated into my kitchen, either as adults or as eggs or larvae in fruit I brought home (\\(I&gt;0\\)). For now, I will assume fruit fly population dynamics in my kitchen are governed by only births and deaths (\\(I=E=0\\)), so, we have \\[ \\frac{N_{t+1} - N_t}{(t+1) - t}=\\frac{\\Delta N}{\\Delta t}=\\frac{B+D}{\\Delta t}\\] In this equation, \\(t\\) has a particular time unit, one week, so \\(t+1\\) is one additional week. We refer to a population like this as closed, because it is closed to migration in or out. Figure 3.3: The number of fruit flies in my kitchen depends on immigration and emigration, and births and deaths. In the text, we assume that immigration and emigration are zero. All rates are individuals per unit time. I would like to represent births and deaths as proportions of existing adults. that is, as \\[B = bN;\\quad D=dN\\] This reflects the biological realities that adults produce offspring, and everyone has some chance of dying. The parameter \\(b\\) could be any positive real number, \\(b \\ge 0\\). This model of births reflects the geometric property of reproduction: over a specified time interval \\(\\Delta t\\), an average parent makes \\(b\\) babies. Parameter \\(d\\) is any real number between zero and one, \\(0 \\le d \\le 1\\). Both \\(b\\) and \\(d\\) have units of individuals per individual per unit time. They depend on that unit of time. What if offspring die before the next census? Fig. 3.3 helps us think about these things. Simplifying, we’ll assume births occur first, and then death comes to offspring and adults. Let’s define a few terms. \\(N_0\\), \\(N_1\\) - the number of flies at the start and after the first time interval. \\(N^\\prime\\), \\(N^{\\prime\\prime}\\) - distinct values of \\(N\\), just after births. \\(\\Delta N\\) - the change in \\(N\\) from one point in time to another. \\(t\\) is time, so \\(\\Delta t\\) is the time interval over which \\(N\\) may change. Let’s match these numbers to what is going on in my kitchen. For my first census count, \\(t=0\\), I counted the adults and label that number \\(N_0\\). These adults lay eggs which hatch, larvae and pupae develop, and become adults, giving us a population of \\(N^\\prime = N_0 + bN\\) Some of the eggs fail to hatch, and some of the larvae die before maturing. Many of the adults die as well. If we assume the eggs, larvae, and adults all die at the same rate, then by the end of one generation we have \\(N_1 = dN^\\prime = d(N_0 + bN)\\). Substituting and multiplying we get \\[ N_1 = N_0 + bN_0 - d\\left(N_0 + bN_0\\right)\\] We see that by the next time point, \\(t=1\\), the number of fruit flies should be equal to the number we started with, \\(N_0\\), plus the number of new individuals, \\(bN_0\\), minus the number of original adults that die, \\(dN_0\\), and minus the number of new individuals that die, \\(dbN_0\\). We can pull all of these parameters together, \\[ N_1 = N_0 + bN_0 - dN_0 - dbN_0 \\] \\[ N_1 - N_0 = N_0 \\left(b - d - db\\right) = N_0 + r_dN_0 \\tag{3.1}\\] where \\(r_d = b - d - db\\). The growth rate of the population is \\(\\Delta N / \\Delta t\\), or, at \\(t=0\\), is \\[\\frac{\\Delta N}{\\Delta t} = \\frac{N_1 - N_0}{t_1-t_0} = \\frac{(N_0 + r_dN_0) - N_0}{t_1-t_0} = r_d N_0 \\] If we generalize, we drop the zero, to get \\(r_dN\\). The per capita population growth rate is \\(r_dN/N =r_d\\)). If our time step were something other than 1, we would also divide by \\(\\Delta t\\). With the simple census data above, we can estimate \\(r_d\\) for the first time step. \\[N_1 = N_0 + r_dN_0= 2 + r_d (2) \\implies r_d=1\\] If we know that \\(r_d\\) is constant over time, we can infer a general rule to project the population forward in time an arbitrary number of time steps. We will let \\(\\lambda = 1+r_d\\). \\[N_1 = N_0 + r_dN_0 = N_0(1 + r_d) = N_0\\lambda\\] \\[N_2 = N_1\\lambda= (N_0 \\lambda)\\lambda\\] \\[N_3 = N_2\\lambda= (N_0 \\lambda)\\lambda\\lambda\\] or simply, \\[N_t = N_0\\lambda^t\\] To summarize our model of discrete population growth, we have the following statements: Projection: \\[N_t = N_0\\lambda^t\\] Population growth rate: \\[\\frac{\\Delta N}{\\Delta t} = r_dN; \\quad \\mathrm{where~} \\lambda=1+r_d\\] Per capita opulation growth rate: \\[\\frac{\\Delta N}{N\\Delta t} = r_d\\] At last, we see how this is a model of density-independent growth: per capita growth rate does not include \\(N\\). 3.2 Fruit flies with continuous overlapping generations In the reality that is my kitchen, individual fruit flies are having sex and reproducing on their own schedules. As a population, they breed continuously, so the cohorts re not synchronous. For populations like that, we need to describe instantaneous growth rates, where \\(\\Delta t\\) is no longer a fixed period of time, but is an instant, or infinity small. We return to our example above (Fig. 3.3), which we summarize in (3.1). Please take a look at that equation; here we make time explicit so that it appears in the equation. We begin by remembering that \\(b\\) and \\(d\\) have time units. Let \\(\\Delta t\\) be a small fraction of \\(t\\), so that the time step goes from \\(t\\) to \\(t + \\Delta t\\). As \\(\\Delta t \\rightarrow 0\\), \\(b\\) and \\(d\\) need to shrink as well, to \\(\\Delta t b\\) and \\(\\Delta t d\\). \\(dN/dt\\) is how we identify the differential equation that is the instantaneous rate of population growth, with lower case \\(d\\) symbolizing infinitesimally small change. We now have to solve for the limit of \\(\\Delta N /\\Delta t\\) as \\(\\Delta t\\) goes to zero. \\[\\frac{dN}{dt}=\\lim_{\\Delta t \\rightarrow 0} \\frac{N_{t+\\Delta t} - N_t}{\\Delta t} = \\lim_{\\Delta t \\rightarrow 0} \\frac{\\Delta t\\,bN_t - \\Delta t \\,dN_t - \\Delta t\\, d (\\Delta t\\, b)N_t}{\\Delta t} \\] If we divide through by \\(\\Delta t\\) and then let \\(\\Delta t \\rightarrow 0\\), we get \\[\\frac{dN}{dt}=\\lim_{\\Delta t \\rightarrow 0} bN_t - dN_t - \\Delta t\\, d bN_t = bN_t - dN_t=rN\\] To arrive at the projection equation for a continuously growing population, we integrate \\(rN\\) with respect to time. Integration is the cumulative summing of \\(y\\) across a range of \\(x\\). It even uses an exagerated “S” to indicate summation, \\(\\int\\). Here we integrate population growth across time. We start by rearranging \\[\\frac{dN}{dt} = rN \\Rightarrow \\frac{dN}{N} = r dt\\] Now we integrate \\(N\\) and \\(r\\) with respect to their start and end points: \\(N\\) from \\(N_0\\) to \\(N_t\\), and, correspondingly, \\(r\\) from \\(t=0\\) to \\(t=t\\), \\[\\int_{N_0}^{N_t} \\frac{1}{N}dN = \\int_{0}^{t}rdt\\] \\[\\ln(N_t) - \\ln(N_0) = rt - r\\,0\\] \\[\\ln(N_t) = \\ln(N_0) + rt\\] We now exponentiate (\\(e^x\\)) both sides to arrive at our projection equation. \\[N_t = e^{\\ln(N_0) + rt} = N_0 e^{rt}\\] To summarize our model of continuous population growth, we have the following statements. Projection: \\[N_t = N_0 e^{rt}\\] Population growth rate: \\[\\frac{dN}{dt} = rN\\] Per capita population growth rate: \\[\\frac{dN}{Ndt} = r\\] Once again, we see why we refer to exponential growth as density-independent: the per capita growth rate does not depend on \\(N\\). 3.3 Properties of geometric and exponential growth Compare the projection equations for geometric and exponential growth. We find that \\[\\lambda = e^{r} \\quad ; \\quad \\ln \\lambda = r\\] This gives us a few useful rules of thumb. No change: \\(r = 0\\quad;\\quad\\lambda =1\\) Growing population: \\(r &gt; 0 \\quad;\\quad \\lambda &gt; 1\\) Shrinking population: \\(r &lt; 0 \\quad;\\quad \\lambda &lt; 1\\) # Let r take on three values r &lt;- c( -1, 0, 1) # Convert to lambda exp(r) ## [1] 0.3678794 1.0000000 2.7182818 Time scaling This is a useful property if we ever want to change time units in a discrete model. We must first \\(\\lambda\\) to \\(r\\), change units in \\(r\\) and convert back to \\(\\lambda\\). For instance, if we find that the annual finite rate of increase for a population of crickets is \\(\\lambda = 1.2\\), we cannot convert that to a monthly rate of \\(1.2/12 = 0.1\\). Instead we convert to \\(r\\) and back to \\(\\lambda\\). lambda &lt;- 1.2 # Convert lambda to r r &lt;- log(lambda); r ## [1] 0.1823216 # Scale r from year to month r2 &lt;- r/12; r2 ## [1] 0.01519346 # Convert back to lambda (per month) lambda2 &lt;- exp(r2); lambda2 ## [1] 1.015309 This is very, very different than \\(\\lambda/12\\). Doubling time Sometimes we gain a more intuitive grasp of an idea when we convert to a different form of the same relationship. Exponential growth is one of those ideas that can be hard to grasp. A more intuitive way to compare or express exponential grwoth rate is through doubling time, the time required for the population to double in size. For instance, a per capita growth rate of \\(r = 0.14\\,\\mathrm{inds}\\cdot \\mathrm{ind}^{-1} \\mathrm{y}^{-1}\\) means that the population will double in less than 5 years. We determine this by letting \\(N_t = 2N_0\\). \\[2N_0 = N_0 e^{rt}\\] \\[\\ln 2 = rt\\] \\[t =\\frac{\\ln 2}{r}\\] # let r be a sequence from r &lt;- c(0.01, 0.05, 0.1, 0.5) #doubling time will be log(2)/r ## [1] 69.314718 13.862944 6.931472 1.386294 # and a picture par(mgp=c(1.2, .2, 0), mar=c(2, 2, 1, 1), tcl=-.2) curve( log(2)/x, xlab=&quot;r&quot;, ylab=&quot;Doubling time&quot;) Figure 3.4: Doubling time is inversely related to the intrinsic rate of increase, r. 3.3.1 Average growth rate In any real data set, such as from a real population of fruit flies or Song Sparrows, \\(N_{t+1}/N_t\\) will vary from year to year. How do we calculate an average growth rate for a fluctuating population? Let’s consider the case where a population increases and then decreases. For each year, we will calculate the annual rate of increase \\(R = N_{t+1}/N_t\\), and take the arithmetic average of those rates to see if it makes sense. N &lt;- c(20, 30, 15, 15) R &lt;- N[2:4]/N[1:3]; R ## [1] 1.5 0.5 1.0 The arithmetic average of those rates is \\((1.5 + 0.5 + 1.0)/3=1.0\\). If \\(R=1.0\\), then, on average, the population should stay the same, but it decreased. Why is that? Let us do the annual time steps explicitly to see what is going on. \\[N_3 = (N_0 R_0) R_1 R_2\\] # Remember that we call the first time t=0 and N0, but # when coding, these values are the first in a series, so # N0 is N[1] # Now we do the annual changes which should equal N3 N[1]*R[1]*R[2]*R[3] ## [1] 15 From this calculation, we see that when we start with \\(N_0=20\\) and do the annaul steps, we wind up with a smaller population, even though the arithmetic average is \\(R_{\\mathrm{ave}} = 1\\). How do we calculate an average of numbers that we multiply together? We want a number \\(\\bar{R}\\) such that \\[\\bar{R}^t = R_1R_2\\ldots R_t\\] To find that, we simply solve for \\(\\bar{R}\\) \\[(\\bar{R}^t)^{1/t} =\\bar{R} = \\left(R_1R_2\\ldots R_t\\right)^{1/t}\\] We take the \\(t\\)-th root of the product of all the \\(R\\). This is called the geometric average. Another way of writing this would be to use the product symbol, as in \\[\\bar{R} = \\left(\\prod_{i=1}^t R_i\\right)^{1/t}\\] R ## [1] 1.5 0.5 1.0 #arithmetic average mean(R) ## [1] 1 # geometric average t &lt;- length(R); t ## [1] 3 prod(R)^(1/t) ## [1] 0.9085603 # shows the population should decline Another way to do the same thing is to take the arithmethic mean of the log-growth rates, and back-transform, exp( mean( log(R) ) ) ## [1] 0.9085603 Now we see the effect of calculating the average growth rate correctly. This leads to a useful rule of thumb: random variation in growth rate suppresses population growth. Here we illustrate that. We start with a growing population. lambda &lt;- 1.01 # positive growth rate N0 &lt;- 100 # starting N t &lt;- 20 # 20 years Nt1 &lt;- N0*lambda^t; Nt1 ## [1] 122.019 Here \\(\\lambda &gt; 1\\), so the population grows. Now we do a simulation in which we let \\(\\lambda\\) have a mean of 1.01 but allow it to vary randomly. # create a vector to hold all N N &lt;- rep(0, t); N[1] &lt;- N0 # create t-1 random lambdas with a mean of 1.01 # ranging from 0.41 to 1.61 set.seed(3) # makes the radnom sequence repeatable random.lambda &lt;- runif(n=(t-1), min=0.41, max=1.61) # the geometric mean prod(random.lambda)^(1/length(random.lambda)) ## [1] 1.00105 # actual simulated projection for(i in 1:(t-1)) { N[i+1] &lt;- N[i] * random.lambda[i] } qplot(x=0:(t-1), N, geom=c(&quot;line&quot;, &quot;point&quot;), xlab=&quot;Time (y)&quot;) Figure 3.5: Random variation in growth rate alters the long term average growth rate. Sometimes the arithmetic average is close to the correct average, but it is never the correct approach. 3.4 Modeling with Data: Simulated Dynamics Science strives to make predictions about about the behavior of systems. Ecologists and conservation biologists frequently strive to predict the fate of populations. This is referred to as population viability analysis (PVA) and is a large field of endeavor that is vital to managing threatened populations. Here we put into practice ideas about population biology to make informed predictions about the fate of the Song Sparrow population in Darrtown, OH. We also illustrate simple computational methods for doing so. The preceding sections (the bulk of the chapter) emphasized understanding the deterministic underpinnings of simple forms of density independent growth: geometric and exponential growth. This section explores the stochastic simulation of density independent growth. Our simulation makes most of the same assumptions we made at the beginning of the chapter. In addition, we assume that the observed annual growth rates (\\(N_{t+1}/N_t\\)) are representative of future growth rates, and that the growth rate in one year is entirely independent of any other year. To make meaning full projections of future population size, we should quantify the uncertainty with our guess. Simulation is one way we can project populations and quantify the uncertainty. The way one often does that is to use the original data and sample it randomly to calculate model parameters. This way, the simulations are random, but based on our best available knowldge, i.e., the real data. The re-use of observed data occurs in many guises, and it is known often as bootstrapping or resampling. In a highly influential paper on miminmum population sizes in conservation, Shaffer (1981) identifies four different types of noise or stochasticity that are important in driving variability in populations. The first of these is demographic stochasticity. This is the random or more correctly stochastic nature of individual births and deaths. Due to this element of random chance, individuals may live or die, produce offspring or not. As a result, population size will fluctuation randomly. This is very important in small populations, and becomes increasingly unimportant in larger and larger populations. This is the same process that underlies genetic drift in small populations. Another source of variation Shaffer (1981) identifies is environmental stochasticity. This is temporal variation in birth or death rates that affects all individuals to a similar degree, due to variation in the population’s biotic or abiotic environment. The last sources of variation are genetic stochasticity and natural catastrophes. Perhaps the latter of these is the most difficult to deal with, because catastrophes are, by definition, enormously consequential and unpredictable. Given these sources of uncertainty, Shaffer (1981) defines minimum population size (MVP) thus, “A minimum viable population for any given species in any given habitat is the smallest isolated population having a 99% chance of remaining extant for 1000 y despite foreseeable effects of demographic, environmental and genetic stochasticity, and natural catastrophes.” In our simulations, we take one approach to simulating a population of Song Sparrows. The computational approaches includes a variety of tricks that you could use in a more serious approach to population projection and determining probabilities of extinction. In their supplemental documentation, Chaudhary and Oli (2019) provide an excellent list of criteria to evaluate your own or someone else’s approach to PVA. 3.4.1 Data-based approaches We could use the observed changes in population counts \\(R_t=N_{t+1}/N_t\\) as our data. We would then draw an \\(R_t\\) at random from among the many observed values, and project the population one year forward. We then repeat this into the future, say, for ten years. Each simulation of a ten year period will result in a different ten year trajectory because we draw \\(R_t\\) at random from among the observed \\(R_t\\). However, if we do many such simulations, we will have a distribution of outcomes that we can describe with simple statistics (e.g., median, mean, quantiles). A different approach would be to estimate the individual probabilities of births and deaths in the entire Darrtown population, and use those probabilities and birth rates to simulate the entire population into the future. In such an individual-based simulation, we would simulate the fates of individuals, keeping track of all individual births and deaths. There are myriad other approaches, but these give you a taste of what might be possible. In this section we focus on the first of these alternatives, in which we use observed \\(R_t\\) to simulate the dynamics of Song Sparrow counts. Do do so, in part, because we have those data, while we do not have any estimates of birth rates or death rates. Here we investigate Song Sparrow (Melospize melodia) dynamics using data from the annual U.S. Breeding Bird Survey (http://www.mbr-pwrc.usgs.gov/ bbs/). Below we will create and examine visually the data (annual \\(R\\)’s), simulate one projection, scale up to multiple simulations, simplify simulations and perform them 1000s of times, and analyze the output. 3.4.2 Creating and visualizing the data Let’s start by graphing the data18. Graphing the data is always a good idea — it is a principle of working with data. We first load the data from the primer R package, and look at the names of the data frame. We then choose to attach the data frame, because it makes the code easier to read.19 library(primer) data(sparrows) names(sparrows) ## [1] &quot;Year&quot; &quot;Count&quot; &quot;ObserverNumber&quot; attach(sparrows) Now we plot these counts through time (Fig. 3.6). ggplot(data=sparrows, aes(x=Year, y=Count)) + geom_line() + geom_point(pch=1) Figure 3.6: Observations of Song Sparrows in Darrtown, OH (http://www.mbr-pwrc.usgs.gov/bbs/). We see that Song Sparrow counts at this site (the DARRTOWN transect, OH, USA) fluctuated a fair bit between 1966 and 2003. They never were completely absent and never exceeded \\(\\sim 120\\) individuals. Next we calculate annual \\(R_t=N_{t+1}/N_t\\), that is, the observed growth rate for each year \\(t\\). # the use of [-1[ in the index tells R to exclude the first element. # length() is the length of a vector, so [-length(X)] means exclude the last obs.R &lt;- Count[-1]/Count[-length(Count)] Thus our data are the observed \\(R_t\\), not the counts per se. These \\(R\\) form the basis of everything else we do. Because they are so important, let’s plot these as well. Let’s also indicate \\(R=1\\) with a horizontal dotted line as a visual cue for zero population growth. Note that we exclude the last year because each \\(R_t\\) is associated with \\(N_t\\) rather than \\(N_{t+1}\\). qplot(x=Year[-length(Count)], y=obs.R, geom=&quot;point&quot;) + geom_hline(yintercept=1, lty=3) + labs(y=bquote(N[t+1]/N[t]), x=&quot;Year (t)&quot;) Figure 3.7: Annual growth rates (R=N[t+1]/N[t]) for Song Sparrows One thing that emerges in our graphic data display (Fig. 3.7) is we have an unusually high growth rate in the early 1990’s, with the rest of the data clustered around 0.5–1.5. We may want to remember that. 3.4.3 One simulation Our simulation will, determine the number of years we wish to simulate, create an empty vector, N, to hold our simulated \\(N\\), which is years + 1 long, draw a random sample of \\(R_t\\), one for each year (R), select a starting abundance \\(N_0\\) and put it in N[1]. multiply our first random \\(R\\), R[1], times N[1] to generate the next, N[2]. repeat step 5 for each year to simulate each N[t+1] from R[t] and N[t]. First, we decide how many years we want to simulate growth, and create an empty vector that will hold our data. years &lt;- 10 N &lt;-numeric(years+1) # rep(0,years+1) would do the same thing. Our vector of \\(N\\) has to be one longer than the number of \\(R\\) we use. This is because each \\(R\\) is sthe change from one year to the next and there will always be one more next than there is \\(R\\). Next we draw 10 \\(R\\) at random with replacement. This is just like having all 35 observed \\(R\\) written down on slips of paper and dropped into a paper bag. We then draw one slip of paper out of the bag, write the number down, and put the slip of paper back in the bag, and then repeat this 9 more times. This is resampling with replacement. In that case, we would be assuming that all of these \\(R_t\\) are important and will occur at some point, but we just don’t know when—they constitute the entire universe of possiblities. The R function sample will do this. [A random process occurs only in our imagination, or perhaps at the quantum level.20 A stochastic process is one which we treat operationally as random while acknowledging that there are complex underlying deterministic drivers. A pseudorandom process is a completely deterministic and hidden process used by computers and their programmers to generate numbers that cannot be distinguished from random; we can repeat a pseudorandom process by stipulating a key hidden starting point.] We can use set.seed() to make your pseudorandom process the same as mine, i.e., repeatable. set.seed(3) # Draw a sample of our observed R with replacement, &quot;years&quot; times. (rRs &lt;- sample(x=obs.R, size=years, replace = TRUE)) ## [1] 1.4489796 0.8125000 1.0714286 1.2857143 0.7727273 0.4805195 1.2857143 ## [8] 1.0500000 0.7204301 1.4489796 Now that we have these 10 \\(R\\), all we have to do is use them to generate the population sizes through time. For this, we need to use what programmers call a for-loop. In brief, a for-loop repeats a series of steps for a predetermined number of times. Let’s start our simulated N with the sparrow count we had in the last year. N[1] &lt;- Count[length(Count)] Now we are ready to use the for-loop to project the population. For each year \\(t\\), we multiply \\(N_t\\) by the randomly selected \\(R_t\\) to get \\(N_{t+1}\\) and put it into the \\(t +1\\) element of N. for( t in 1:years) { # starting with year = 1, and for each subsequent year, do... N[t+1] &lt;- N[t] * rRs[t] } Let’s graph the result. qplot(0:years, N, geom=c(&quot;point&quot;,&quot;line&quot;)) Figure 3.8: A single simulated population projection. It appears to work (Fig. 3.8). Let’s review what we have done. We had a bird count each year for 36 years. From this we calculated 35 \\(R\\) (for all years except the very last). decided how many years we wanted to project the population (10,y). * drew at random and with replacement the observed \\(R\\)—one \\(R\\) for each year we want to project forward. * we created an empty vector and put in an initial value (the last year’s real data). * performed each year’s calculation, and put it into the vector we made. So what does Fig. 3.8 represent? It represents one possible outcome of a trajectory, if we assume that \\(R\\) has an equal probability of being any of the observed \\(R_t\\). This particular trajectory is very unlikely, because it would require one particular sequence of randomly selected \\(R\\)s. However, it is no less likely than any other particular trajectory. As only one realization of a set of randomly selected \\(R\\), Fig. 3.8 tells us very little. What we need to do now is to replicate this process a very large number of times, and examine the distribution of outcomes, including moments of the distribution such as the mean, median, and confidence interval of eventual outcomes. 3.4.4 Multiple simulations Now we create a way to perform the above simulation several times. There are a couple tricks we use to do this. We still want to start small so we can figure out the steps as we go. Here is what we would do next. We start by creating a function that will do the steps we did above. We then do replicate independent simulations, using replicate(). Here we write a function to combine several steps. myForLoop &lt;- function(obs.R, years, initial.N) { # select all R at random rR &lt;- sample(obs.R, size=years, replace=TRUE) # create a vector to hold N N &lt;- numeric(years+1) # give it an initial population size N[1] &lt;- initial.N # Do the for-loop for( t in 1:years ) { # project the population one time step N[t+1] &lt;- N[t] * rR[t] } # return the vector of N N } # try it out with different hypothetical R myForLoop(obs.R=0:3, years=5, initial.N=43) ## [1] 43 129 0 0 0 0 Our function seems to work. Next we do ten such projection simulations, each for 50 time steps, using the sparrow data. # specify the number of simulations and for how long sims=10; years=50 set.seed(3) outmat &lt;- replicate(sims, expr=myForLoop(obs.R=obs.R, years=years, initial.N=43) ) Now let’s peek at the results (Fig. 3.9). It is fun to graph our output, but also helps us make sure we are not making a heinous mistake in our code. Note we use log scale to help us see the small populations. matplot(0:years, outmat, type=&quot;l&quot;, log=&quot;y&quot;) Figure 3.9: Using matplot() to plot a matrix vs. a single variable. Our simulated populations sometimes increase and sometimes decrease. # combine columns years, and our output junk &lt;- data.frame(years = 1:(years+1), outmat) names(junk) ## [1] &quot;years&quot; &quot;X1&quot; &quot;X2&quot; &quot;X3&quot; &quot;X4&quot; &quot;X5&quot; &quot;X6&quot; &quot;X7&quot; &quot;X8&quot; ## [10] &quot;X9&quot; &quot;X10&quot; # make sure to load &#39;tidyr&#39; if you did not already load it or tidyverse # library(tidyr) # Take the wide data frame with many columns and turn it into # a long data frame with one column to ID each simulation, and one to hold values. out.long &lt;- pivot_longer(junk, cols=X1:X10, names_to=&quot;Run&quot;, values_to=&quot;N&quot;) ggplot(data=out.long, aes(x=years, y=N, group=Run)) + geom_line() + scale_y_log10() Figure 3.10: Using ggplot() to plot one variable against vs. a single variable, organized by a grouping variable. Our simulated populations sometimes increase and sometimes decrease. # Or for colorful lines # ggplot(data=out.long, aes(x=years, y=N, linetype=Run, colour=Run)) + # geom_line(show.legend=FALSE) + scale_y_log10() What does it mean that the simulation has an approximately even distribution of final population sizes (Fig. )? If we plotted it on a linear scale, what would it look like?^[Plotting it on the log scale reveals that the relative change is independent of population size; this is true because the rate of change is geometric. If we plotted it on a linear scale, we would see that many trajectories result in small counts, and only a few get really big. That is, the median size is pretty small, but a few populations get huge.} Rerunning this simulation, with new \\(R\\) each time, will show different dynamics every time, and that is the point of simulations. Simulations are a way to make a few key assumptions, and then leave the rest to chance. In that sense it is a null model of population dynamics. 3.4.5 A distribution of possible futures Now we are in a position to make an informed prediction, given our assumptions. We will predict the range of possible outcomes and the most likely outcomes, given our set of assumptions. We will simulate the population for 50 years 10,000 times and describe the distribution of final populatin sizes. We use system.time to tell me how long it takes on my computer. sims=1e4; years=50 set.seed(3) ## system.time keeps track of how long processes take. system.time( outmat &lt;- replicate(sims, expr=myForLoop(obs.R=obs.R, years=years, initial.N=43) ) ) ## user system elapsed ## 0.274 0.076 0.629 This tells me how long it took to complete 10,000 simulations. We also check the dimensions of the output, and they make sense. dim(outmat) ## [1] 51 10000 We see that we have an object that is the size we think it should be. We shall assume that everything worked way we think it should. 3.4.6 Analyzing results We extract the last year of the simulations (last row), and summarize it with quartiles (0%, 25%, 50%, 75%, 100%, and also the mean). N.2053 &lt;- outmat[51,] summary(N.2053, digits=6) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 12.1 60.7 1306.3 297.7 2299420.0 hist(log10(N.2053)) Figure 3.11: Distribution of the 10000 final base-10 log population sizes. Note the approximately Normal distribution. The quantile() function allows us to find a form of empirical confidence interval, including, approximately, the central 90% of the observations.21 quantile(N.2053, prob=c(0.05, .95) ) ## 5% 95% ## 1.331579 2862.940808 These quantiles provide an estimate of the most likely range of possible populatin sizes, given our assumptions. 3.4.7 Inferring processes underlying growth rate The above approach relies only on the observed data. That means that the growth rates, while representative, can never be different than what was observed. A different approaach would be to assume that the growth rates can be different than observed, but drawn from the same underlying process that caused the observed rates. The observed rates are simply a visible manifestation of unseen processes. We might summarize these by asserting that the observed growth rates were samples from a continuous distribution distribution, whose prperties we can infer from the sample. For instance, it may be that these processes cause annual rates to follow a Normal, or perhaps log-normal distribution. We can fit a Normal distribution to the logarithms of our observed \\(R\\), and we see that it doesn’t do too bad a job (Fig. 3.12). mu &lt;- mean( log(obs.R) ) sigma &lt;- sd( log(obs.R) ) # a regular sequence for log-R lR &lt;- seq(-1, 1.1, by=0.01) # the probability densities for the log-R dR &lt;- dnorm(lR, m=mu, sd=sigma) # rescale the probability density to visible height to graph rdR &lt;- dR*10 hist(log(obs.R), breaks=10, ylab=&quot;Frequency&quot;) lines(lR, rdR) Figure 3.12: The logarithms of the observed R seem reasonably approximated by a Normal distribution whose mean and standard deviation are derived from the log-transformed data. The probability distribution has been rescaled to be visible on this graph. Now we will simulate populations just like before, but instead of random draws from the observed data, we do random draws from the inferred distribution. Our new function. myForLoop2 &lt;- function(mu, sigma, years, initial.N) { # select all R at random from lrR &lt;- rnorm(years, m=mu, sd=sigma) rR &lt;- exp(lrR) # create a vector to hold N N &lt;- numeric(years+1) # give it an initial population size N[1] &lt;- initial.N # Do the for-loop for( t in 1:years ) { # project the population one time step N[t+1] &lt;- N[t] * rR[t] } # return the vector of N N } Our new simulations. sims=1e4; years=50 set.seed(3) outmat2 &lt;- replicate(sims, expr=myForLoop2(mu=mu, sigma=sigma, years=years, initial.N=43) ) N2.2053 &lt;- outmat2[51,] quantile(N2.2053, prob=c(0.05, .95) ) ## 5% 95% ## 1.205509 3089.819907 quantile(N.2053, prob=c(0.05, .95) ) ## 5% 95% ## 1.331579 2862.940808 The results are very similar to those based on only the observed \\(R\\). If they were markedly different, we might ask whether our choice of distribution was appropriate. Our conclusions are based on a model of discrete density-independent population growth what assumptions are we making and are they valid? Are our unrealistic assumptions perhaps nonetheless a good approximation of reality? what would you like to add next to make the model a better approximation? 3.4.8 1/\\(f\\) environmental noise Perhaps we might explain some of the variation in annual growth rates to weather patterns in the breeding range (Darrtown, Ohio). If so, we might separate demographic effects vs. environmental effects. That would give us an even better model we could use for explanation and prediction. An important consideration in modeling more realistic time series the temporal autocorrelation that often appears in environmental data. Patterns of autocorrelation are often best characterized by “one over f-noise” (\\(1/f\\)), that is, random variation where the temporal autocorrelation follows a color spectrum. Uncorrelated noise is referred to as white noise because the correlations actually occur at all wavelengths. Red noise emphasized strong correlation at short wavelengths and low correlation at long wavelengths. As a result, red noise is more random at longer wavelengths but less random at short wavelengths . Environmental variables typically have a reddened color that we typically refer to as pink noise (Halley 1996). In this chapter, we have explored the meaning of density-independent population growth. It is a statistically demonstrable phenomenon, wherein the per captia growth rate exhibits no relation with population density. It is a useful starting point for conceptualizing population growth. We have derived discrete geometric and continuous exponential growth and seen how they are related. We have caculated doubling times. We have discussed the assumptions that different people might make regarding these growth models. Last, we have used simulation to explore prediction and inference in a density-independent context. References "],
["DID.html", "4 Density-independent Demography 4.1 A two stage matrix model 4.2 A brief primer on matrices 4.3 Decomposing A 4.4 A three stage model 4.5 Projection 4.6 Analyzing the transition matrix 4.7 Integral projection 4.8 R packges for demography 4.9 Exploring a real population", " 4 Density-independent Demography In the preceding chapter, we listed Hastings’ (Hastings 2011) key principles and assumptions of single species population growth. One of the key assumptions is that “all individuals in a population are identical.” In this chapter, we elucidate an important violation of that assumption, population structure. Figure 4.1: Demography of human populations of Mexico and Sweden. Based on 1990 data from US Census Bureau, Population Division, International Programs Center. Populations have structure. Consider the human populations of Mexico and Sweden in 1990. Mexico had a much larger fraction of their population in child bearing age classes or younger (Fig. 4.1). In addition, the age-specific fertility rate was higher in Mexico, especially for younger women (Fig. 4.1). How did this happen, and why did Mexico have so many young people? What were the consequences of this for their culture, their use of resources, their domestic and foreign policies, and their future population growth? How about Sweden? Demography is the study of populations with special attention to their structure (Lincoln, Boxshall, and Clark 1998). Originally, age-based human demography was the provenance of actuaries who helped governments keep track of the number citizens of different ages and thus, for instance, know how many would be available for conscription into the military.22 The reason we model the structure of populations is because various demographic rates vary markedly with these stages. Juveniles produce no offspring. Very few seeds survive an entire year, whereas some large adults survive very well. We use structure when that structure is associated with important differences in demographic rates: survival, fecundity, and growth. The structure to which we refer is simply the organization of populations by some character such as life history stage, age, or size. Sizes and ages are often reduced to categories such as we saw in human populations (e.g., 0–4.9,y, 5–9.9,y,…). Sizes may be based on any reliable and repeatable measure that relates to demographic rates and are similarly binned. Life history stages may include eggs, larvae, metamorphs, juveniles, and adults in amphibians, or seeds, rosettes, and reproductive stems in herbaceous plants. With a variable such as size, we don’t even need to use categories, but rather we can use size as a continuous variable; we address this briefly later in the chapter. Structured population models allow us to intertwine species-specific natural history and quantitative methods. This makes the approach especially appealing for the conservation biology of threatened and endangered species. We use structured population models to improve our better understanding of a population or improve predictions of its future dynamics, or guide the management of the population. We might learn a lot about what controls the abundance of a species if we can test ideas related to different stages, ages, or sizes. What limits the population growth of the Western toad – is it egg survival, or overwintering survival of juveniles? Where should we invest our efforts to control garlic mustard (Alliaria petiolata) – killing the first year rosettes, or the second year adults? Why are cacti generally endangered (Goettsch et al. 2015)—is the smallest size, or the largest size that is most essential to insure long-term survival? We can use structured population models to address such questions. 4.1 A two stage matrix model Figure 4.2: Like all amphibians, the Western toad (Anaxyrus boreas) has a complex life cycle, with several life history stages. Adults breed in early spring, laying eggs in water. The larvae (tadpoles) hatch and develop over the spring and summer, and then metamorphose (become metamorphs), and then juveniles. Juveniles require more than a year to mature. Adults can live up to about a decade. American toads (A. americanus) do the same thing. A matrix model of a structured population consists of stages and transitions. Vonesh and Cruz (2002) used matrix projection to assess the importance of egg mortality for declines in amphibian populations. Their model of the Western toad (Anaxyrus boreas, Fig. 4.2) comprises two stages (juveniles and adults) and four transitions. In all structured popuation models23, a transition is the annual contribution of an individual in stage \\(i\\) at time \\(t\\) to stage \\(j\\) at \\(t+1\\). In Fig. 4.2, the transition from juvenile to adult is the probability that a juvenile survives an entire year and also matures, becoming sexually viable.24 The transition from juvenile to juvenile is the probability that a juvenile survives a year and does not mature. The transition from adult to adult is the probability that an adult survives the year. These three transitions are probabilities. The transition from adult to juvenile (Fig. 4.2) is typically referred to as fecundity, and it is the product of several events. Vonesh and De la Cruz assume that this transition depends on the population sex ratio, the average clutch size of a female, egg survival, larval survival and metamorphosis, and the overwintering survival of metamorphs. They even assume that larval survival depnds on denisty. Thus what we refer to as “fecundity”25 is far more than just average clutch size because it must include all the processes that occur over the year associated with producing a clutch and the survival of that clutch. Structured population models allow us to take advantage of the natural history of our study species. For our study population, at a minimum, we need to (i) identify stages that differ in their demographic rates, and (ii) when individuals tend to breed. Consider the example of the Western toad (Anaxyrus boreas). As with all amphibians, survival and fecundity rates depend heavily or entirely on life history stages of egg, larvae (tadpole), juvenile, and adult. We would know that breeding occurs in early spring, depending on latitude and elevation. If we wanted to model juveniles and adults, we would typically sample a population prior to breeding when juveniles and adults are just starting to become active. The design of a structured population model depends on the sampling or census schedule. These models are typically assume an annual census that occurs just before, and just after seed set, egg laying, or births. We refer to these as pre-breeding or post-breeding census models. Vonesh and Cruz (2002) (Fig. 4.2) use a pre-breeding census model. This is because only juveniles and adults are present in the population at the time of sampling. If the design assumed a post-breeding census (later in the year), it would probably include three stages, with larva (tadpoles) in addition to juveniles and adults. The reasons for using a pre- vs. post-breeding census include our ability to actually identify and sample stages, and parameter estimation. For example, it may be easy to accurately estimate the abundance of juvenile and adult toads, but very difficult to estimate larval density and larval survival. In such a case, we could represent the adult to juvenile transition as a black box, estimated as the total number of new juveniles in year \\(t+1\\) divided by the number of adults in year \\(t\\). We can draw a two different types of life cycle graphs for this two-stage model in just such a population (Fig. 4.3). Some people find one more illuminating than the other. It is useful to be able to use both. Figure 4.3: Two types of life cycle graphs. These both represent an amphibian pre-breeding model. All the stages must be present during the annual census, and each arrow or transition must represent everything that happens over the entire year. Notice the transition from adult toad to juvenile toad (Fig. 4.3) includes egg production, egg survival, tadpole or larva survival and growth, and metamorphosis out of the aquatic stage. This are obviously important events. We make explicit only those stages that we count during our census; all other other events are iplicit within the transitions. Once we have a life cycle diagram (Fig. 4.3), we create a transition or projection matrix that represents mathematically all of the stages and transitions between stages (4.1). This matrix will have one row and one column for each stage, and the columns represent the stages in year \\(t\\) and the rows represent the stages in year \\(t+1\\). We refer to a single column by j and a single row by i. Each column represents stage j in year \\(t\\), and each row represents stage i in year \\(t+1\\). For our amphibian example, the transition matrix will have two rows and two columns. It will be a “two by two”, or \\(2 \\times 2\\) matrix. \\[ \\begin{equation} \\tag{4.1} \\mathbf{A} = \\left( \\begin{array}{cc} p_{11}&amp;F_{12} \\\\ p_{21}&amp;p_{22} \\end{array} \\right) \\end{equation} \\] If (4.1) represents the Western toad (Fig. 4.3), then transition \\(p_{11}\\) is the probability that juveniles survive but fail to mature, \\(p_{21}\\) is the probability that juveniles survive and also mature, \\(p_{22}\\) is the probability that adults survive, and \\(F_{12}\\) is contribution of the average adult to the juvenile stage. In addition to fecundity, survival, maturation or growth from one stage to the next, some organisms undergo regression (Fig. 4.4). Regressing means to transition from a later stage to an earlier stage. For instance, and plant can shrink in size do to physical damage, disease or herbivory. A plant can also return temporarily to a non-reproductive stage after a large bout of reproduction. These are examples of regression (Fig. 4.4). One assumption we are making is that individuals set seed, or give birth, all at once. Therefore, we refer to our model as a birth-pulse model. On the other hand, if we assume that we have continuous reproduction throughout the year, we do things differently, and would refer to this as a birth-flow model. Whether a population is breeding continuously over a year, or whether reproduction is seasonal, will influence how we estimate fecundities. Even for synchronously breeding populations, many models pool years into a single age class or stage. The interested reader should consult an authoritative text such as Caswell (2001). Figure 4.4: A transition matrix, in which each element in the matrix describes the probability that an individual of a given size \\(j\\) at time \\(t\\) appears as size \\(i\\) and time \\(t+1\\). Reproduction typically results in the minimum size, stage, or age. This matrix may be composed of a small number of rows and columns (2-10), or, in the case of integral projection, an infinite number of rows and columns. The number of rows is equal to the number of columns. A life cycle graph (Figs. 4.2, 4.3) and the corresponding transition matrix (4.1) constitute our model. The matrix A for our structured population is directly analogous to \\(\\lambda\\) for our unstructured model of discrete population growth in the previous chapter.26 Later, we will project the population in an analogous way, using \\[\\mathbf{ N_{t+1} = A N_t}\\] and to do that, we need a refresher on matrix multiplication. 4.2 A brief primer on matrices We refer to matrices by their rows and columns. A matrix with three rows and one column is a \\(3 \\times 1\\) matrix (a ``three by one’’ matrix); we always state the number of rows first. Matrices comprise elements; an element of a matrix is signified by its row and column. The element in the second row and first column is \\(a_{21}\\). The dimension of a matrix is its number of rows and columns. To add two matrices, they must have the same dimensions. Consider two matrices, A and B . To add these two matrices we simply add the elements in the same row and column of both matrices, as below. \\[\\begin{align*} \\mathbf{A} &amp;= \\left( \\begin{array}{cc} a &amp; b \\\\ c &amp; d \\end{array} \\right); \\; \\mathbf{B} = \\left(\\begin{array}{cc} m &amp; o\\\\ n &amp; p \\end{array}\\right)\\\\ \\mathbf{A+B} &amp;= \\left( \\begin{array}{cc} \\left( a+m \\right) &amp; \\left(b+o \\right)\\\\ \\left(c+n \\right) &amp; \\left(d+p \\right) \\end{array} \\right) \\end{align*}\\] Multiplying matrices is a little more complicated. To do so, we mutliply elements and then sum them: multiply each row element of the first matrix (A) times each column element of the second matrix (B), sum the element-wise products, and place this sum in the respective element of the final matrix. This process is what we refer to as a dot product or sometimes inner product. When we have two vectors of equal length \\(x\\) and \\(y\\) the dot product is \\[x \\cdot y = x_1y_1 + x_2y_2 + \\ldots + x_n y_n\\] A dot product begins with two equal length vectors and returns a single number (i.e. a scalar). Consider the matrix multiplication in (4.2). We first multiply each element of row 1 of A (\\(a\\; b\\)), times the corresponding elements of column 1 of B (\\(m\\; n\\)), sum these products, and place the sum in the first row, first column of the resulting matrix. We then repeat this for each row of A and each column of B. \\[\\begin{align} \\tag{4.2} \\mathbf{AB} &amp;= \\left( \\begin{array}{cc} \\left( am + bn \\right) &amp; \\left(ao+bp \\right)\\\\ \\left(cm + dn \\right) &amp; \\left(co + dp \\right) \\end{array}\\right) \\end{align}\\] To do this, the number of columns in the first matrix must equal the number of rows in the second matrix. It also means that the resulting matrix will have the same number of rows as the first matrix, and the same number of columns as the second matrix. Multiplying a \\(2 \\times 2\\) matrix by a \\(2 \\times 1\\) results in a \\(2 \\times 1\\). Multiplying a \\(3 \\times 3\\) matrix by a \\(3 \\times 1\\) results in a \\(3 \\times 1\\). We cannot multiply a \\(2 \\times 1\\) matrix by a \\(2 \\times 2\\) because the number of columns in the first matrix (1) does not match the number of rows in the second matrix (2). Let’s define two \\(2 \\times 2\\) matrices, M and N, filling in one by rows, and the other by columns. (M &lt;- matrix( 1:4 , nrow=2, byrow=TRUE)) ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 (N &lt;- matrix( c(10, 20, 30, 40), nrow=2)) # byrow=FALSE is the default. ## [,1] [,2] ## [1,] 10 30 ## [2,] 20 40 Adding these matrices is simple. Here we do the first element by hand, and then sum the matrices all at once. # 1 + 10 M[1,1] + N[1,1] ## [1] 11 M + N ## [,1] [,2] ## [1,] 11 32 ## [2,] 23 44 To mulitply M and N, we multiply and then sum the first row of \\(M\\) by the first column of \\(N\\), and make this element \\(a_{11}\\) of the resulting matrix product. # 1*10 + 2*20 M[1,1] * N[1,1] + M[1,2] * N[2,1] ## [1] 50 This is the dot product. In R, we must use %*% to signify that we mean matrix multiplication. M %*% N ## [,1] [,2] ## [1,] 50 110 ## [2,] 110 250 If we multiply M times a \\(2 \\times 1\\) matrix D, what should we get? D &lt;- matrix(c(100, 200), nrow=2) M %*% D ## [,1] ## [1,] 500 ## [2,] 1100 # note that we cannot perform D %*% M Make sure you could write out the multiplication and summation for each element in the resulting matrix. The transpose of M is \\(\\mathbf{M^T}\\) M; t(M) ## [,1] [,2] ## [1,] 1 2 ## [2,] 3 4 ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 We use the transpose of A to calculate reproductive value, later in the chapter. 4.3 Decomposing A A slightly different way to conceptualize our transition matrix is to consider it the three separate matrices, one each for growth, survival, and fecundity, \\[\\mathbf{ A = GS + F }\\]. Survival, S, and growth, G, have these elements: each stage \\(j\\) has its own probability of survival \\(s_j\\), which describes survival of each stage from \\(t\\) to \\(t+1\\). each survivor in stage \\(j\\) will grow or regress into a different stage, or remain in the same stage, with probability \\(g_{ij}\\). In a demographic context, fecundity, F, is the surviving number of offspring produced by the average individual in stage \\(i\\). Sometimes this is a complete black box, in which we can only count the adults in year \\(t\\) and the offspring in year \\(t+1\\). Other times, we can use estimates of the probability that an individual in stage \\(i\\) reproduces at all, the average number of offspring of an individual that does actually reproduce, and the survival and growth of the adults or the resulting offspring. It all depends on the detail we have of our study system. And, of course, it depends heavily on whether we census our population shortly before reproduction (pre-breeding census), or shortly after reproduction (post-breeding census). For our Western Toad (Fig. 4.2), this results in \\[\\begin{equation*} \\tag{4.3} \\mathbf{A = GS + F} = \\left( \\begin{array}{cc} 1-\\mathrm{P} &amp; 0 \\\\ \\mathrm{P} &amp; 1 \\end{array} \\right) \\left( \\begin{array}{cc} \\sigma_j&amp;0\\\\ 0 &amp; \\sigma_a \\end{array} \\right) + \\left( \\begin{array}{cc} 0 &amp; \\rho \\phi \\sigma_e \\sigma_t \\sigma_m \\\\ 0 &amp; 0 \\end{array} \\right) = \\left( \\begin{array}{cc} \\sigma_j (1-\\mathrm{P}) &amp; \\rho \\phi \\sigma_e \\sigma_t \\sigma_m \\\\ \\sigma_j \\mathrm{P} &amp; \\sigma_a \\end{array} \\right) \\end{equation*}\\] where \\(\\sigma_j,\\,\\sigma_a\\) are survival of juveniles and adults, and P is the probability of juvenile growth, given survival. If an adult survives it always remains an adult (\\(g_{22}=1\\)) and never regresses (\\(g_{12}=0\\)). Fecundity occurs only in adults, and it is the product of the sex ratio (\\(\\rho\\)), average clutch size per female (\\(\\phi\\)), egg survival (\\(\\sigma_e\\)), survival of tadpoles (\\(\\sigma_t\\)), and the overwintering survival of the metamorphs (\\(\\sigma_m\\)).27 Vonesh and de la Cruz went further and added density-dependence using a term for the negative effects of high tadpole density on tadpole survival and growth. We do not show that here, but regardless how complex the natural history gets, we can build natural history into our models. 4.4 A three stage model Now we describe a three-stage model of a plant population. Like our amphibian example, it is a pre-breeding model, relying on a pre-breeding census. Nonetheless, it includes a seed stage for the seed bank, where seeds may be more than one year old. Eleanor Pardini et al. (n.d.) and colleagues modeled garlic mustard (Alliaria petiolata), a biennial plant species that is an exotic invasive species in the eastern deciduous forest of the U.S. The stages they choose to represent were those present in May: seeds in the soil seed bank, 1–2 month old immature rosettes, and adults (Fig. 4.5. Figure 4.5: The life cycle of garlic mustard using a post-breeding census (Pardini et al. 2009). The census takes place in May of each year. Each arrow represents the transition from May to May. Seeds germinate in early spring and become rosettes (basal leaves near the soil surface). The rosettes experience mortality all summer, fall, and winter. Surviving rosettes become reproductive adults the following spring a summer. Adults flower and are pollinated in June, after which the fruits ripen and seeds mature. Seeds overwinter for at least six months before germinating in the spring. Not all seeds germinate, but they may remain viable in the seed bank for several years. Thus, the complete life cycle at least two years. Once the seeds germinate, the plant requires over a year to reach maturity, and produce flowers, fruits and seeds. Let’s work through these probability transitions. \\(s_1\\), a germinated seed survives as a rosette. \\(s_2\\), surviving from May to August as a rosette. \\(s_3\\), surviving from August to early May and becoming a reproductive plant. \\(v\\), a seed is viable (survives and can germinate). \\(g_1\\), a viable seed germinates in the first season, or \\(1-g_1\\) remains ungerminated. \\(g_2\\), a viable seed germinates in the second season or \\(1-g_2\\) does not. Fecundity, \\(f\\), is the average number of seeds per reproductive plant. The transition matrix A would thus be \\[\\begin{equation*} \\tag{4.4} \\mathbf{A} = \\left( \\begin{array}{ccc} 1-g_2 &amp; 0 &amp; v(1-g_1)f \\\\ g_2 s_1 &amp; 0 &amp; v g_1 s_1 f \\\\ 0 &amp; s_2 s_3 &amp; 0 \\end{array} \\right) \\end{equation*}\\] Put into your own words each of the transition elements. What about the transition from adult to rosette? Did the plant shrink? While perennial plants can get smaller, or regress, that is not what happens here. In this transition, the adult in May gets pollinated, develops fruits, the seeds mature and are deposited on the soil late that summer or fall. Those seeds are survive overwinter, germinate in early spring, and grow into rosettes that summer, and survive until the next census in May. In that way, stage 3 (adult) contributes to stage 2 (rosette) through reproduction plus survival and growth. The transition from adult to seed, \\(p_{13}\\), occurs only when the seeds do not germinate after the first winter, but spend another year in the seed bank in the soil. Once we have the transition matrix, we can use it to characterize many features of the population, including the finite rate of increase (\\(\\lambda\\)), the predicted relative abundances of the various stages, and the relative importance of each separate transition \\(p_{ij}\\) for the long term population growth rate. We will do this in a later section, but first will explore projection. It is frequently useful to acutally project the population, one year at a time, into the future. 4.5 Projection Projection is the modeling of a population through time, for prediction under one or another set of assumptions. In practice, we use matrix multiplication to project stage- or structured populations. Matrix multiplication does all these calculations for us. We let A be our square demographic transition matrix, with one row and one column for each stage. Let \\(\\mathbf{N}_t\\) be a one-column matrix of stage sizes, with one row for each stage. Matrix multiplication allows us to project the population, \\(\\mathbf{A}\\mathbf{N}_t = \\mathbf{N}_{t+1}\\). To project a population for multiple years, we use a for-loop. We used this in the previous chapter for an unstructured population. Here we multiply our transition matrix by the current year’s abundances projecting next year’s abundances. All we need to specify are the transition matrix, starting stage abundances for \\(t=0\\), and the number of years through which we want to project. Here we define a transition matrix, \\(\\mathbf{N}_0\\), and a numbers of time steps to project. A &lt;- matrix( c(.1, 2.0, .3,.4), nrow=2, byrow=T) N0 &lt;- matrix(c(100, 1), nrow=1) years &lt;- 6 To do the for-loop, we need an zeroes matrix to hold \\(n\\) for each of the years of each of the stages, including for our first year. We start by filling our matrix with zeroes and “binding” the rows in \\(\\mathbf{N}_0\\) onto the top of our zeroes matrix as the first row. N.proj1 &lt;- matrix( 0, nrow=years, ncol=nrow(A)) colnames(N.proj1) &lt;- c(&quot;Juv&quot;, &quot;Adult&quot;) N.proj2 &lt;- rbind(N0, N.proj1) Now we perform the iteration with the for-loop and plot the result. Note how we do the multiplication for the current year \\(t\\) and put the result in the next year \\(t+1\\). # Project, then... for(t in 1:years) {N.proj2[t+1,] &lt;- A%*%N.proj2[t,]} # ...rearrange and plot N.proj.data &lt;- data.frame(Year=0:years, N.proj2) npd &lt;- gather(N.proj.data, Stage, Abundance, -Year) ggplot(npd, aes(Year, Abundance, linetype=Stage)) + geom_line() Figure 4.6: Projection of a population showing transient dynamics. In the first seven years, we see the abundances of the two stages bounce around. These are transient dynamics that, in our density-independent models, will fade away over time. 4.6 Analyzing the transition matrix Projection is very important for many reasons, especially for stochastic models or for very complicated models. However, we also get some of our best insights through direct analysis the transition matrix using eigenanalysis (Caswell 2001). The features we learn about a structured population using eigenanalysis are best thought of as predictions, attractors, or long term averages, assuming that the transition elements don’t change. This is a big assumption, but understanding it helps us interpret the analysis appropriately. Once you have obtained the transition matrix, \\(\\mathbf{A}\\), you can analysis it using eigenanalysis to estimate \\(\\lambda\\), the finite rate of increase, stable stage structure, reproductive value, and sensitivities and elasticities. Below, we explain each of these quantities. 4.6.1 Eigenanalysis Eigenanalysis is a mathematical technique that summarizes multivariate data. Ecologists use eigenanalysis frequently, for (i) multivariate statistics such as ordination, (ii) local stability analyses with two or more species, and (iii) analyzing population transition matrices. Eigenanalysis is simply a method to transform a square matrix into independent, or orthogonal, pieces. These pieces are eigenvectors and their corresponding eigenvalues. There are the same number of eigenvalues (and eigenvectors) as there are columns in a matrix. In demography, the two of the most useful pieces are the dominant right eigenvalue and its corresponding right eigenvector. Eigenanalysis is a technique that finds all the solutions for \\(\\lambda\\) and \\(\\mathbf{w}\\) of \\[ \\tag{4.5} \\mathbf{Aw}=\\lambda \\mathbf{w} \\] where \\(\\mathbf{w}\\) is a column vector with the same number of rows as \\(\\mathbf{A}\\). If we write out eq. (4.5) for a \\(2 \\times 2\\) matrix, we would have \\[ \\tag{4.6} \\left( \\begin{array}{ccc} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22}\\\\ \\end{array} \\right) \\left( \\begin{array}[c]{c} w_{11}\\\\ w_{21} \\end{array} \\right) =\\lambda \\left( \\begin{array}[c]{c} w_{11}\\\\ w_{21} \\end{array} \\right) \\] For instance, we can perform eigenanalysis on this transition matrix. (A &lt;- matrix(c(0, .3, 2, .7), nrow=2)) ## [,1] [,2] ## [1,] 0.0 2.0 ## [2,] 0.3 0.7 (eA &lt;- eigen(A)) ## eigen() decomposition ## $values ## [1] 1.2 -0.5 ## ## $vectors ## [,1] [,2] ## [1,] -0.8574929 -0.9701425 ## [2,] -0.5144958 0.2425356 This gives us one eigenvalue per column of our transition matrix (values). Each eigenvalue has a corresponding eigenvector that is the corresponding column of the vectors matrix. Let’s use R to prove to ourselves that eq. (4.5) is what we say it is. Here we see for ourselves whether \\(\\mathbf{A}\\mathbf{w} = \\lambda \\mathbf{w}\\) for \\(i = 1\\). Below, we use the results of the previous eigenanalysis. (lambda1 &lt;- eA$values[1]) ## [1] 1.2 (w1 &lt;- eA$vectors[,1]) ## [1] -0.8574929 -0.5144958 cbind(A %*% w1, lambda.w=lambda1 * w1) ## lambda.w ## [1,] -1.0289915 -1.0289915 ## [2,] -0.6173949 -0.6173949 The first column is \\(\\mathbf{Aw}\\) and the second column is \\(\\lambda \\mathbf{w}\\). Sure enough, they look the same. Try doing the same exercise for the second eigenvalue and the second eigenvector, \\(i=2\\). Typically, the first eigenvalue and its corresponding eigenvector capture the most important features of the transition matrix. We call these the dominant eigenvalue, \\(\\lambda_1\\), and its corresponding eigenvector, \\(w_1\\). While first solution does not capture all of the information about our transition matrix, it is the most useful. There are an infinite number of solutions to this equation because solutions can just be simple multiples of the set found with eigenanalysis. Eigenanalysis finds a set in which the solutions are all independent of each other, and which capture all of the information in \\(\\mathbf{A}\\) in a particularly useful way. In this book, we will not delve into details of eigenanalysis beyond this. Here are some eigenanalysis takeaways: you can perform eigenanalysis only on square matrices (number of rows = number of columns). there are the same number of eigenvalues of A as there are columns of A. eigenvalues are usually complex numbers, having a real part and an imaginary part. the largest eigenvalue is the one with the largest geometric mean of the real and the imaginary parts with the sign (+,-) respected. the “dominant” eigenvalue is the largest one; R will return this as the first one. each eigenvalue has a corresponding eigenvector. the number of elements in each eigenvector is the same as the number of rows in A. What is important for us is how we use the results. Below, we describe how we use eigenanalysis to find (i) the long term asymptotic finite rate of increase \\(\\lambda\\), (ii) the stable stage distribution, and the the reproductive values of each stage. 4.6.2 Finite rate of increase The asymptotic annual growth rate or finite rate of increase is the dominant eigenvalue of the transition matrix. It has the same meaning as in geometric growth of an unstructured population. Eigenvalues are always referred to with the Greek symbol \\(\\lambda\\), and provide a solution to (4.5). The dominant eigenvalue of any matrix, \\(\\lambda_{1}\\), is the eigenvalue with the largest magnitude, and it is frequently a complex number. When we perform eigenanalysis, it is common to get complex numbers, with real and imaginary parts. The magnitude is the sum of the squared parts. With population transition matrices, \\(\\lambda_{1}\\) will always be positive and real. This will not be the case with other types of matrices we examine in later chapters. The dominant eigenvalue is the biggest one. We can find which one it is by asking R to tell us the index position \\(i\\) of the largest absolute value (the modulus) of the eigenvalues. In most cases, it is the first eigenvalue, as it is here. ( dom.pos &lt;- which.max( Mod(eA[[&quot;values&quot;]]) ) ) ## [1] 1 We use that index to extract the largest eigenvalue. We keep the real part, using Re(), dropping the imaginary part. (Note that although the dominant eigenvalue of a real transition matrix will always be real, R will include an imaginary part equal to zero (\\(0i\\)) as a place holder if any of the eigenvalues has a non-zero imaginary part). # extract the dominant eigenvalue and retain only its Real part ( L1 &lt;- Re(eA[[&quot;values&quot;]][dom.pos]) ) ## [1] 1.2 L1 is \\(\\lambda_1\\), the asymptotic finite rate of increase. This finite rate of increase has the same biological meaning as \\(\\lambda\\) in the previous chapter. 4.6.3 Stable stage distribution The predicted long term average relative abundance of the different life history stages or ages is called the stage distribution, that is, the distribution of individuals among the stages. A property of a stage structured population is that, if all the demographic rates (elements of the transition matrix) remain constant, its stage structure will approach a stable stage distribution, a stage distribution in which the relative number of individuals in each stage is constant. Note that a population can grow, so that the absolute number of individuals increases, but the relative abundances of the stages is constant; this is the stable stage distribution. If the population is not actually growing (i.e. \\(\\lambda=1\\)) and demographic parameters remain constant, then the population is stationary and will achieve a stationary stage distribution, where neither absolute nor relative abundances change. How do we find the stable stage distribution? It also turns out that \\(w_1\\) provides the necessary information. We scale the eigenvector \\(w_1\\) by the sum of its elements because we are interested in the distribution, which is defined by all stages summing to one. Therefore the stable stage distribution is \\[ \\tag{4.7} \\frac{w_1}{\\sum_{i=1}^s{w_1}} \\] where \\(s\\) is the number of stages. Once a population reaches its stable stage distribution each of the stages grows or shrinks exponentially. You might believe that if you consider that we can represent \\(\\mathbf{A}\\) with \\(\\lambda\\). 4.6.4 Calculating the stable stage distribution The dominant eigenvector, \\(w_1\\), is in the same position as the dominant eigenvalue. We extract \\(w_1\\), keeping just the real part, and divide it by its sum to get the stable stage distribution. # continuing from previous code... w1 &lt;- Re(eA[[&quot;vectors&quot;]][,dom.pos]) ssd &lt;- w1/sum(w1) round(ssd, 3) ## [1] 0.625 0.375 This shows us that if the transition matrix does not change over time, the population will eventually be composed of these relative abundances. We have claimed, without evidence, that with a constant transition matrix, the projected population will eventually reach a stable stage distribution and grow exponentially with a finite rate of increase of \\(\\lambda_1\\). Here we show an example. A &lt;- matrix(c(0, .3, 2, .7), nrow=2) # our tran. matrix N0 &lt;- c(Juveniles=1,Adults=10) # initial population steps &lt;- 8 # number of time steps # combine the stages of our initial population, and a zero matrix # with a column for each stage and a row for each time step N &lt;- rbind(N0, matrix(0, ncol=2, nrow=steps) ) # use a for-loop to project the population each year and store it. for(t in 1:steps) {N[t+1,] &lt;- A%*%N[t,]} # Sum the stages to get the total N N.total &lt;- rowSums(N) # For each year, divide each stage by the total to get # relative abundances and thus the distribution. proportions &lt;- N/N.total SD &lt;- data.frame(Year=0:steps, proportions) sdg &lt;- gather(SD, Stage, Proportion, -Year) # plot the distributions for succeeding years. ggplot(sdg, aes(Stage, Proportion)) + geom_col() + facet_wrap(~Year, nrow=3, ncol=3) If we sum the abundances of the different stages, we calculate total population sizes. With that, we can calculate an annual rate of increase \\(N_{t+1}/N_t\\). # using &quot;-&quot; in an index removes that element lambda.t &lt;- N.total[-1]/N.total[-(steps+1)] qplot(x=1:steps, y=lambda.t, geom=c(&quot;line&quot;, &quot;point&quot;)) + annotate(&quot;point&quot;, x = steps , y=L1, pch=1, size=3) Figure 4.7: Calculating an annual finite rate of increase from a projected population shows that the population will approach asymptotically a constant geometric rate of increase. Solid points are annual growth rate; the circular point is lambda(1) from eigenanalysis. Iterating the transition matrix to approximate \\(\\lambda_1\\) and \\(w_1\\) is actually called the power iteration method for eigenanalysis. 4.6.5 Reproductive value If the stage structure gives us one measure of the importance of a stage (its relative abundance), then the reproductive value gives us one measure of the importance of an individual in each stage. Reproductive value is the expected contribution of each individual to future reproduction. We characterize all individuals in a stage using the same expected reproductive value. We find the reproductive value associated with each stage by solving for the dominant left eigenvector \\(\\mathbf{v}\\), where \\[ \\tag{4.8} \\mathbf{vA}=\\lambda\\mathbf{v}. \\] Like the relation between the dominant right eigenvector and the stable stage distribution, this vector is actually proportional to the reproductive values. Unlike the stable stage distribution, we scale it so that all reproductive values are relative to that of the first stage (e.g. juveniles or seeds). \\[ \\tag{4.9} \\frac{v_1}{v_{1[1]}} \\] We find the left eigenvalues and -vectors by performing eigenanalysis on the transpose of the transition matrix. Transposition flips rows and columns, so that row 1 becomes column 1 and vice versa. We perform eigenanalysis, extracting just the dominant left eigenvector; we then scale it, so the stage 1 has a reproductive value of 1.0. tA &lt;- t(A) # transpose etA &lt;- eigen(tA) dom.pos &lt;- which.max(Mod(etA$values)) v1 &lt;- Re(etA$vectors[,dom.pos]) ( rv &lt;- v1/v1[1] ) ## [1] 1 4 Here we see that reproductive value, rv, increases with age or stage. This means that the expected reproductive value of an individual in the second stage is 4 times as great as that of an individual in the first stage. In general, reproductive value of individuals in a stage increases with increasing probability of reaching fecund stages. 4.6.6 Sensitivity and elasticity Sensitivity and elasticity tell us the relative importance of each transition (i.e. each arrow of the life cycle graph or element of the matrix) in determining \\(\\lambda\\). They do so by combining information on the stable stage structure and reproductive values. The stage structure and reproductive values each in their own way contribute to the importance of each stage in determining \\(\\lambda\\). The stable stage distribution provides the relative abundance of individuals in each stage. Reproductive value provides the expected contribution to future population growth of individuals in each stage. Sensitivity and elasticity combine these to tell us the relative importance of each transition in determining \\(\\lambda_1\\). Sensitivities are the direct contributions of each transition to determining \\(\\lambda_1\\). The sensitivity for the element \\(a_{ij}\\) of a transition matrix is the change in \\(\\lambda_1\\) that occurs when we change \\(a_{ij}\\) a small amount, or \\[\\delta \\lambda / \\delta a_{ij}\\]. It isn’t surprising, then, these are derived from the stable stage distribution and the reproductive values. Specifically, the sensitivities are calculated as \\[ \\frac{\\delta \\lambda}{\\delta a_{ij}}=\\frac{v_{1[i]}w_{1[j]}}{v_1\\cdot w_1} \\tag{4.10} \\] where \\(v_{i}w_{j}\\) is the product of each pairwise combination of elements of the dominant left and right eigenvectors, \\(v\\) and \\(w\\). Specifically, the numerator is generated by the reproductive value of the target stage and the stable stage distribution of the source stage, \\[ \\begin{pmatrix} v_1\\\\v_2 \\end{pmatrix} \\begin{pmatrix} w_1 &amp; w_2 \\end{pmatrix}= \\begin{pmatrix} v_1 w_1 &amp; v_1 w_2 \\\\ v_2 w_1 &amp; v_2 w_2 \\end{pmatrix} \\] In the denominator, the dot product, \\(\\mathbf{v} \\cdot \\mathbf{w}\\), is the sum of the pairwise products of each vector element, \\[v_{11}w_{11} + v_{12}w_{12} + \\ldots + v_{1n}w_{1n}\\]. Dividing the numerator by this sum causes the sensitivities to be relative to the magnitudes of \\(v\\) and \\(w\\). Let’s calculate sensitivities now. Because the stable stage distribution and the reproductive values are merely scaled versions of the dominant right and left eigenvectors, it doesn’t matter whether we use the unscaled eigenvectors, or the scaled stable stage distribution and reproductive values. vw &lt;- matrix(rv, nr=2, nc=1) %*% matrix(ssd, nr=1, nc=2) # or vw &lt;- v1 %*% t(w1); the numerator dot.prod &lt;- sum(rv*ssd) # or dot.prod &lt;- sum(v1 * w1) denominator (s &lt;- vw/dot.prod) ## [,1] [,2] ## [1,] 0.2941176 0.1764706 ## [2,] 1.1764706 0.7058824 These are the sensitivities, \\(\\delta \\lambda / \\delta a_{ij}\\), of each corresponding transition element. You will always get a sensitivity for every position in this matrix, even when the transition is zero, \\(a_{ij}=0\\). We just ignore those, but by convention, usually include them. These sensitivities are the relative change in \\(\\lambda_1\\) for an absolute change in the element. For instance, it is the relative effect on lambda of increasing \\(a_{21}\\) from 0.3 to 0.31, or \\(a_{22}\\) from 0.7 to 0.71. The largest of the sensitivities we just calculated is that for \\(p_{21}\\), surviving from the first stage to the second stage. This means that small changes to \\(p_{21}\\) have larger effects on \\(\\lambda_1\\) than do small changes to \\(F_2\\) or \\(p_{22}\\). As \\(\\delta \\lambda / \\delta a_{ij}\\), the sensitivities are the slope of the line relating the magnitude of \\(\\lambda_1\\) to the matrix element. Figure 4.8: Sensitivities of lambda to transition elements are slopes. The dotted line is the calculated sensitivity of lambda to A[2,1], because it is the slope evaluated at A[2,1]. Elasticities are sensitivities that have been weighted by the transition probabilities. Recall that sensitivities are the effects on lambda of a small absolute change in transition matrix elements. In contrast, elasticities are the effects on lambda of a proportional change in a transition element influences \\(\\lambda_1\\)—how does a 1% increase in seed production, or a 1% decline in juvenile survival influence \\(\\lambda_1\\)? For these answers, we need to adjust sensitivities to account for the relative magnitudes of the transition elements, and this provides the elasticities, \\(e_{ij}\\). Elasticities are relative sensitivities, and are defined as \\[ e_{ij}=\\frac{\\delta \\lambda/\\lambda}{\\delta a_{ij}/a_{ij}} = \\frac{a_{ij}}{\\lambda}\\frac{\\delta \\lambda}{\\delta a_{ij}}. \\] These are also equal to \\[e_{ij}= \\frac{\\delta \\log \\lambda}{\\delta \\log a_{ij}}.\\] Like sensitivities, we can think of elasticities as slopes. Calculating these in R is easy. e &lt;- (A/L1) * s (round(e, 3)) ## [,1] [,2] ## [1,] 0.000 0.294 ## [2,] 0.294 0.412 Now we see that survival by adults (\\(p_{22}\\)) has the biggest effect on \\(\\lambda_1\\). Why the difference between sensitivities and elasticities? Because the elasticities reflect the effect of a proportional change (e.g., 1%) of the elements, whereas sensitivities reflect the effect of a change by a constant amount (e.g., 0.01) of each element. Note that elasticities are relative to each other, in that they sum to 1.0. This is an especially nice feature of elasticities because it makes it easier to compare elasticities among different matrices and different organisms. Once we have the sensitivities and elasticities, we can really begin to see what is controlling the growth rate of a stage (or age) structured population. They provide us with the predicted effects on \\(\\lambda_1\\) of a proportional change in a demographic rate. This is particularly important in the management of invasive (or endangered) species where we seek to have the maximum impact for the minimum amount of effort and resources (Caswell 2001; Ellner and Guckenheimer 2006). We can use these to help predict how a population might respond to natural phenomena or management practices that affect one stage or another. All of these details can get very confusing, and smart people don’t always get it right. Therefore, get expert advice (Caswell 2001; Ellner and Guckenheimer 2006), and remember that the stages of life cycle graph and matrix are the stages that you collect at one point in time, and an arrow or transition element has to include everything that happens from one census period to the next. 4.7 Integral projection What do we do if our stages seem like arbitrary categories along a continuous scale? What if size is easy to measure accurately and is a really good predictor of demographic rates, and these rates vary continuously with size? How do we decide on size classes? How do we draw seemingly arbitrary divisions between different sizes? With integral projection, as opposed to matrix projection, we no longer have to worry about a particular number of stages or age classes. We select an individual-level state variable, such as body mass, length, stem diameter, or even location, that is a useful predictor of demographic rates. We use this continuously varying state variable in place of stages or age classes. We rely on statistical methods, such as linear regression, to describe the relations between the individual-level state variable and survival, growth, and fecundity. We then combine those relations to model how individuals in a population are likely to change from one generation to the next. In many organisms, size is often a relatively good predictor of survival and fecundity. Within a population, size is often associated with age, learning, and resource acquisition. Size is also related to the onset of reproductive maturity and initiation of development of reproductive structures. Among reproductive individuals, size is often strongly correlated with per capita reproductive output. Integral projection can use size to model size-dependent demography. Integral projection models (IPMs) are based on the calculus of integration across continuous variables to combine information about size-dependent demographic rates and size distributions to project population abundances and sizes in the future. In practice, we rarely use the tools of integral calculus on which IPMs so solidly grounded. Instead, we approximate integration using very large matrices. As a simple example of this approximation, consider plant height that we measure using a meter stick. We assume that plant height is, in principle, a continuous variable that could take any real value between 0 and infinity. However, imagine that we only measure height to the nearest centimeter, and thereby create 100 height categories. This measurement process chops up continuous variation into discrete categories. When implementing integral projection models, we typically combine different techniques that are associated with continuous variation (e.g., linear regression) and with discrete variation (e.g., matrix algebra). 4.7.1 A size-based IPM of smooth coneflower Rachel Collins and colleagues have been studying populations of an endangered coneflower, Echinecea laevigata, in southwest Virginia, USA. Smooth coneflower is a perennial rhizomatous herbaceous plant that is sparsely distributed across mid-Atlantic and southeastern states (plantsusda.gov). It requires open spaces with little canopy cover, such as meadows or early successional habitat. Collins marked each individual in selected populations, measured size of individual coneflower plants using total leaf area, which ranged from 3-950 cm\\(^2\\). Because she tagged individuals and tracked changes over time, she was able estimate survival and fecundity of different sized individuals. She also measured seed set (number of seeds per inflorescence) and recruitment. Recruitment is emergence from the seed, that is, germination, growth, and survival in the first year. In what follows, we see empirical data on growth, survival, and fecundity. These continuous data will allow us to produce matrices with very, very narrow size classes. The details require some understanding of probability densities, rather than probabilities, per se, but they are conceptually analogous. The continuous probability density analog of a matrix is referred to as a “kernel”. Regardless, the goal is the same – we want to use our understanding of growth, survival, and fecundity to estimate a matrix or kernel K where, \\[\\mathbf{K = GS + F}\\]. Next we show the the size-dependence of these processes, and the resulting kernels. In IPMs, it is common to use the logarithm of size rather than the original linear scale. This is because many processes scale with log-size. That is what we do here - all sizes are the natural log of leaf area. # vegetative coneflower data. data(coneflower) cf &lt;- coneflower # seed set data(coneflowerseeds) sf &lt;- coneflowerseeds # recruit sizes - not shown data(coneflowerrecruits) rs &lt;- coneflowerrecruits # recruit sizes - not shown Survival, S, from one year to the next depends on size. eda_s &lt;- ggplot(cf, aes(logA, surv)) + lims(x=c(0.5, 2.75)) + geom_jitter(height=.02, alpha=0.5) + geom_smooth(method=&quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)) + labs(title=&quot;Survival&quot;) eda_s Figure 4.9: Survival is represented as surviving (1) or not surviving (0). The probability of surviving to the next year, given a size in the first year is esitmated using logistic regression. Growth, G is really how the size of a plant in one year depends on its size in the previous year. # use only the plants alive in both years cfs &lt;- filter(cf, surv==1 &amp; !is.na(logAp)) eda_g &lt;- ggplot(cfs, aes(logA, logAp)) + geom_point() + geom_abline(intercept=0, slope=1, lty=2, col=&quot;blue&quot;) + labs(title=&quot;Growth, Stasis, Regr.&quot;) + geom_smooth(method=&quot;lm&quot;,col=&quot;red&quot;, se=) eda_g Figure 4.10: Growth is the relation between size at one time vs. size in another. The fitted estimate includes the 95% confidence interval. The dashed line is the 1:1 line; above this line is growth, while below it is regression to a smaller size. Next we tackle fecundity, F, which for us is estimated using the size-dependent probability of flowering, the size-dependent number of seeds produced by a flowering individual, the probability of a seed germinating and surviving to be a new recruit, and the size-distribution of new recruits. Typically, bigger individuals have a greater chance of flowering, and smooth coneflower is no exception. We estimate that chance using logistic regression. cff &lt;- filter(cf, surv==1 ) eda_f &lt;- ggplot(cfs, aes(logA, flower_p)) + geom_jitter(height=.02, alpha=0.5) + geom_smooth(method=&quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)) + labs(title=&quot;Flowering&quot;) eda_f Figure 4.11: Plants that are larger in the first year have a greater chance of flowering in the next year. It is also true that bigger plants might produce more seeds, although there is not a lot of evidence for that is these data. eda_sd &lt;- ggplot(sf, aes(logAs, seeds)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + labs(title=&quot;Seed set&quot;) eda_sd Figure 4.12: No compelling evidence that size influences seed set. Nonetheless, we will use this approach in estiamting fecundity, F. We also need to estimate establishment probability, or the chance that a seed germinates and survives until the following summer. Collins estimated that using seed baskets. These are mesh baskets with soil into which she placed a known number of seeds. They are placed in the ground and seedlings or recruits are counted the following year. # 50 seeds into each of baskets N &lt;- rep(50, 9) # no. of seeds planted in the fall that popped up and # survived into June success &lt;- c(5,8,11,10,1,0,4,5,5) Y &lt;- cbind(success, failure=N-success) germ.est &lt;- glm(Y ~ 1, family=&quot;binomial&quot;) # the point estimate of establishment success # backtransform from logistic regression. pr &lt;- 1/(1 + exp(-coef(germ.est)[1])) # plot the probability distribution of establishment x &lt;- sum(Y[,&quot;success&quot;]) nx &lt;- sum(Y[,&quot;failure&quot;]) # Use the Jeffreys interval, which is based on the Beta distribution # with priors of (1/2, 1/2) being the conjugate prior for the binomial. eda_pr &lt;- ggplot(data = data.frame(x = c(0, 0.5)), aes(x)) + stat_function(fun = dbeta, n = 501, args = list(shape1 = x+1/2, shape2=nx+1/2)) + labs(y=&quot;Prob(recruiting)&quot;, title=&quot;Seed basket recruitment&quot;) + scale_y_continuous(breaks = NULL) eda_pr Figure 4.13: Probability that seeds in one year establish as new recruits the following summer. We can use other data (not shown) to characterize the size distribution of new recruits, which are approximately log-normally distributed. m.log &lt;- mean(log10(rs$area17)) # mean of log-area of new recruits std.log &lt;- sd(log10(rs$area17)) # st. dev. of log-area of new recruits eda_C &lt;- ggplot(data = data.frame(x = c(0.4, 1.4)), aes(x)) + stat_function(fun = dnorm, n = 101, args = list(mean = m.log, sd = std.log)) + labs(y=&quot;Prob(recruit log-size x)&quot;, title=&quot;Distr. of recruit sizes&quot;) + scale_y_continuous(breaks = NULL) eda_C Figure 4.14: The size distribution of new recruits; we assume that this is independent of plant size in year t. First we estimate something from data, then we use it to build functions. I use code handed down on stone tablets from Ellner, Merow, and others. We start with a data frame to hold summaries. ## this sets up a list of the model parameters. These parameters will be estimated and recorded below. params=data.frame( surv.int=NA, surv.slope=NA, growth.int=NA, growth.slope=NA, growth.sd=NA, flowering.int=NA, flowering.slope=NA, seed.int=NA, seed.slope=NA, seed.sd=NA, recruit.size.mean=NA, recruit.size.sd=NA, establishment.prob=NA ) Next, we perform the analyses from which we extract means, linear relationships, and variation, and put this values into the above data frame. #survival regression surv.reg=glm(surv~logA,data=cf,family=binomial()) params$surv.int &lt;- coef(surv.reg)[1] params$surv.slope &lt;- coef(surv.reg)[2] # Growth gr.reg &lt;- lm(logAp ~ logA, data=cf) params$growth.int &lt;- coef(gr.reg)[1] params$growth.slope &lt;- coef(gr.reg)[2] params$growth.sd &lt;- sd(resid(gr.reg)) # flowering fl.reg=glm(flower_p~logA, data=cf,family=binomial()) params$flowering.int &lt;- coef(fl.reg)[1] params$flowering.slope &lt;- coef(fl.reg)[2] # seed set seed.reg &lt;- lm(seeds ~ logAs, data=sf) params$seed.int &lt;- coef(seed.reg)[1] params$seed.slope &lt;- coef(seed.reg)[2] params$seed.sd &lt;- sd(resid(seed.reg)) # recruitment params$establishment.prob &lt;- pr # recruit size distr. params$recruit.size.mean &lt;- m.log params$recruit.size.sd &lt;- std.log Here we make functions that will be able use the above relationships and the data frame to make the kernel. ## Make the kernel (cf. projection matrix) # Relies on the Riemann sum, using midpoints. Increase $n$ to decrease $h$ and improve accuracy (but reduce speed). # The variable &#39;y&#39; in the figures below is log10(Area). # 1. boundary points b, mesh points y and step size h # integration limits - these limits span the range of sizes observed in the data set, and then some. min.size=.9*min(c(log10(rs$area17), cf$logA,cf$logAp),na.rm=T) max.size=1.1*max(c(log10(rs$area17), cf$logA,cf$logAp),na.rm=T) # number of cells in the discretized kernel n=100 # boundary points (the edges of the cells defining the kernel) b = min.size + c(0:n)*(max.size-min.size)/n # mesh points (midpoints of the cells) y = ( b[1:n] + b[2:(n+1)] ) / 2 # width of the cells h = y[2]-y[1] ############# # 2. make component kernels par(mfrow=c(2,2)) # outer yields an outer product where each element is can be an arbitrary function. G=h*outer(y, y, FUN=g.zpz, params=params) # growth kernel image(y,y,t(G),main=&#39;G&#39;) # plot it P = G # placeholder;redefine P on the next line S=s.z(y,params=params) for(i in 1:n) P[,i]=G[,i]*S[i] # growth*survival kernel {image(y,y,t(P),main=&#39;GS&#39;) # plot it abline(0,1,lwd=3) }# plot 1:1, which represents stasis Fec=h*outer(y, y, f.zpz, params=params) # reproduction kernel image(y,y,t(Fec),main=&#39;F&#39;) # plot it K=P+Fec # full kernel #image(y,y,t(K),main=&#39;full kernel&#39;) # plot it # sometimes it&#39;s hard to see both because # the fecundity part of the kernel swamps the growth/survival part, # so here&#39;s a plotting trick to level out the kernel image(y,y,t(K)^.33,main=&#39;K&#39;, col=grey.colors(12, start=0, end=1, rev = TRUE)) # plot it Figure 4.15: The component kernels G, S, and F, that make up the full demographic projection kernel, K, for smooth cone flower. Unlike proection matrices, kernels scale both axes to start at size = 0 in the lower left corner. The color scaling of the full kernel differs slightly so that we can see the contributions of G, S, and F. 4.7.2 Population summaries Any question that we could answer using matrices, we can answer using kernels. We estimate the finite rate of increase, \\(\\lambda\\), the same way we did before. (lambda=Re(eigen(K)$values[1])) [1] 1.061195 The same is true for the stable size distribution, reproductive value, and elasticity. w.eigen=Re(eigen(K)$vectors[,1]) stable.dist=w.eigen/sum(w.eigen) v.eigen=Re(eigen(t(K))$vectors[,1]) repro.val=v.eigen/v.eigen[1] # The eigen-things can be combined to obtain the sensitivity and elasticity matrices. # 2. compute elasticity and sensitivity matrices v.dot.w=sum(stable.dist*repro.val)*h sens=outer(repro.val,stable.dist)/v.dot.w elas=matrix(as.vector(sens)*as.vector(K)/lambda,nrow=n) # 3. plot results par(mfrow=c(1,3)) plot(y,stable.dist,xlab=&quot;Size&quot;,type=&quot;l&quot;,main=&quot;Stable size distribution&quot;) plot(y,repro.val,xlab=&quot;Size&quot;,type=&quot;l&quot;,main=&quot;Reproductive values&quot;) image(y,y,t(elas),xlab=&quot;Size (t)&quot;,ylab=&quot;Size (t+1)&quot;,main=&quot;Elasticity&quot;) Figure 4.16: Descriptions of smooth coneflower demographics. 4.8 R packges for demography Caswell (2001) is a definitive reference text for matrix models. Ellner and Guckenheimer (2006) provides an excellent introduction, and I am sure there are many other excellent texts as well. Stubben and Milligan (2007) and Stott, Hodgson, and Townley (2018), and de la Cruz (2019) provide R packages for stage-based matrix models with methods that go well beyond this text. In addition, there are several other packages for analyzing life tables and human demography. Ellner, Childs, and Rees (2016) is probably the best source for understanding IPMs. The R package IPMpack (Metcalf et al. 2014) is an excellent package to implement and analyze IPMs. 4.9 Exploring a real population Crouse, Crowder, and Caswell (1987) performed a demographic analysis of an endangered sea turtle species, the loggerhead (Caretta caretta). Management of loggerhead populations seemed essential for their long term survival, and a popular management strategy had been and still is to protect nesting females, eggs, and hatchlings. The ground breaking work by Crouse28 and her colleagues compiled data to create a stage-based projection matrix to analyze quantitatively which stages are most important and least important in influencing long-term growth rate. This work led to US Federal laws requiring that US shrimp fishermen use nets that include Turtle Excluder Devices (TEDs, https://www.fisheries.noaa.gov/southeast/bycatch/turtle-excluder-device-regulations ). Crouse et al. determined a transition matrix, A, for their loggerhead population: \\[\\begin{array}{c} H\\\\J_s\\\\J_l \\\\sub \\\\ B_1 \\\\B_2 \\\\ M \\end{array} \\left( \\begin{array}{cccccccc} 0&amp; 0&amp; 0&amp; 0&amp; 127&amp; 4&amp; 80\\\\ 0.6747&amp; 0.7370&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0.0486&amp; 0.6610&amp; 0&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0.0147&amp; 0.6907&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0&amp; 0.0518&amp; 0&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 0.8091&amp; 0&amp; 0\\\\ 0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0.8091&amp; 0.8089 \\end{array} \\right)\\] A &lt;- matrix( c(0, 0, 0, 0, 127, 4, 80, 0.6747, 0.7370, 0, 0, 0, 0, 0, 0, 0.0486, 0.6610, 0, 0, 0, 0, 0, 0, 0.0147, 0.6907, 0, 0, 0, 0, 0, 0, 0.0518, 0, 0, 0, 0, 0, 0, 0, 0.8091, 0, 0, 0, 0, 0, 0, 0, 0.8091, 0.8089), nrow=7, ncol=7, byrow=TRUE) eigen(A)$values ## [1] 0.9450310+0.0000000i 0.7461702+0.2130565i 0.7461702-0.2130565i ## [4] 0.3716668+0.0000000i 0.2654528+0.0000000i -0.0884455+0.1195997i ## [7] -0.0884455-0.1195997i Draw by hand two different types of life cycle graphs for this loggerhead population. Include the matrix elements associated with each transition. Use eigenanalysis to determine \\(\\lambda_1\\). Explain what this tells us about the population, including any assumptions regarding the stable stage distribution. Use eigenanalysis to determine the stable stage distribution. Use eigenanalysis to determine the elasticities. Which transition(s) are most influential in determining growth rate? What is the predicted long-term relative abundance of all stages? What do we call this? If your interest is to maximize long-term growth rate, in which stage(s) should you invest protection measures? Which stages are least likely to enhance long-term growth rate, regardless of protective measures? Start with \\(\\mathbf{N} = \\left(1000\\,10\\,10\\,10\\,10\\,10\\,10\\right)\\) and graph dynamics for all stages for 20 years. References "],
["DDgrowth.html", "5 Density-dependent growth 5.1 Continuous logistic growth 5.2 Dynamics around the equilibria — stability 5.3 Other forms of density-dependent growth 5.4 Discrete Density-dependent Growth 5.5 Maximum Sustained Yield", " 5 Density-dependent growth Let’s go back to our Song Sparrow (Melospiza melodia) data that we used to illustrate density-independent growth — now we graph all the data. Figure 5.1: Song Sparrow Melospiza melodia* counts, \\(N\\), from 1966–2003 and the relation between observed counts and annual growth rate determined from those counts, fit with ordinary least squares regression. See Chapter 3 for data source.* When we plot the annual per capita growth rate, \\(r_t = \\log (N_{t+1}/N_t)\\), as a function of \\(N\\), we see a pattern emerge. At low \\(N\\), \\(r&gt;0\\), whereas at high \\(N\\), \\(r &lt; 0\\). The annual growth rate depends on the size or density of the population. This is the sort of thing we mean we we use the term density-dependent growth. What might limit the population growth of these sparrows? Space available for male territories in their successional-scrub type habitat? Availability of seeds, fruits and invertebrates? We don’t necessarily know precisely what limits it, but if it is something related to their own abundance, then we can treat density as a proxy for the amount of limitation. Density-dependent population growth is the case where the per capita population growth rate depends statistically on the density of the population. When the slope of that relation is negative as it is in Fig. 5.1, we call this negative density-dependence. Negative density dependence a characteristic of a population undergoing intraspecific competition, where individuals of the same species compete for shared resources and have negative effects on their demographic rates. So, how would we represent this algebraically?29 5.1 Continuous logistic growth When it was originally introduced to ecology by Verlhurst in the late 1800s, he described the limits to population growth in terms of an upper limit \\(K\\), \\[\\begin{equation} \\frac{dN}{dt}= rN\\left(1-\\frac{N}{K}\\right) \\tag{5.1} \\end{equation}\\] where \\(K\\) is referred to as the carrying capacity. It is the population size where the negative effects of crowding prevent additional population growth. This happens in this equation because when \\(N=K\\), population growth rate falls to zero, because \\(\\left(1-K/K\\right)=1-1=0\\). Notice that the first part of this equation is exponential growth \\(rN\\), which is then modified by a negative effect of a growing population. As \\(N\\) grows, so does \\((1-N/K)\\) and causes \\(dN/dt\\) to shrink. As \\(N\\) approaches \\(K\\), \\(dN/dt\\) approaches zero, and the population stops changing and stays at \\(N=K\\). We refer to \\(K\\) as an attractor because \\(N\\) moves in a deterministic fashion toward \\(K\\) – \\(K\\) attracts \\(N\\). We explore the meanings of attractor and related terms throughout the book. Theory alert! Recall that Alan Hastings (2011) identified principles of macroscopic theory of population growth, that (i) populations exponentially, unless (ii) something prevents exponential growth. Here we see one of those somethings – negative density dependence. Another common representation of this model, the one we use here is \\[\\begin{equation} \\frac{dN}{dt}= rN\\left(1-\\alpha N\\right) \\tag{5.2} \\end{equation}\\] where \\(\\alpha=1/K\\). In this manner, \\(\\alpha\\) represents the per capita effect of an individual on its population growth rate. More on that next. 5.2 Dynamics around the equilibria — stability The stability of a system30 is a measure of how much it tends to stay the same, in spite of external disturbances or changes in the state of the system. The term stability has been given many more specific meanings, including resilience, resistant, reactivity, and permanence. We won’t go into these here, but one could consider them different facets of stability .31 We will focus on resilience, the tendency for a population to return an equilibrium, or be attracted toward an equilibrium, if it is perturbed from it. Consider the stability of a marble inside a wok. If the wok doesn’t move, then the marble just sits in the lowest spot on the bottom. If the wok is bumped, the marble jiggles and rolls around a bit, but settles back down to the bottom. This is a stable system because there is a point at the bottom of the bowl (the attractor) toward which the marble rolls — all points inside the wok allow the marble to find the lowest point (the attractor). For this reason, we call the collection of points on the inside surface of the wok the basin of attraction. The steeper the sides, the more quickly the marble moves toward the bottom. This rate is referred to as its resilience. To translate the notion of a basin into a population, let the position of marble inside the wok be the value of \\(N\\) at any particular point. Bumping the wok is any disturbance that causes a change in \\(N\\). The slope of the sides of the wok reflects the biology and its mathematics that cause \\(N\\) to move quickly or slowly back toward the bottom. For the logistic model, this rate is determined by \\(r\\) and \\(\\alpha\\), and also by \\(N\\) itself. The attractor at the very bottom of the bowl is the population’s carrying capacity, \\(K=1/\\alpha\\).32 When we imagine a marble in a wok, it becomes easy to envision \\(K\\) as an attractor at the bottom of the bowl. That is why we consider the carrying capacity a stable equilibrium point, or attractor, even if other factors, such as a disturbance, may cause \\(N\\) to deviate from it. The equilibrium we have focused on has been \\(K\\), but recall that \\(N=0\\) is also an equilibrium. This equilibrium is actually the edge of the wok — the slightest jiggle, and the marble falls in and moves toward the center of the wok, \\(K\\). The biological analog of this “jiggle” is the additional of one or a very small numbers of individuals to an otherwise extinct population. For example, consider that a sterile Petri dish with nutrient agar has an E. coli population size of zero. If that E. coli \\(N=0\\) gets “perturbed” with a single added cell, the population will move quickly toward its carrying capacity \\(K\\). In this sense, \\(N=0\\) is an equilibrium, but it is an unstable equilibrium. We also call such an unstable equilibrium a repeller. 5.2.1 Analytical linear stability analysis We are interested in the dynamics or stability of \\(N\\) at each of the equilibria, \\(N^*\\). Here we use analytical linear stability analysis to show mathematically what we described above with the marble and the wok. While somewhat limited in its scope, linear stability is nonetheless a powerful technique for dynamic model analysis. In a nutshell, what we do is determine whether the growth rate, which is zero at each equilibrium, becomes positive or negative in response to a small change in \\(N\\). That is, if \\(N\\) takes a tiny step away from the equilbrium, does that tiny step shrink, or grow? If a tiny step results in a shrinking of that step, back toward the equilibrium, that demonstrates stability. If a tiny step results in growth and a bigger step, that demonstrates instability. That is what analytical stability analysis tells us. Consider a plot of the growth rate, \\(dN/dt\\) vs. \\(N\\) (Fig. 5.2). The equilibria, \\(N^*\\), are the \\(N\\) (\\(x\\)-axis) at which \\(dN/dt=0\\) (points a, d). Note where population growth rate is positive and where it is negative. What will happen to this population if it finds itself at \\(N=50\\)? It will grow, moving along the \\(x\\)-axis, until population growth rate slows so much that it comes to rest where \\(N=1/\\alpha=K=100\\). Thus, \\(N\\) changes until it converges on the equilibrium, \\(N^*\\), where \\(dN/dt=0\\). Alternatively at \\(N=110\\), \\(dN/dt\\) is negative, and so \\(N\\) shrinks back down to \\(K\\) (point d). This return toward \\(K\\) means that \\(K\\) is an attractor and a stable equilibrium. Next, consider \\(N=0\\), at point a; it cannot change on its own. However, if “perturbed” at all, with the addition of one or more individuals, then this “perturbation” will grow, sending \\(N\\) across the \\(x\\)-axis, away from \\(N=0\\), toward \\(N=K\\). This stasis at \\(N=0\\), and movement away from \\(N=0\\) with the slightest perturbation means that \\(N=0\\) is a repeller and an unstable equilibrium. Linear stability analysis will calculate the degree of attraction or repulsion at a local point. # Plot the phase portrait - use the phaseR package logisticPP &lt;- phasePortrait(logistic, ylim = c(-5, 105), parameters = c(1, 100), ylab=&quot;Population Growth Rate (dN/dt)&quot;, xlab=&quot;N&quot;) N &lt;- c(0, 10, 50, 100, 115) pop.growth.rate &lt;- expression( N * (1 - N/100) ) points(N, eval(pop.growth.rate), cex=1.5) text(N, eval(pop.growth.rate), letters[1:5],adj=c(.5,2)) Figure 5.2: Population growth rate, \\(dN/dt\\), as a function of \\(N\\). This kind of graph is called a phase portrait or phase plane. Points a–e are labelled for convenience. At values of \\(N\\) associated with points \\(a\\) and \\(d\\), population growth rate equals zero. At values of \\(N\\) associated with \\(b\\) and \\(c\\) growth rate is positive, and for \\(e\\) growth rate is negative. Note this is growth rate as a function of \\(N\\) (time is not explicitly part of this graph) How fast will \\(N\\) return to \\(N^*=K\\), if perturbed? Let’s start by imagining that we have two populations with different intrinsic rates of increase (\\(r=1,\\,0.5\\)), and focus in on the growth rate at \\(N^*=K\\) (Fig. 5.3). For which one of these populations will \\(dN/dt\\) go to zero more quickly? If each population loses a few individuals and declines by \\(x\\) to \\(N^*-x\\), which population will return to \\(N^*\\) more quickly? Not surprisingly, it is the population with the higher \\(r\\) — when \\(r=1\\), its population growth rate (\\(y\\)-axis) is greater than when \\(r=0.5\\), and therefore will return at a faster rate. Note also that this same population (\\(r=1\\)) has a negative growth rate of greater magnitude at \\(N^*+x\\). Regardless of whether it gains or loses individuals, it will return to \\(N^*\\) more quickly than the population with the lower \\(r\\). Figure 5.3: Very close to an equilibrium, a population recovers from a perturbation, moving toward the equilibrium attractor, at rate \\(e^{-r}\\). Left, slopes of population growth \\(vs.\\) \\(N\\) near the equilibrium; around the equilibrium attractor, small decreases in \\(N\\) lead to positive growth rate, whereas small increases lead to negative growth rate; the population with the steeper slope changes faster. Right, regardless of the particular \\(r\\) of a population, a population recovers from a perturbation, moving toward the equilibrium attractor, at rate \\(e^{-r}\\) How do we quantify the rate of return at \\(N^*\\) so that we can compare two or more populations? The slope of the curve at \\(N^*\\) quantifies the rate of return, because the slope is the exponential return rate. To calculate the slope of a curve we use calculus, because the slope of a curve is a derivative. In this case, we need the derivative of the growth rate (\\(dN/dt\\)) with respect to the variable on the \\(x\\)-axis, \\(N\\). Such a derivative is called a partial derivative. Therefore we need the partial derivative of growth rate, with respect to \\(N\\). This will be the slope of the growth rate with respect to \\(N\\). To find the partial derivative, let us denote the population growth rate as \\(\\dot{N}=dN/dt\\) (“N-dot”), \\[\\begin{equation} \\label{eq:dot} \\dot{N} = rN\\left(1-\\alpha N\\right). \\end{equation}\\] \\(\\dot{N}\\) is a common symbol for a time derivative such as a growth rate, and we use it here merely to simplify the notation. Given \\(\\dot{N}\\), its partial derivative with respect to \\(N\\) is \\[\\begin{equation} \\tag{5.3} \\frac{\\partial \\dot{N}}{\\partial N} = r - 2r\\alpha N. \\end{equation}\\] Further, we are interested in the equilibrium, where \\(N = 1/\\alpha\\). If we substitute this into eq. and simplify, this reduces to \\[\\begin{equation} \\label{eq:pdlog2} \\frac{\\partial \\dot{N}}{\\partial N} = -r \\, . \\end{equation}\\] At \\(N^*=1/\\alpha\\), the slope is \\(-r\\). *This negative slope at the equilibrium demonstrates the stability of this equilibrium. Near \\(N^*\\), population growth rate is \\(-rx\\).33 That is, the rate of change of \\(x\\) (Figs. 5.3) is \\[\\begin{equation} \\tag{5.4} \\frac{dx}{dt} = -rx \\end{equation}\\] This allows us to pretend that the perturbation will diminish exponentially, because the growth rate is constant. We say “pretend,” because we realize that this rate applies only in the small region where we can assume the slope is a straight line. We can describe the size of \\(x\\) at any time \\(t\\) by integrating this well-known differential equation with respect to time as \\[\\begin{equation} \\tag{5.5} x_t = x_0e^{-r t} \\end{equation}\\] where \\(x_0\\) is the size of the initial displacement relative to the equilibrium, and \\(x_t\\) is the size of the displacement at time \\(t\\) relative to the equilibrium. If we choose an \\(x_t\\) carefully, and do so for any and all such analyses, we can determine the time required to reach \\(x_t\\) and we call that time the characteristic return time. To determine the characteristic return time, we will let \\(x_t=x_0/e\\), thus defining the characteristic return time as the amount of time required to reduce the perturbation by 63% (i.e. \\(1/e\\)). We can solve for \\(t\\) by dividing through by \\(x_0\\) and taking the \\(\\log\\) of both sides, \\[\\begin{align} \\tag{5.6} \\frac{x_0}{e} &amp;= x_0e^{-r t}\\\\ \\log\\left(e^{-1}\\right) &amp;= -r t\\\\ t &amp;= -\\frac{1}{\\left(-r\\right)}. \\end{align}\\] Thus we see return time, \\(t\\), here is a positive number, with the same units as \\(r\\), and depends on the slope of the the growth rate with respect to \\(N\\). It also depends on the assumption of linearity very close to the equilibrium. To review, we took the partial derivative of \\(dN/dt\\) with respect to \\(N\\), and then evaluated the partial derivative at \\(N^*\\) to get the rate of change of the perturbation, \\(x\\). A negative value indicates that the perturbation will decline through time, indicating a stable equilibrium or attractor. A positive value would indicate that the perturbation will grow over time, thus indicating an unstable equilibrium, or a repellor. We can use R’s minimal symbolic capabilities to get derivatives. Here we get the partial derivative and then evaluate it for the two equilibria (Fig. 5.2). alpha &lt;- 0.01; r &lt;- 1 pop.growth.rate &lt;- expression( r * N * (1 - alpha*N) ) # find the partial derivative of dNdt dF.dN &lt;- D(pop.growth.rate,&quot;N&quot;) dF.dN # here it is ## r * (1 - alpha * N) - r * N * alpha # set N equal to zero and the carrying capacity N &lt;- c(0, 1/alpha) # calculate the slopes of dN/dt vs. N at those two points eval(dF.dN) ## [1] 1 -1 The first value, 1, corresponds to the first value of \\(N\\), which is \\(N=0\\). Because it is positive, this indicates that the perturbation will increase with time, meaning that \\(N=0\\) is a repellor. The second value, \\(-1\\), is negative, and so indicates that the perturbation will decrease with time, meaning that \\(N=1/\\alpha\\) is an attractor. 5.2.2 Projection with numerical integration In simple density-independent growth, we were able to project a population using the integral of the exponential growth equation, \\(N_t=N_0 e^{rt}\\). As our models become more complex, we are no longer able to to do that. Instead, we use numerical integration to project models of continuous growth through time. We use numerical techniques that turn the infinitely small intervals of calculus (\\(dx\\), \\(dy\\)) into very, very small, but finite steps. Mathematicians and computer scientists have devised very clever ways of doing this very accurately and precisely. In R, the best package for this is deSolve, which contains several solvers for differential equations that perform numerical integration. We will access these solvers (i.e. numerical integraters) using the ode function in the deSolve package. This function, ode, is a wrapper for the underlying suite of functions that do the work. When we have an ordinary differential equation (ODE) such as logistic growth,\\(dN/dt = rN(1-\\alpha N)\\) we say that we “solve” the equation, over a particular time interval given a set of parameters and particular initial conditions or initial population size. For instance, we say that we solve the logistic growth model for time at \\(t=0,\\, 1 \\ldots \\, 20\\), with parameters \\(r=1\\), \\(\\alpha=0.001\\), and \\(N_0=10\\). Let’s do an example with ode, using logistic growth. We first have to define a function in a particular way. The arguments for the function must be, in order: time, a vector of populations, and a vector or list of model parameters. Note that this function is already in the primer package as clogistic(), so you don’t have to run this code to use the function. clogistic &lt;- function(time, y, parameters){ # y is a single value of N; if we have more than one population, # e.g. competition, then y would have two values, one for # each population. # parameters is a vector of...parameters.... # Both y and parameters have names for each element, # e.g., y &lt;- c(N=10) - see the text. with(as.list(c(y, parameters)), { # &quot;with&quot; creates an &quot;environment&quot; within which R looks for values # c() combines the two vectors into one # as.list() turns the resulting vector into a list # our differential equation for growth dN.dt &lt;- r * N * (1 - alpha * N) # making the function create output, which must be a list with # one element return( list( dN.dt ) ) } ) } While it isn’t necessary, we use with() to allow us to use the names of variables and parameters (Petzoldt 2003). This works only when y and p are vectors with named variables and parameters. Finally, we use return to cause the function to produce the derivative in a list. The following is equivalent, but slightly less readable or transparent. logistic2 &lt;- function(t, y, p){ dN.dt &lt;- p[1] * y[1] * (1 - p[2] * y[1]) return( list( dN.dt ) ) To solve the ODE, we will need to specify parameters–we wil have to tell R the values we want to use for \\(r\\) and \\(\\alpha\\). p &lt;- c(r=1, alpha = 0.001) We also need to tell R the size of the population to start with, at \\(t=0\\), or \\(N_0\\). We refer to this as the initial condition, and we will start with a population size of \\(N_0=1\\). We also need to supply the time steps we want as output. R will project the population size for all times up until and including the last time step we specify. # We name the state variable and the parameters y0 &lt;- c(N=1) t &lt;- 0:20 Now you put it all into ode(), with the correct arguments. The output is a matrix, with the first column being the time steps, and the remaining being your state variables. Because you loaded primer, the deSolve package should be loaded already.34 out &lt;- ode(y=y0, times=t, func=clogistic, parms=p) out[1:5,] ## time N ## [1,] 0 1.000000 ## [2,] 1 2.713627 ## [3,] 2 7.342179 ## [4,] 3 19.709440 ## [5,] 4 51.820737 We can plot the output as well. The deSolve package directs R to use special methods to plot output from ode. plot(out) Figure 5.4: Output from a numerical integration of logistic growth, where N0==10, r=1, alpha=0.001. Here we see the classic S-shaped curve of logistic growth. Regardless where we start, the population will always settle down on \\(K=1/\\alpha\\). Before reading on, predict the shape of this curve if: \\(r\\) is smaller, or larger. \\(\\alpha\\) is smaller, or larger. the initial population size is above \\(K\\) t=seq(0, 20, by=0.01); r &lt;- c(.5, 1.5) alpha &lt;- c(0.002, 0.001); N0 &lt;- c(10, 1500) input &lt;- expand.grid(r=r, alpha=alpha, N=N0) outdf &lt;- NULL #outdf &lt;- data.frame(time=NULL, N=NULL, N0=NULL, r=NULL, alpha=NULL) for(i in 1:nrow(input)) { y &lt;- c(N=input[i,&quot;N&quot;]) p &lt;- c(r=input[i,&quot;r&quot;], alpha=input[i,&quot;alpha&quot;] ) out &lt;- ode(y, times=t, fun=clogistic, p) out2 &lt;- cbind(out, N0=y, r=p[&quot;r&quot;], alpha=p[&quot;alpha&quot;]) outdf &lt;- rbind.data.frame(outdf, out2) } outdf$N0 &lt;- as.factor( outdf$N0 ) outdf$alpha &lt;- as.factor(outdf$alpha ) ggplot(outdf, aes(time, N, colour=N0, linetype=alpha) ) + geom_line() + facet_grid(r~., labeller=label_both) + theme_bw() Figure 5.5: How variation in logistic growth parameters influence the dynamics. We see that the refer to \\(K\\) as an attractor because \\(N\\) moves in a deterministic fashion toward \\(K\\). We explore the meanings of attractor and related terms throughout the book. The phaseR package has some sweet plotting functions for systems of 1 or two ODEs. We used it above for the phase portrait, and here we use it for the trajectories. # Plot the velocity field, nullclines and several trajectories ## These create arrows (vectors) whose length and direction ## reveal the velocity at different points logistic_flowField &lt;- flowField(logistic, xlim = c(0, 5), ylim = c(-1, 3), parameters = c(1, 2), points = 21, system = &quot;one.dim&quot;, add = FALSE) ## A logistic_nullclines &lt;- nullclines(logistic, xlim = c(0, 5), ylim = c(-1, 3), parameters = c(1, 2), system = &quot;one.dim&quot;) logistic_trajectory &lt;- trajectory(logistic, y0 = c(-0.5, 0.5, 1.5, 2.5), tlim = c(0, 5), parameters = c(1, 2), system = &quot;one.dim&quot;) Figure 5.6: A velocity field is kind of like a magnetic field, showing what rate and direction of trajectories throughout this space. A nullcline is an isocline where the rate of change is zero (the straight horizontal lines in this figure). Here r = 1, and K=2. 5.3 Other forms of density-dependent growth There are many forms of density-dependent growth, some of which will we describe below. Let’s start by decoupling the density-dependence of birth and death rates (Gotelli 2001). 5.3.1 Effects of N on birth and death rates Recall from chapter 3 that \\(r=b-d\\). Now we will let \\(b\\) and \\(d\\) be functions of population size \\(N\\) (\\(b=F(N)\\), \\(d=G(N)\\)). We could let \\(F(N)\\) and \\(G(N)\\) take a wide variety of different forms. For now, however, let’s say that \\(N\\) has linear effects on these rates so that \\[\\begin{align} b &amp;=b_0 - aN\\\\ d &amp;= d_0 + cN \\end{align}\\] which appear in Fig. 5.7. Figure 5.7: Per capita birth and death rates can be functions of density (dashed lines). The carrying capacity (K) occurs at the point where the per capita birth and death rates are equal. The solid line represents the per capita population growth rate, which is zero when N=K. Now population growth rate is \\[\\begin{align} \\frac{dN}{dt} &amp;= [(b_0-aN)-(d_0 + cN)] N\\\\ &amp; =[(b_0-d_0) - (a+c)N] N\\\\ &amp; = (b_0-d_0)(1-\\frac{a+c}{b_0-d_0}N)N \\end{align}\\] where the net negative effect of \\(N\\) on per capita population growth rate is \\[\\alpha = \\frac{a+c}{b_0-d_0}\\] where the numerator is the total direct negative effect of \\(N\\) on birth and death rates, and the denominator is \\(r\\), the net maximum per capita growth rate which occurs as \\(N\\) approaches zero. 5.3.2 Theta-logistic growth Here we explore a simple extension of the logistic model, the theta-logistic model, which adds a parameter to increase flexibility and generality. \\[\\begin{equation} \\tag{5.7} \\frac{dN}{dt} = rN\\left(1 - \\left(\\alpha N\\right)^\\theta \\right) \\end{equation}\\] Here \\(\\theta\\) is strictly positive (\\(\\theta&gt;0\\)); \\(\\theta=0\\) means zero growth, and \\(\\theta &lt; 0\\) would mean negative growth below \\(K\\), and unbounded positive growth above \\(K\\). Approximations of eq. (5.7) that allow \\(\\theta \\leq 0\\) are possible (Sibly et al. 2005), but the interpretation becomes strained. Here we make a function that we can use with ode(), the numerical integration function. You’ll need to run this code to use it later. thetalogistic &lt;- function(times, y, parms) { ## with() and as.list() create an environment in which R will see ## the named elements in `parms`. n &lt;- y[1] with(as.list(parms), { dN.dt &lt;- r * n * (1-(alpha*n)^theta) return( list( c(dN.dt) ) ) } ) } By varying \\(\\theta\\), we can change the linear density dependence of the simple logistic model to curvilinear density dependence (Fig. ). This curvilinearity arises because when \\(\\alpha N &lt; 1.0\\) (i.e. \\(0 &lt; N &lt; K\\)), \\[\\begin{align*} \\tag{5.8} \\left(\\alpha N\\right)^\\theta &amp;&lt; \\alpha N,\\quad \\theta &gt; 1\\\\ \\left(\\alpha N\\right)^\\theta &amp;&gt; \\alpha N,\\quad \\theta &lt; 1. \\end{align*}\\] In contrast, when \\(\\alpha N=1.0\\), then \\(\\left(\\alpha N\\right)^\\theta &lt; \\alpha N\\). This means that \\(\\theta\\) does not affect \\(K\\). When \\(\\theta &gt; 1\\), this weakens density dependence at low \\(N\\), so the population grows faster than logistic, all else being equal. When \\(\\theta &lt; 1\\), this strengthens density dependence at low \\(N\\), causing the population to grow more slowly than logistic, all else being equal. The effects of \\(\\theta\\) on density dependence controls the shape of relation between growth rate \\(vs\\). \\(N\\) (a.k.a. the production function, Fig. ). First, note that for a given \\(r\\), growth rate for \\(N&lt;K\\) increases with \\(\\theta\\). Second, note that the position of peak of the production function shifts to the right as \\(\\theta\\) increases. That is, as \\(\\theta\\) increases, the \\(N\\) at which the maximum growth rate occurs also increases. If we wanted to shift the peak growth rate to a higher \\(N\\) without also increasing the height of the peak, we could decrease \\(r\\) simultaneously. We could speculate on biological meaning of \\(\\theta\\) and the shape of the denisty dependence. For instance, very high \\(\\theta\\) suggests a threshold, wherein the population exhibits little density dependence until very close to \\(K\\). Perhaps this is related to territoriality, or a spatial refuge from predators. Alternatively, low \\(\\theta\\) might suggest resource preemption, wherein a small number of individuals can sequester large amounts of resources, but increasing \\(N\\) results in reduced preemption. For organisms with very plastic body sizes (plants, fish), this could mean that at low \\(N\\), average body size is large, but as \\(N\\rightarrow K\\), average body size decreases. While \\(\\theta\\), per se, is devoid of mechanism, discovering the magnitude of \\(\\theta\\) for different types of species could lead to the generation of new testable hypotheses about what controls populations. r &lt;- .75; alpha &lt;- 0.01; theta &lt;- c(.5, 1, 2); N &lt;- 0:110 ## Per capita PGR theta.out &lt;- sapply(theta, function(th) {1-(alpha*N)^th}) matplot(N, theta.out, type=&#39;l&#39;, col=1) abline(h=0) legend(&#39;topright&#39;, legend=paste(&quot;theta =&quot;, c(2, 1, 0.5) ), lty=3:1, bty=&#39;n&#39;) ## PGR thetaGR.out &lt;- sapply(theta, function(th) {r*N*(1-(alpha*N)^th)}) matplot(N, thetaGR.out, type=&#39;l&#39;, col=1) abline(h=0) ## r &lt;- 3.4 lines(N, r*N*(1-(alpha*N)^theta[1])) text(12, 24, &quot;r=3.4&quot;) prms &lt;- c(r = 0.75, alpha = 0.01, theta=1) t &lt;- seq(0,20, by=.1) thetaN &lt;- sapply(theta, function(th) {prms[&quot;theta&quot;] &lt;- th ode(y=1, times=t, thetalogistic, prms)[,2] } ) matplot(t, thetaN, type=&#39;l&#39;) Figure 5.8: Theta-logistic per capita rates, population growth rates, and dynamics for $ heta&lt;1$, $ heta=1$, and $ heta&gt;1$. In a review of population dynamics, Sibly et al. (2005) use theta-logistic density dependence to show that populations most frequently have a concave-up, $ heta &lt; 1$, pattern. 5.3.3 Allee effect The Allee effect is a positive relation between average individual fitness and population size (Drake and Kramer 2011). For us, this translates as a positive relation between per capita population growth rate and population size. An Allee effect is likely to arise in sexually reproducing populations. This occurs because at very low population sizes, male and female individuals are less likely to encounter each other and so mating frequency is very low. As population size increases, females and males are more likely to encounter each other, and mating increases. One way to represent this is with an additional term in our model, which incorporates a threshold population size, below which population growth rate is negative. Here \\(a\\) is the threshold population size, \\[\\begin{equation} \\frac{dN}{dt}= rN\\left(1-\\alpha N\\right)\\left(1 - \\frac{a+\\tau}{N+\\tau}\\right) \\tag{5.9} \\end{equation}\\] so that if the population size falls below the threshold, it cannot recover (\\(N&lt;a\\), \\(dN/dt &lt; 0\\)). Parameter \\(\\tau\\) is greater than 0, and controls how severe the consequence is for \\(N&lt;a\\). The smaller \\(\\tau\\) is, the more negative population growth becomes. A function to project this dynamic is available in primer as alogistic(). ## for simplicity, we let r=1 so we can ignore it here. pgrA &lt;- function(N, alpha, a, tau){ N*(1-alpha*N)*(1-(a+tau)/(N+tau)) } myData &lt;- data.frame( N=c(0, 110) ) # ggplot requires a data frame p &lt;- ggplot(data=myData, aes(x=N)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=pgrA, geom=&quot;line&quot;, n=1001, args=list(alpha = 0.01, a=20, tau=.1)) + labs(y=&quot;Population growth rate (dN/dt)&quot;, x=&quot;Population size (N)&quot;) + #theme_classic() + geom_hline(yintercept=0, lty=3)+ scale_x_continuous(expand = c(0, 0)) p Figure 5.9: The Allee effect the a positive relation bewteen population growth rate and population size, often best envisioned as a negative consequence of small population size. Here, the threshold population size is 20, meaning that \\(dN/dt &lt; 0\\), when \\(N &lt; 20\\). 5.3.4 The integral of logistic growth We might as well add that there is an expression for \\(N_{t}\\), analogous to \\(N_{t}=N_{0}\\exp(rt)\\) for exponential growth. If we integrate eq. (5.2) with respect to time, we have \\[\\begin{equation} N_{t}=\\frac{N_{0}e^{rt}}{1+\\alpha N_{0}\\left(e^{rt}-1\\right)}. \\label{fig:clogisticNt} \\end{equation}\\] Note the resemblance to the exponential equation. We have the exponential equation in the numerator, divided by a correction factor which starts at 1 when \\(t=0\\). The correction factor then grows with time, at a rate which is virtually the same as exponential growth but adjusted by \\(\\alpha\\) and scaled by \\(N_{0}\\). Thus when \\(t=0\\), and if \\(N_0\\) is small, we have near-exponential growth, decreased merely by a factor of \\(\\alpha N_0\\). 5.4 Discrete Density-dependent Growth The continuous logistic equation is probably our simplest example of population growth, aside from pure exponential growth. Here we describe the discrete-time version. Recall that the discrete time version of population growth rate is \\[\\frac{\\Delta N}{\\Delta t}=\\frac{N_{t+1}-N_t}{(t+1) - t}=N_{t+1}-N_t\\] because our time step is one (1) entire time unit (typically a year). The discrete time logistic function is therefore \\[\\begin{equation} N_{t+1} - N_t = r_d N_t\\left(1-\\alpha N_t\\right) \\tag{5.10} \\end{equation}\\] Here \\(r_d\\) has the same meaning it did in chapter 3, where \\(r_d = b-d-bd\\). When \\(r_d\\) is quite small in a slow growing population, this is very similar to the continuous form. However, as \\(r_d\\) becomes larger in a faster growing population, the dynamics can get quite exciting. Let’s explore the dynamics of this numerically by writing a function to project discrete logistic growth. A pre-written function is available in primer by the same name. To project a discrete time model, we have to project entire one year at a time. We did this for structured demographic models, and unstructured geometric growth and our sparrow simulation. We will do it here using a function in the deSolve package that imposes a one year time step, specifically for discrete time models, including difference equations.35 We set up the model as we did with the continuous time model. dlogistic &lt;- function (t, y, p) { N &lt;- y[1] with( as.list(p),{ N.diff &lt;- rd * N * (1 - alpha * N) return(list(N.diff)) }) } We then specific the parameters, the initial state or population size, and the time steps. Note that for a discrete time model the time steps must be annual increments. We then project the population. p &lt;- c(rd=1, alpha=.01) y &lt;- c(N=10) years &lt;- 0:10 outd &lt;- ode(func = dlogistic, y = y, times = years, parms = p, method = &quot;euler&quot;) outd &lt;- as.data.frame(outd) ggplot(outd, aes(x=time, N)) + geom_line() + geom_point() + annotate(&quot;text&quot;, x=1, y =1/p[&quot;alpha&quot;]+2, label=&quot;K = 1/alpha&quot;) Figure 5.10: Discrete growth can look a lot like continuous growth as long as the per capita growth rate is low. 5.4.1 Effects of \\(r_d\\) Changing \\(\\alpha\\) or \\(K\\) does not change radically the dynamics of this model. However, increasing \\(r_d\\) changes the dynamics a lot. This is in contrast to what happens in continuous logsitic growth. When we increase \\(r_d\\) sufficiently, we get stable limit cycles and if we raise \\(r_d\\) high enough, we get chaos.36. rd.v &lt;- seq(1.3, 2.8, by=.3) N0 &lt;- c(N=10); t = 0:20 Ns &lt;- sapply(rd.v, function(r) { p &lt;- c(rd=r, alpha=0.01) outd &lt;- ode(func = dlogistic, y = N0, times = t, parms = p, method = &quot;euler&quot;)[,2] } ) out &lt;- data.frame(t=t, Ns) names(out) &lt;- c(&quot;t&quot;, paste(&quot;rd=&quot;,rd.v, sep=&quot;&quot;)) out.l &lt;- pivot_longer(out, cols=-1, names_to=&quot;r.d&quot;, values_to=&quot;N&quot;) ggplot(out.l, aes(t, N) ) + geom_line() + facet_wrap(~r.d) Figure 5.11: How variation in \\(r_d\\) influences dynamics of discrete logistic growth. At low \\(r_d\\), we have simple asymptotic approach to \\(K\\). As \\(r_d\\) increases, we see the population overshoot the carrying capacity and exhibit damped oscillations. When \\(2 &lt; r_d &lt; 2.449\\), the population is attracted to two-point limit cycles. In this case, these two points are stable attractors. Regardless where the population starts out, it is attracted to the same two points, for a given \\(r_d\\). As \\(r_d\\) increases further, the number of points increases to a four-point limit cycle (e.g., at \\(r_d=2.5\\)), then an eight-point cycle, a 16-point limit cycle, and so on. These points are stable attractors. As \\(r_d\\) increases further , however, stable limit cycles shift into chaos (\\(r_d&gt;2.57\\)). Chaos is a non-repeating, deterministic fluctuating trajectory, that is bounded, and sensitive to initial conditions. May (1974) shocked the ecological community when he first demonstrated stable limit cycles and chaos using this model. His groundbreaking work, done on a hand calculator, showed how very complicated, seemingly random dynamics emerge as a result of very simple deterministic rules. Among other things, it made population biologists wonder whether prediction was possible at all. In general, however, chaos seems to require very special circumstances, including very high population growth. Is there a biological interpretation of these fluctuations? Consider some simple environment, in which small vegetation-eating animals with high reproductive rates eat almost all the vegetation in one year. The following year, the vegetation will not have recovered, but the animal population will still be very high. Thus the high growth rate causes a disconnect between the actual population size, and the negative effects of those individuals comprising the population. The negative effects of the actions of individuals (e.g., resource consumption) are felt by the offspring of those individuals, rather than the individuals themselves. We won’t belabor the point here, but it is certainly possible to extend this delayed density dependence to a wide variety of populations. The discrete logistic model has a built in delay, or time lag, of one time step, because the growth increment makes a single leap of one time step. This delay is missing from the analogous continuous time model because the growth increment covers an infinity small time step, thanks to the miracles of calculus.37 5.4.2 Bifurcations Up until now, we have examined \\(N\\) as a function of time. We have graphed it for different \\(\\alpha\\) and \\(N_0\\), but time was always on the \\(x\\)-axis. Now we are going to examine \\(N\\) as a function of \\(r_d\\), so \\(r_d\\) is on the \\(x\\)-axis. Specifically, we will plot the stable limits or attractors \\(vs\\). \\(r_d\\) (Fig. ??). What does it mean? For \\(r_{d} &lt; 2\\), there is only a single \\(N\\). This is what we mean by a stable point equilibrium, or point attractor. As long as \\(r_d\\) is small, \\(N\\) always converges to a particular point.38 When \\(2&lt;r_{d}&lt;2.45\\), then all of a sudden there are two different \\(N\\); that is, there is a two-point stable limit cycle. Note that when \\(r_d\\approx 2\\) these oscillations between the two point attractors around \\(K\\) are small, but as we increase \\(r_d\\), those two points are farther apart. The point at which the limit cycle emerges, at \\(r_d=2\\), is called a bifurcation; it is a splitting of the single attractor into two attractors. At \\(r_{d}\\approx 2.45\\), there is another bifurcation, and each the two stable attractors split into two, resulting in a total of four unique \\(N\\). At \\(r_{d}\\approx 2.53\\), there are eight \\(N\\). All of these points are periodic attractors because \\(N\\) is drawn to these particular points at regular intervals. As \\(r_d\\) increases the number of attractors will continue to double, growing geometrically. Eventually, we reach a point when there becomes an infinite number of unique points, that are determined by \\(r_{d}\\).39 This completely deterministic, non-repeating pattern in \\(N\\) is a property of chaos. Chaos is not a random phenomenon; rather it is the result of deterministic mechanisms generating non-repeating patterns. Here we perform more comprehensive simulations, and plot the point and periodic attractors vs. \\(r_d\\). First we pick some constraints for the simulation: the number of different \\(r_d\\), the sequence of \\(r_d\\) values, and the number of time steps. ## Iff you are interested.... num.rd &lt;- 1001 # the number of rd&#39;s you want rd.s &lt;- seq(1.5,3, length=num.rd) # the actual rd values t &lt;- 0:1000 # how long to run each population N0 &lt;- c(N=99) # N-zero ## do all the dynamical simulations putting each run ## into a column of a matrix. Ns &lt;- sapply(rd.s, function(r) { p &lt;- c(rd=r, alpha=0.01) outd &lt;- ode(y = N0, times = t, func = dlogistic, parms = p, method = &quot;euler&quot;)[,2] } ) out &lt;- data.frame(t=t, Ns) # put times to the front of the matrix names(out) &lt;- c(&quot;t&quot;, paste(&quot;rd=&quot;,rd.s, sep=&quot;&quot;)) # relabel columns out.last &lt;- subset(out, t &gt; 0.8*max(t)) # keep only the last 20% ## put the data in the &quot;long format&quot; out.l &lt;- pivot_longer(out.last, cols=-1, names_to=&quot;r.d&quot;, values_to=&quot;N&quot;) out.l &lt;- arrange(out.l, r.d, t) # re-order the data ## extract text out of the &#39;r.d&#39; label that is the numeric value text.values &lt;- substr(out.l$r.d, regexpr(&quot;=&quot;, out.l$r.d)+1, 100) ## convert the characters of &quot;1.5&quot; to the number 1.5 out.l$rd &lt;- as.numeric( text.values ) ## plot the stable limits to show the bifurcations ggplot(out.l, aes(rd, N)) + geom_point(pch=&quot;.&quot;) + theme_bw() Figure 5.12: Illustration of the long term dynamics of discrete logistic population growth. When a small change in a continuous parameter results in a change in the number of attractors (e.g. a single point equilibrium to a stable 2-point limit cycle), we call this a bifurcation. out.l.chaotic &lt;- subset( out.l, rd &gt; 2.6 ) ggplot(out.l.chaotic, aes(rd, N)) + geom_point(pch=&quot;.&quot;) + theme_bw() Figure 5.13: Illustration of the long term dynamics of discrete logistic population growth. When a small change in a continuous parameter results in a change in the number of attractors (e.g. a single point equilibrium to a stable 2-point limit cycle), we call this a bifurcation. There has been a great deal of effort expended trying to determine whether a particular model or real population exhibits true chaos. In any practical sense, it may be somewhat unimportant whether a population exhibits true chaos, or merely a higher order periodic attractor (Ellner and Turchin 2005). The key point here is that very simple models, and therefore potentially simple mechanisms, can generate very complex dynamics. Another very important characteristic feature of chaotic populations is that they are very sensitive to initial conditions. Thus emerges the idea that whether a butterfly in Sierra Leone flaps its wings twice or thrice may determine whether a hurricane hits the southeastern United States in New Orleans, Louisiana, or in Galveston, Texas.40 If we generate simulations where we vary initial population size by a single individual, we find that this can have an enormous impact on the similarity of two populations’ dynamics, and on our ability to predict future population sizes (Fig. @(fig:DDGChaosInitN)). Note how the populations start with similar trajectories, but soon diverge so that they experience different sequences of minima and maxima (Fig. @(fig:DDGChaosInitN)). This is part of what was so upsetting to ecologists about May’s 1974 paper — perhaps even the simplest deterministic model could create dynamics so complex that we could not distinguish them from random (May 1974). Over time, however, we came to learn that (i) we could distinguish random dynamics from some chaos-like dynamics, and (ii) the hunt for chaos could be very exciting, if most frequently disappointing (Becks et al. 2005; Constantino et al. 1995; Kendall, Prendergast, and Bjornstad 1998). We start with three populations, all very close in initial abundance, \\(N_0 \\in \\{97,98,99\\}\\). We then project the population with a \\(r_d\\) to generate chaos for 30 time steps. N.init &lt;- c(97,98,99) t &lt;- 0:30 p &lt;- c(rd=2.7, alpha=0.01) out &lt;- NULL for(i in 1:3){ # project the population N0 &lt;- c(N=N.init[i]) a &lt;- ode(y=N0, times=t, dlogistic, parms=p, method=&quot;euler&quot;) # fill a column with the initial value b &lt;- data.frame(a, N0=as.factor(N0)) # b now has cols: t, N, rd # store data in rows of out &quot;bind rows&quot; with rbind out &lt;- rbind.data.frame(out, b) } ggplot(data=out, aes(time, N, colour=N0, linetype=N0)) + geom_line() Figure 5.14: Effects of differences in initial population size on the short term and long term dynamics, and their correspondence, of three populations. One last issue that we should note is the extent to which our populations are bounded. A population may have complex dynamics, but we may be able to characterize a given population by its upper and lower bounds. In spite of the differences created by the initial conditions, the upper and lower bounds of our chaotic populations were very similar (Fig. 5.14). Note also as \\(r_d\\) increases (Fig. ??) the oscillations increase very systematically. One way to see the deterministic nature of chaos is to trace population size from each time point to the next time point. We put \\(N_t\\) on the \\(x\\)-axis and \\(N_{t+1}\\) on the \\(y\\)-axis, and connect all successive points. N0 &lt;- c(N=2); t &lt;- 0:1000 p &lt;- c(rd = 2.8, alpha = 0.01) out &lt;- ode(N0, t, dlogistic, p, method=&quot;euler&quot;) n &lt;- out[901:1000, 2] ntp1 &lt;- n[-1] nt &lt;- n[-length(n)] qplot(nt, ntp1, geom=c(&quot;point&quot;, &quot;path&quot;) ) + labs(y=&quot;N[t+1]&quot;, x=&quot;N[t]&quot;) Figure 5.15: A chaotic discrete logistic population shows certain highly predictable patterns including population sizes limited to a quadratic form revealed here. In general, we can describe many characteristics of populations, even if we cannot predict exactly what the population size will be five years hence. For instance, we can describe the shape of density dependence (linear, nonlinear), and characteristics of \\(N\\), such as the average, the variance, the periodicity, the upper and lower bounds, and the color (i.e. degree of temporal auto-correlation). Indeed, these characteristics may vary among types of organisms, body sizes, or environments. 5.4.2.1 Ricker and more There are many more models of density dependent growth. Some, like the theta-logistic and the Richards models, are more flexible and have more parameters. Others, like the Gompertz model, are used more widely in other fields, such as cancer research for tumor growth, von Bertalanffy for body size growth, and the Ricker model for fisheries. The Ricker model looks a lot like our friend, exponential growth, but where \\(r\\) is modified by density. Here we see them side by side. \\[\\begin{equation} N_{t+1} = N_t e^{r} \\quad ; \\quad N_{t+1}=N_t e^{r_d \\left(1-N_t/K\\right)} \\end{equation}\\] Like discrete logistic growth, the Ricker model41 will also exhibit chaos at high per capita growth rates (\\(r_d&gt;&gt;1\\)). 5.5 Maximum Sustained Yield The classical model of harvesting fisheries and wildlife populations is based on a particular conceptualization of maximum sustained yield (MSY). Maximum sustained yield is historically defined as the population size where both population growth rate and harvest rate are at a maximum. For the logistic growth model, this is half the carrying capacity. We can solve this by finding the maximum of the production function. To do this we use calculus (differentiation) to find where the slope of the production function equals zero. Starting with the partial derivative with respect to \\(N\\) (eq. (5.3)), we solve for zero. \\[\\begin{align} \\tag{5.11} 0 &amp;= r - 2r\\alpha N\\\\ N &amp;= \\frac{r}{2r\\alpha} = \\frac{K}{2} \\end{align}\\] Similarly, we could determine this peak for the \\(\\theta\\)-logistic model as well. \\[\\begin{align} \\tag{5.12} \\frac{\\partial \\dot{N}}{\\partial N} &amp;=r - \\left(\\theta+1\\right)r\\left(\\alpha N\\right)^\\theta\\\\ 0 &amp;= \\frac{K}{\\left(\\theta+1\\right)^{1/\\theta}} \\end{align}\\] When \\(\\theta=1\\), this reduces to \\(K/2\\), as for the logistic model. As we saw above, \\(\\theta &lt; 1\\) causes this value to be less than \\(K/2\\). Even if we assume the logistic model is appropriate for a given population, harvests in practice seldom reduce populations to \\(K/2\\), because often \\(N\\) and \\(K\\) vary with time and are difficult to estimate. Moreover, economic forces often lead to over-harvesting. More contemporary models of harvesting incorporate these concepts (Roughgarden and Smith 1996) but still may not prevent fisheries collapse driven by social and political pressures. We should note that when more detailed information is available on age- or stage-specific survivorship and reproduction, age- or stage-structured models of harvesting are the preferred method (e.g., Chapter 2). For many populations, such as marine fisheries, however, data are often available only on stock size (\\(N\\)) and total catch (\\(H\\)). In some fisheries models, the total catch is fixed and does not vary with \\(N\\). This leads to highly unstable population dynamics and fortunately is no longer practiced in most fisheries. Usually the total catch \\(H\\) is modeled as a function of \\(N\\). Let us assume that total catch or harvest, \\(H\\), is a simple linear function of \\(N\\); the total harvest rate \\(FN\\) is usually described this way.42 In this case, a maximum sustained yield can be determined from the logistic growth-harvest model. This basic model is then \\[\\begin{align} \\tag{5.13} \\frac{dN}{dt}&amp;=rN(1-\\frac{N}{K})-FN \\end{align}\\] where \\(FN=H\\) harvest rate, and \\(F\\) is the per capita fishing mortality rate. Here we assume a fixed per capita catch mortality \\(F\\) so that total harvest is \\(H=F\\times N\\). Maximum sustained yield should then occur at \\(K/2\\) (Fig. 5.16). Therefore would like to know the value of \\(F\\) for which a new \\(N^* = K/2\\) rather than \\(K\\). We can determine the value of \\(F\\) for which this is true by finding when \\(dN/dt=0\\) and \\(N=K/2\\). \\[\\begin{align} 0 &amp;= r\\frac{K}{2}\\left(1-\\frac{\\frac{K}{2}}{K}\\right)-F\\frac{K}{2}\\\\ F &amp;= \\frac{r}{2} \\tag{5.14} \\end{align}\\] pgrlog &lt;- function(N, r, alpha){ r*N*(1-alpha*N) } r &lt;- 0.5; alpha &lt;- 0.01 myData &lt;- data.frame( N=c(0, 110) ) # ggplot requires a data frame p &lt;- ggplot(data=myData, aes(x=N)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=pgrlog, geom=&quot;line&quot;, n=1001, args=list(r=r, alpha = alpha)) + labs(y=&quot;Population growth rate (dN/dt)&quot;, x=&quot;Population size (N)&quot;) + geom_abline(intercept=0, slope=r/2, lty=2) + ylim(c(-5, 15)) p pgrH &lt;- function(N, r, alpha, f){ r*N*(1-alpha*N) - f*N } f &lt;- r/2 myData2 &lt;- data.frame( N=c(0, 60) ) # ggplot requires a data frame h &lt;- ggplot(data=myData2, aes(x=N)) + # set the basic properties of the plot # in the stat_function, we indicate the parameters in our equation. stat_function(fun=pgrH, geom=&quot;line&quot;, n=1001, args=list(r=r, alpha = alpha, f = f)) + labs(y=&quot;PGR w/ harvesting (dN/dt)&quot;, x=&quot;Population size (N)&quot;) + ylim(c(-5, 15)) h Figure 5.16: To find the predicted population growth rate with harvesting, we start with Logistic growth rate (solid line) and then substract harvest rate (dashed line). If harvesting occurs at a rate of \\(F&lt;r/2\\), the slope of the harvest line is shallower than in Fig. 5.16, and we refer to this as under-harvesting. If the rate is \\(F&gt;r/2\\), then the slope is steeper than in Fig. 5.16, and we refer to this as over-harvesting. Roughgarden and Smith (1996) show that under-harvesting is the most ecologically stable, whereas over-harvesting is frequently thought to be the economically optimal approach if we don’t care about the long-term wellbeing of the fishing industry. Typically the economically optimal approach leads to over-harvesting because the marginal income on a fishery is related to the interest rate on invested income, \\(F= (r + \\rho)/2\\), where \\(\\rho\\) is the interest rate (usually \\(\\rho\\) is set to 0.05). We can substitute this into eq. (5.13) and solve for \\(N\\) (ignoring \\(N=0\\)). \\[\\begin{align*} \\tag{5.15} 0&amp;=rN(1-\\frac{N}{K})-\\frac{r + \\rho}{2}N\\\\ N\\frac{r}{K}&amp;=r -\\frac{r}{2} -\\frac{\\rho}{2}\\\\ N &amp;=\\frac{K}{2}\\left(1-\\frac{\\rho}{r}\\right) \\end{align*}\\] Thus, unless \\(\\rho=0\\), the typical economic optimum \\(N_{e}^*\\) will be smaller than \\(N*=K/2\\). This makes intuitive economic sense if we consider income from invested profits. The margin of error, however, is much smaller, putting the fisheries population, and the investment of fishing fleets and associated econmoies at greater risk. Roughgarden and Smith (1996) showed that ecological stability of a fishery is likely to beget economic and cultural stability. They show that the supposed “economic optimal” harvesting rate was so low that it increased the extinction risk of the harvested population to unacceptably high levels. The collapse of a fishery is, of course, both economically and culturally devastating. References "],
["meta.html", "6 Populations in Space 6.1 Source-sink Dynamics 6.2 Metapopulations 6.3 Hanski’s incidence function", " 6 Populations in Space Figure 6.1: A frequency distribution of the number of plant species (y-axis) that occupy different numbers of grassland remnants (x-axis). Note the U-shaped (bimodal) distribution of the number of sites occupied. Other years were similar (Collins and Glenn 1991). Over relatively large spatial scales, it is not unusual to have some species that seem to occur everywhere, and many species that are found in only one or a few locations. For example, Scott Collins and Susan Glenn (Collins and Glenn 1991) showed that in grasslands, each separated by up to 4\\(\\,\\)km, there were more species occupying only one site (Fig. 6.1, left-most bar) than two or more sites, and also that there are more species occupying all the sites than most intermediate numbers of sites (Fig. 6.1, right-most bar), resulting in a U-shaped frequency distribution. Illke Hanski (Hanski 1982) coined the rare and common species “satellite” and “core” species, respectively, and proposed an explanation. Part of the answer seems to come from the effects of immigration and emigration in a spatial context. In this chapter we explore mathematical representations of individuals and populations in space, and we investigate the consequences for populations and collections of populations. 6.1 Source-sink Dynamics In Chapters 3-5, we considered closed populations. In contrast, one could imagine a population governed by births plus immigration, and deaths plus emigration (a BIDE model). Ron Pulliam (Pulliam 1988) proposed a simple model that includes all four components of BIDE which provides a foundation for thinking about connected subpopulations. We refer to the dynamics of these as source-sink models. Examples include subpopulations of birds inhabit low quality forest patches only because of immigration from high quality forest patches (Robinson et al. 1995), or understory palms that inhabitat distinct microhabitats in which seeds move from high to low quality patches (Berry et al. 2008). Figure 6.2: The simplest source-sink model, where m21 &gt; m12 so that net movement of individuals is from the source to the sink. The concept of source-sink populations begins with the assumption that spatially separated subpopulations occupy distinct patches, which each exhibit their own intrinisic dynamics due to births and deaths (Fig. 6.2). We can characterize each subpopulation with its own population growth rate, \\(\\lambda_i\\). In addition, individuals migrate between patches. Therefore, the number of individuals we observe in a particular patch is due to both internal dynamics of births and deaths, and also migration. Source populations are those with more births than deaths (\\(\\lambda &gt; 1\\)) and with more emigration than immigration. Sink populations are those with fewer births than deaths (\\(\\lambda &lt; 1\\)) and with more immigration than emigration. When we consider causes of variation in \\(\\lambda\\), we often refer to the quality of patches or habitats. High quality patches have are those with high growth rates (\\(\\lambda&gt;1\\)), whereas low quality patches are those with low growth rates (\\(\\lambda &lt; 1\\)). We might also study factors associated with growth rate, such as the frequency of nesting sites, predator densities, or soil fertility, factors which we predict would regulate growth rates. Pulliam envisioned two linked bird populations where we track adult reproduction, adult and juvenile survival, and estimate \\(\\lambda_i\\) separately for each population. The size of the source population, at time \\(t+1\\) is \\(n_{1,t+1}\\) and is the result of survival and fecundity. Adult survival \\(P_A\\) and fecundity results from reproduction, \\(\\beta_1 n_{1,t}\\), times survival of the juveniles \\(P_J\\). The sink population was modeled the same way. \\[\\begin{align} \\tag{6.1} n_{1, t+1} = P_A n_{1,t} + P_J (\\beta_1 n_{1,t}) = \\lambda_1 n_1\\\\ n_{2, t+1} = P_A n_{2,t} + \\beta_2 P_J n_{1,t} = \\lambda_2 n_2 \\end{align}\\] Pulliam then assumed that the two populations vary only in fecundity (\\(\\beta\\)), which created differences in growth rates, such that \\(\\lambda_1 &gt; 1 &gt; \\lambda_2\\). birds in excess of the number of territories in the source population emigrated from the source habitat to the sink habitat, \\(m_{21} = \\lambda_1 - 1\\). These assumptions result in the source population maintaining a constant density, while all the excess fecundity migrates to the sink population. We can use a matrix model to investigate source-sink populations (e.g., Berry et al. 2008). We place each rate in the respective element in a two-stage matrix model. We assume a pre-breeding census, in which we count only adults. The population dynamics would thus be governed by . \\[\\begin{equation} \\tag{6.2} \\mathbf{A} = \\left( \\begin{array}{cccc} P_{A1} + P_{J1}\\beta_1 &amp; M_{12} \\\\ M_{21} &amp; P_{A2} +P_{J2}\\beta_2 \\end{array} \\right) \\end{equation}\\] where the upper left element (row 1, column 1) reflects the within-patch growth characteristics for patch 1. The lower right quadrant (row 2, and column 2) reflects the within-patch growth characteristics of patch 2. Source-sink models assume net migration flows from the source to the sink (\\(M_{21}&gt;M_{12}\\)). We will assume, for simplicity, that migration is exclusively from the source to the sink (\\(M_{21}&gt;0\\), \\(M_{12}=0\\)). We further assume that \\(\\lambda_1 &gt; 1\\) but all excess individuals migrate to patch 2, so \\(M_{21} = \\lambda_1 - 1&gt;0\\). Then simplifies to \\[\\begin{equation} \\tag{6.3} \\mathbf{A} = \\left( \\begin{array}{cccc} 1 &amp; 0 \\\\ \\lambda_1-1 &amp; \\lambda_2 \\\\ \\end{array} \\right) \\end{equation}\\] We first assign \\(\\lambda\\) for the source and sink populations, and create a matrix. lambda1 &lt;- 1.2; lambda2 &lt;- .4 A &lt;- matrix(c(1, 0, lambda1-1, lambda2), nrow=2, byrow=TRUE) A ## [,1] [,2] ## [1,] 1.0 0.0 ## [2,] 0.2 0.4 We can then use eigenanalysis, as we did in Chapter 4 for stage structured populations. The dominant eigenvalue will provide the long term asymptotic total population growth. We can calculate the stable stage distribution, which in this case is the distribution of individuals between the two habitats. eA &lt;- eigen(A) eA$values ## [1] 1.0 0.4 # calculate the stable stage distr. (ssd &lt;- eA$vectors[,1]/sum(eA$vectors[,1]) ) ## [1] 0.75 0.25 From the dominant eigenvalue, we see Pulliam’s working assumption that the total population growth (for the two popuations combined) is \\(\\lambda=1\\). Upon calculating the stable distribution, we also see that the source population contains more individuals than the sink population. Pulliam explored the consequences of these assumptions for the relative abundances in the two populations. He varied \\(\\lambda_1\\) over a range of values and calculated the relative abundance of the source population. We let p1 be the proportion of the total population in the source. # a range of lambdas lambda1 &lt;- seq(1, 3, by=0.01) # proportion of total N in the source habitat p1 &lt;- sapply(lambda1, function(l1) { # replace lambda1 A[2,1] &lt;- l1-1 # extract the dominant eigenvalue dom.ev &lt;- eigen(A)$vectors[,1] # calculate the relative abundance of the first pop. dom.ev[1]/sum(dom.ev) }) # plot the result qplot(x=lambda1, y=p1, geom=&quot;line&quot;, ylab=&quot;Fraction of total population\\n in the source population&quot;, xlab=expression(lambda[1]) ) Figure 6.3: The declining relative abundance in the high quality habitat in a source-sink model. The proportion of the total population (\\(n_1/(n_1+n_2)\\)) in the source population may decline with increasing habitat quality and growth rate. One of his main theoretical findings was that relative abundance and population density can be misleading indicators of habitat quality (Fig. 6.3). If we assume that excess individuals in the source migrate to the sink, then as habitat quality and reproduction increase in the source population, the source population comprises an ever decreasing proportion of the total population! That is, as \\(\\lambda_1\\) gets larger, \\(n_1/(n_1+n_2)\\) gets smaller. Thus, density can be a very misleading predictor of long-term population viability, if the source population is both productive and exhibits a high degree of emigration. 6.1.1 Complications and cases Pseudosinks and ecological traps are special cases with counterintuitive dynamics. Pseudosinks are patches in which immigration is so high that it pushes the subpopulation over its carrying capacity and depresses growth rates (e.g., Breininger and Oddy 2004). In the absence of immigration, population growth rates would sustain the population (\\(\\lambda &gt; 1\\)). Ecological traps are habitats that are preferred by animals, but are actually low quality (\\(\\lambda &lt; 1\\)). These can occur, espcially in the face of human-induced rapid environmental change. In many cases, there is a mismatch between sensory traits of organisms and novel environments (Robertson, Rehage, and Sih 2013). Like a moth to a flame, as it were. Ideal free and despotic are two types of distributions of individuals among patches. For both types, we assume that the quality of unoccupied habitats varies among patches. We also assume that individuals have negative effects on quality, for example, through territory occupation or resource use. This means that current habitat quality depends on the original quality of unoccupied habitat and the also the number of occupants. An ideal free distribution of individuals among patches results when individuals distribute themselves in perfect proportion to habitat quality. The net result is that all current patches have equal quality because high quality patches suffer from proportionally more individuals. In contrast, an ideal despotic distribution arises when individuals always prefer habitat that has higher original quality, until the habitat is full, at which point they use low quality habitat. This is thought to occur where animals are territorial, and prefer the better habitat as long as there is a single territory available. Balanced dispersal arises when migration occurs at similar rates among patches of similar quality (\\(\\lambda \\approx 1\\)) but where patches vary in size and population size. This results in the unexpected obervation that migration for small patches with few individuals into large patches occurs nearly as often as the reverse. This means that per capita emigration rates are higher for small patches than large patches. It is not clear why this occurs, but it could could occur if the higher edge:area ratio of smaller patches boosts migration rate (Hambäack et al. 2007) and the evolution of dispersal characteristics in populations of different sizes (Legrand et al., n.d.; McPeek and Holt 1992). 6.2 Metapopulations The logistic model (Chapter 5) is all well and good, but it has no concept of space built into it. In many, and perhaps most circumstances in ecology, space has the potential to influence the dynamics of populations and ecosystem fluxes (Lehman and Tilman 1997; Leibold et al. 2004; Loreau, Mouquet, and Holt 2003). The logistic equation represents a closed population, with no clear accounting for emigration or immigration. In particular cases, however, consideration of space may be essential. What will we learn if we start considering space, such that sites are open to receive immigrants and lose emigrants? Figure 6.4: Collections of sites, where each site (A-F) may be a spot of ground potentially occupied by a single plant, or it may be an oceanic island potentially occupied by a butterfly population. Sites may also be colonized via both internal and external sources. A metapopulation is a population of populations (Fig. 6.4). Modeling metapopulations emerged from work in pest management when Levins (1969) wanted to represent the dynamics of the proportion of fields infested by a pest. He assumed that a field was either occupied by the pest, or not. In this framework, we keep track of the proportion of all populations that remain occupied. He assumed that the metapopulation is closed, in the sense that all migration occurs there exists a finite number of sites which may exchange migrants. Whether we consider a single spatial population, or single metapopulation, we can envision a collection of sites connected by dispersal. Each site may be a small spot of ground that is occupied by a plant, or it may be an oceanic island that is occupied by a population. All we know about a single site is that it is occupied or unoccupied. If the site is occupied by an individual, we know nothing of how big that individual is; if the site is occupied by a population, we know nothing about how many indiviuals are present. The models we derive below keep track of the proportion of sites that are occupied. These are known loosely as metapopulation models. Although some details can differ, whether we are modeling a collection of spatially discrete individuals in single population or a collection of spatially discrete populations, these two cases share the idea that there are a collection of sites connected by migration, and each is subject to extinction. The most relevant underlying biology concerns colonization and extinction in our collection of sites (Fig. 6.4). In this chapter, we will assume that all sites experience equal rates. In the one model, we assume that the collection of sites receives propagules from the outside, from some external source that is not influenced by the collection of sites (Fig. 6.4). In all cases, we will consider how total rates of colonization, \\(C\\), and extinction, \\(E\\), influence the the rate of change of \\(p\\), the proportion of sites that are occupied, \\[\\frac{dp}{dt}=C-E.\\] We will consider below, in a somewhat orderly fashion, several permutations of how we represent colonization and extinction of sites (Gotelli and Kelley 1993; Gotelli 1991). 6.2.1 The classic Levins model Levins (1969) proposed what has become the classic metapopulation model, \\[\\begin{equation} \\tag{6.4} \\frac{dp}{dt} = c_{i}p\\left(1-p\\right) - ep \\end{equation}\\] This equation describes the dynamics of the proportion, \\(p\\), of a set of fields invaded by a pest. The pest colonizes different fields at a total rate governed by the rate of propagule production, \\(c_i\\), and also on the proportion of patches that contain the pest, \\(p\\). Thus, propagules are being scattered around the landscape at rate \\(c_i p\\). We use the subscript \\(i\\) to remind us that the colonization is coming from within the sites that we are studying (i.e. internal colonization). The rate at which \\(p\\) changes is also related to the proportion of fields that are unoccupied, \\((1-p)\\), and are therefore available to become occupied and increase \\(p\\). The total rate of colonization is \\(c_ip(1-p)\\). The pest has a constant local extinction rate \\(e\\), so the total extinction rate in the landscape is \\(ep\\). The parameters \\(c_i\\) and \\(e\\) are very similar to \\(r\\) of continuous logistic growth, insofar as they are dimensionless instantaneous rates. However, they are sometimes thought of as probabilities. The parameter \\(c_i\\) is approximately the proportion of open sites colonized per unit time. For instance, if we created or found 100 open sites, we could come back in a year and see how many became occupied over that time interval of one year, and that proportion would be a function of \\(c_i\\). The parameter \\(e\\) is often thought of as the probability that a site becomes unoccupied per unit time. If we found 100 occupied sites in one year, we could revisit them a year later and see how many became *un}occupied over that time interval of one year. With internal colonization, we are modeling a closed spatial population of sites, whether “site” refers to an entire field (as above), or a small patch of ground occupied by an individual plant (Tilman et al. 1994). The Levins metapopulation model: An R function for a differential equation requires arguments for time, a vector of the state variables (here we have one state variable, \\(p\\)), and a vector of parameters. levins &lt;- function(t, y, parms) { p &lt;- y[1] with(as.list(parms), { dp &lt;- ci * p * (1-p) - e * p return(list(dp)) }) } By using with, we can specify the parameters by their names, as long as parms includes names. The function levins() returns a list that contains a value for the derivative, evaluated at each time point, for each state variable (here merely \\(dp /dt\\)). We then use levins in the numerical integration function ode in the deSolve package. prms &lt;- c(ci=0.15, e=0.05) Initial.p &lt;- 0.01 out.L &lt;- data.frame(ode(y=Initial.p, times=1:100, func=levins, parms=prms )) We then plot the result (Fig. 6.5). qplot(x=out.L[,1], y=out.L[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 25, .75, label=bquote(over(dp,dt)==cp(1-p)-ep)) Figure 6.5: Levins metapopulation model Can we use this model to predict the eventual equilibrium? Sure — we just set (6.4) to zero and solve for \\(p\\). This model achieves and equilibrium at, \\[\\begin{align*} \\tag{6.5} 0 &amp;=c_{i}p-c_{i}p^2 - ep\\\\ p^* &amp;= \\frac{c_{i}-e}{c_{i}}=1-\\frac{e}{c_{i}}. \\end{align*}\\] When we do this, we see that \\(p^* &gt; 0\\) as long as \\(c_i &gt; e\\) (e.g., Fig. 6.5). When is \\(p^* = 1\\), so that all the sites are filled? In principle, all sites cannot be occupied simultaneously unless \\(e=0\\). 6.2.2 Propagule rain From where else might propagules come? If a site is not closed off from the rest of the world, propagules could come from outside the collection of sites that we are actually monitoring. For now, let us assume that our collection of sites is continually showered by propagules from an external source. If only those propagules are important, then we could represent the dynamics as, \\[\\begin{equation} \\tag{6.6} \\frac{dp}{dt} = c_{e}\\left(1-p\\right) - ep \\end{equation}\\] where \\(c_{e}\\) specifies the rate of colonization coming from the external source. Gotelli (1991) refers to this model as a metapopulation model with propagule rain, or as the island–mainland model. He calls it this because it describes a constant influx of propagules which does not depend on the proportion, \\(p\\), of sites occupied for propagule production. Extinction here is mediated only by the proportion of sites occupied, and has a constant per site rate. The propagule rain metapopulation model: An R function for a differential equation requires arguments for time, a vector of the state variables (here we have one state variable, \\(p\\)), and a vector of parameters. gotelli &lt;- function( t, y, parms) { p &lt;- y[1] with(as.list(parms), { dp &lt;- ce * (1-p) - e * p return(list(dp)) }) } prms &lt;- c(ce=0.15, e=0.05) Initial.p &lt;- 0.01 out.G &lt;- data.frame(ode(y=Initial.p, times=1:100, func=gotelli, parms=prms )) We then plot the result (Fig. 6.6). qplot(x=out.G[,1], y=out.G[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 50, .25, label=bquote(over(dp,dt)==c[e](1-p)-ep)) Figure 6.6: Propagule rain metapopulation model We can solve for this model’s equilibrium by setting eq. equal to zero. \\[\\begin{align*} 0 &amp;= c_{e}-c_{e}p - ep\\\\ p^*&amp;=\\frac{c_{e}}{c_{e}+e}. \\end{align*}\\] Of course, we might also think that both internal and external sources are important, in which case we might want to include both sources in our model, \\[\\begin{align} \\tag{6.7} \\frac{dp}{dt} &amp;= (c_{i}p+c_{e})\\left(1-p\\right) - ep \\end{align}\\] As we have seen before, however, adding more parameters is not something we take lightly. Increasing the number of parameters by 50% could require a lot more effort to estimate. 6.2.3 The rescue effect and the core-satellite model Thus far, we have ignored what happens between census periods. Imagine that we sample site “A” each year on 1 January. It is possible that between 2 January and 31 December the population at site A becomes extinct and then is subsequently recolonized, or “rescued” from extinction. When we sample on 1 January in the next year, we have no way of knowing what has happened in the intervening time period. We would not realize that the population had become extinct and recolonization had occurred. We can, however, model total extinction rate \\(E\\) with this rescue effect, \\[\\begin{equation} \\tag{6.8} E = - ep\\left( 1-p \\right). \\end{equation}\\] Note that as \\(p \\rightarrow 1\\), the total extinction rate approaches zero. Total extinction rate declines because as the proportion of sites occupied increases, it becomes increasingly likely that dispersing propagules will land on all sites. When propagules happen to land on sites that are on the verge of extinction, they can “rescue” that site from extinction. Brown and Kodric-Brown (1977) found that enhanced opportunity for immigration seemed to reduce extinction rates in arthropod communities on thistles. They coined this effect of immigration on extinction as the rescue effect. MacArthur and Wilson (1963) also discussed this idea in the context of island biogeography. We can even vary the strength of this effect by adding yet another parameter \\(q\\), such that the total extinction rate is \\(-ep\\left( 1-qp \\right)\\) (Gotelli and Kelley 1993). Assuming only internal propagule supply and the simple rescue effect results in what is referred to as the the core-satellite model, \\[\\begin{align} \\tag{6.9} \\frac{dp}{dt} &amp;= c_ip\\left(1-p\\right) - ep\\left( 1-p \\right) \\end{align}\\] This model was made famous by Illka Hanski (Hanski 1982). It is referred to as the core-satellite model because Hanski showed that it predicts precisely the pattern we saw in Fig. 6.1 at the beginning of the chapter. The core-satellite metapopulation model: A function for a differential equation requires arguments for time, a vector of the state variables (here we have one state variable, \\(p\\)), and a vector of parameters. hanski &lt;- function( t, y, parms) { p&lt;- y[1] with(as.list(parms), { dp &lt;- ci * p * (1-p) - e * p *(1-p) return(list(dp)) }) } prms &lt;- c(ci=0.15, e=0.05) Initial.p &lt;- 0.01 out.H &lt;- data.frame(ode(y=Initial.p, times=1:100, func=hanski, parms=prms )) We then plot the result (Fig. 6.7). qplot(x=out.H[,1], y=out.H[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 50, .25, label=bquote(over(dp,dt)==c[i]*p(1-p)-ep(1-p))) Figure 6.7: The core-satellite metapopulation model What is the equilibrium for the Hanski mode (eq. (6.9))? We can rearrange this to further simplify solving for \\(p^*\\). \\[\\begin{align} \\tag{6.10} \\frac{dp}{dt} &amp;= \\left(c_i-e \\right) p \\left(1-p\\right) \\end{align}\\] This shows us that for any value of \\(p\\) between zero and one, the sign of the growth rate (positive or negative) is determined by \\(c_i\\) and \\(e\\). If \\(c_i&gt;e\\), the rate of increase will always be positive, and because occupancy cannot exceed 1.0, the metapopulation will go to full occupancy (\\(p^*=1\\)), and stay there. This equilibrium will be a stable attractor or stable equilibrium. What happens if for some reason the metapopulation becomes globally extinct, such that \\(p=0\\), even though \\(c_i&gt;e\\)? If \\(p=0\\), then like logistic growth, the metapopulation stops changing and cannot increase. However, the slightest perturbation away from \\(p=0\\) will lead to a positive growth rate, and increase toward the stable attractor, \\(p^*=1\\). In this case, we refer to \\(p^*=0\\) as an unstable equilibrium and a repellor. Let’s explore the stability of these equilibria by plotting the metapopulation growth rate as a function of \\(p\\) (Fig. 6.8). When we set \\(c_i&gt;e\\), and examine the slope of that line at \\(p^*=1\\), we see the slope is negative, indicating a stable equilibrium. At \\(p^*=0\\) the slope is positive, indicating an unstable equilibrium. dpdtCS &lt;- expression((ci-e)*p*(1-p)) ci &lt;- 0.15; e &lt;- 0.05 p &lt;- seq(0,1, length=50) dp.dt &lt;- eval(dpdtCS) qplot(p, dp.dt, geom=&quot;line&quot;, ylab=&quot;dp/dt&quot;) Figure 6.8: Metapopulation growth rate as a function of \\(p\\), in the core-satellite model when \\(c_i &gt; e\\). We see that growth rate falls to zero at full occupancy (i.e., at \\(p^*=1\\)). At that point, the slope is negative, indicating that this equilibrium is stable. If \\(c_i&lt;e\\), the rate of increase will always be negative, and because occupancy cannot be less than 0, the metapopulation will become extinct (\\(p^*=0\\)), and stay there. Thus \\(p^*=0\\) would be a stable equilibrium or attractor. What is predicted to happen if, for some odd reason this population achieved full occupancy, \\(p=1\\), even though \\(c_i&lt;e\\)? In that case, \\((1-p)=0\\), and the rate of change goes to zero, and the population is predicted to stay there, even though extinction is greater than colonization. How weird is that? Is this fatal flaw in the model, or an interesting prediction resulting from a thorough examination of the model? How relevant is it? How could we evaluate how relevant it is? We will discuss this a little more below, when we discuss the effects of habitat destruction. What happens when \\(c_i=e\\)? In that case, \\(c_i - e = 0\\), and the population stops changing. What is the value of \\(p\\) when it stops changing? It seems as though it could be any value of \\(p\\), because if \\(c_i-e=0\\), the rate change goes to zero. What will happen if the population gets perturbed — will it return to its previous value? Let’s return to question in a bit. To analyze stability in logistic growth, we examined the slope of the partial derivative at the equilibrium, and we can do that here. We find that the partial derivative of (6.9) with respect to \\(p\\) is \\[\\begin{equation} \\tag{6.11} \\frac{\\partial \\dot{p}}{\\partial p} = c - 2cp - e + 2ep \\end{equation}\\] where \\(\\dot{p}\\) is the time derivative (6.9). A little puzzling and rearranging will make things a little simpler. \\[\\begin{equation} \\tag{6.12} \\frac{\\partial \\dot{p}}{\\partial p} = \\left(c_i - e\\right)\\left(1-2p\\right) \\end{equation}\\] Recall our rules with regard to stability (Chapter 5). If the partial derivative (the slope of the time derivative) is negative at an equilibrium, it means the the growth rate approaches zero following a perturbation, meaning that it is stable. If the partial derivative is positive, it means that the change accelerates away from zero following the perturbation, meaning that the equilibrium is unstable. So, we find the following guidelines: \\(c_i&gt;e\\) \\(p=1\\), \\(\\partial \\dot{p}/ \\partial p &lt; 0\\), stable equilibrium. \\(p=0\\), \\(\\partial \\dot{p}/ \\partial p&gt;0\\), unstable equilibrium. \\(c_i &lt; e\\) \\(p=1\\), \\(\\partial \\dot{p}/ \\partial p &gt; 0\\), unstable equilibrium. \\(p=0\\), \\(\\partial \\dot{p}/ \\partial p &lt; 0\\), stable equilibrium. What if \\(c_i=e\\)? In that case, both the time derivative (\\(d p / dt\\)) and the partial derivative (\\(\\partial \\dot{p}/ \\partial p\\)) are zero for all values of p. Therefore, if the population gets displaced from any arbitrary point, it will remain unchanged, not recover, and will stay displaced. We call this odd state of affairs a neutral equilibrium. We revisit neutral equilibrium when we discuss interspecific competition and predation. 6.2.4 Parallels with Logistic Growth It may have already occurred to you that the closed spatial population described here sounds a lot like simple logistic growth. A closed population, spatial or not, reproduces in proportion to its density, and is limited by its own density. Here we will make the connection a little more clear. It turns out that a simple rearrangement of (6.4) will provide the explicit connection between logistic growth and the spatial population model with internal colonization (Roughgarden 1998). Imagine for a moment that you are an avid birder following a population of Song Sparrows in Darrtown, OH, USA (Ch. 5). If Song Sparrows are limited by the number of territories, and males are competing for territories, then you could think about male Song Sparrows as “filling up” some proportion, \\(p\\), of the available habitat. Each territory is thus like a local population, but where a pair of sparrows either occupies a site, or not, and the proportion of all territories that are occupied is \\(p\\). You therefore decide that you would like to use Levins’ spatially-implicit metapopulation model instead (6.4). How will you do it? You do it by rescaling logistic growth, \\(dN/dt = rN(1-\\alpha N)\\). Let us start by defining our logistic model variables in other terms. First we define \\(N\\) as \\[\\begin{equation*} N=Hp \\end{equation*}\\] where \\(N\\) is the number of males defending territories, \\(H\\) is the total number of possible territories, and \\(p\\) is the proportion of possible territories occupied at any one time. At equilibrium, \\(N^*=K=Hp^*\\), and \\(\\alpha=1/(Hp^*)\\). Recall that for the Levins model, \\(p^*=(c_i-e)/c_i\\), so therefore, \\[\\alpha = \\frac{c_i}{H\\left(c_i - e\\right)}\\] We now have \\(N\\), \\(\\alpha\\), and \\(K\\) in terms of \\(p\\), \\(H\\), \\(c_i\\) and \\(e\\), so what about \\(r\\)? Recall that for logistic growth, the per capita growth rate goes to \\(r\\) as \\(N \\to 0\\) (Chapter 3). For the Levins metapopulation model, the per patch growth rate is \\[\\begin{align} \\frac{1}{p}\\frac{dp}{dt}&amp;=c_{i}\\left(1-p\\right) - e. \\end{align}\\] As \\(p \\to 0\\) this expression simplifies to \\(c_i-e\\), which is equivalent to \\(r\\). Summarizing, then, we have, \\[\\begin{gather} \\tag{6.13} r=c_i-e\\\\ N=Hp\\\\ \\alpha = \\frac{1}{K} = \\frac{1}{Hp^*} = \\frac{c_i}{H\\left(c_i-e\\right)} \\end{gather}\\] Substituting into logistic growth (\\(\\dot{N} = rN(1-\\alpha N)\\)), we now have \\[\\begin{align} \\tag{6.14} \\frac{d(pH)}{dt} &amp;= \\left(c_i-e\\right)pH\\left(1-\\frac{c_i}{H\\left(c_i-e\\right)}Hp\\right)\\\\ &amp;= \\left(c_i-e\\right)pH - \\frac{ c_i-e }{c_i-e}c_ip^2H\\\\ &amp;= H\\left(c_ip\\left(1-p\\right) - ep \\right) \\end{align}\\] which is almost the Levins model. If we note that \\(H\\) is a constant, we realize that we can divide both sides by \\(H\\), ending up with the Levins model (6.4). 6.2.5 Levins \\(vs\\). Hanski Why would we use Levins’ model instead of Hanski’s core-satellite model? To explore this possibility, let’s see how the Hanski model might change gradually into the Levins model. First we define the Hanski model with an extra parameter, \\(a\\), \\[\\begin{equation} \\tag{6.15} \\frac{dp}{dt} = c_ip\\left(1-p\\right) - ep\\left(1-ap\\right). \\end{equation}\\] Under Hanski’s model, \\(a=1\\) and under Levins’ model \\(a=0\\). If we solve for the equilibrium, we see that \\[\\begin{equation} \\tag{6.16} p^*=\\frac{c-e}{c-ae} \\end{equation}\\] so that we can derive either result for the two models. In the context of logistic growth, where \\(K=Hp^*\\), this result (6.16) implies that for the Hanski model, \\(K\\) fills all available habitat, whereas the Levins model implies that \\(K\\) fills only a fraction of the total available habitat. That fraction results from the dynamic balance between \\(c_i\\) and \\(e\\). 6.2.6 Habitat Destruction Other researchers have investigated effects of habitat loss on metapopulation dynamics (Kareiva and Wennergren 1995; Nee and May 1992; Tilman et al. 1994). Taking inspiration from the work of Lande (Lande 1987, 1988), Kareiva and Wennergren (1995) modeled the effect of habitat destruction, \\(D\\), on overall immigration probability. They incorporated this into Levins’ model as \\[\\begin{equation} \\tag{6.17} \\frac{dp}{dt}=c_ip(1-D-p) - ep \\end{equation}\\] where \\(D\\) is the amount of habitat destroyed, expressed as a fraction of the original total available habitat. To turn eq. (6.17) into a function we can use with ode, we have, lande &lt;- function(t, y, parms) { with(as.list(c(y,parms)), { dp &lt;- ci * p * (1-D-p) - e * p return(list(dp)) }) } prmsD &lt;- c(ci=0.15, e=0.05, D=.2) Initial.p &lt;- c(p=0.1) out.D &lt;- data.frame(ode(y=Initial.p, times=1:100, func=lande, parms=prmsD )) qplot(x=out.D[,1], y=out.D[,2], geom=&quot;line&quot;, ylim=c(0,1), ylab=&quot;p&quot;, xlab=&quot;time&quot;) + annotate(&quot;text&quot;, 25, .75, label=bquote( over(dp,dt)==c[i]*p(1-D-p)-ep) ) Figure 6.9: Habitat destruction metapopulation model Habitat destruction, \\(D\\), may vary between 0 (\\(=\\) Levins model) to complete habitat loss 1.0; obviously the most interesting results will come for intermediate values of \\(D\\), which we illustrate next. 6.2.7 Illustrating the effects of habitat destruction We can plot the dynamics for three levels of destruction, starting with none (\\(D=0\\)). We first set all the parameters, and time. t &lt;- 1:200 prmsD &lt;- c(ci=0.15, e=0.05, D=0) Initial.p &lt;- c(p=0.01) t &lt;- 1:200 D0 &lt;- ode(y=Initial.p, times=t, func=lande, parms=prmsD ) prmsD[&quot;D&quot;] &lt;- 0.2 D.2 &lt;- ode(y=Initial.p, times=t, func=lande, parms=prmsD ) prmsD[&quot;D&quot;] &lt;- 0.5 D.5 &lt;- ode(y=Initial.p, times=t, func=lande, parms=prmsD ) ps &lt;- rbind.data.frame(D0, D.2, D.5) ps$D &lt;- as.character( rep(c(0, .2, .5), each=length(t)) ) Last, we plot it and add some useful labels. ggplot(ps, aes(time, p, linetype=D)) + geom_line() Figure 6.10: Three different levels of habitat destruction What is the equilibrium under this model? Setting eq. to zero, we can then solve for \\(p\\). \\[\\begin{gather} \\tag{6.18} 0=c_i-c_iD-c_ip - e\\\\ p^* = \\frac{c_i-c_iD - e}{c_i} = 1 - \\frac{e}{c_i} - D \\end{gather}\\] Thus we see that habitat destruction has a simple direct effect on the metapopulation. 6.2.8 Different assumptions lead to different predictions about rates of extinction Let us return now to the case in the core-satellite model where \\(c_i &lt; e\\) and \\(p=1\\). Recall that in this case, \\(p=1\\) is an unstable equilibrium (\\(p=0\\) is the stable equilibrium for \\(c_i&lt;e\\)). Imagine that at one time, a metapopulation is regulated by the mechanisms in the core-satellite model, including the rescue effect, and \\(c_i&gt;e\\). We therefore pretend that, the metapopulation occupies virtually every habitable site (let \\(p=0.999\\)). Now imagine that the environment changes, causing \\(c_i&lt;e\\). Perhaps climate change enhances extinction rates. All of a sudden, our metapopulation is poised near an unstable equilibrium, with \\[p=0.999\\quad ; \\quad c_i &lt; e\\]. What will happen and how might it differ with and without the assumption of the rescue effect? When \\(c_i &gt; e\\), we see that \\(p^*=1\\) is the stable attractor (Fig. 6.11). If extinction rates rise so that \\(c_i &lt; e\\), we see the inevitable march toward extinction predicted by the core-satellite model (Fig. 6.11). The decline starts slowly and remains slow, until it begins to gradually accelerate. Do all metapopulation models make the same predictions? If we try this experiment with the Levins model, we see something very different. The Levins model predicts very rapid decline once \\(c_i &lt; e\\). Both models predict extinction, but the rescue effect delays the appearance of that extinction. It appears that the rescue effect (which is the difference between the two models) may act a bit like the ``extinction debt’’ (Tilman et al. 1994) wherein deterministic extinction of a dominant species in a multi-species community is merely delayed, but not postponed indefinitely. Perhaps populations influenced by the rescue effect might be prone to unexpected collapse, if the only stable equilibria are 1 and 0. Thus simple theory can provide interesting insight, resulting in very different predictions for superficially similar processes. Here we show the unexpected collapse of core populations, starting at or near equilbrium. The first two use the Hanski model, while the third uses Levins. The second and third use \\(c_i &lt; e\\). C1 &lt;- ode(y=c(p=0.999), times=t, func=hanski, parms=c(ci=0.2, e=0.01)) C2 &lt;- ode(y=c(p=0.999), times=t, func=hanski, parms=c(ci=0.2, e=0.25)) L2 &lt;- ode(y=c(p=0.999), times=t, func=levins, parms=c(ci=0.2, e=0.25)) coll &lt;- rbind.data.frame(C1, C2, L2) coll$model &lt;- factor(rep(c(&quot;c&gt;e&quot;, &quot;c&lt;e&quot;, &quot;c&lt;e (Levins)&quot;), each=nrow(L2)), levels=c(&quot;c&gt;e&quot;, &quot;c&lt;e&quot;, &quot;c&lt;e (Levins)&quot;)) ggplot(coll, aes(time, p, linetype=model)) + geom_line() Figure 6.11: Metapopulation dynamics, starting from near equilibrium for \\(c_i=0.20\\) and \\(e=0.01\\). If the environment changes, causing extinction rate to increase until it is greater than colonization rate, we may observe greatly delayed, but inevitable, extinction (e.g., \\(c_i=0.20, e=0.25\\)) 6.3 Hanski’s incidence function The above models of metapopulation dynamics provide an outline for understanding metapopulation dynamics. However, they do not necessarily provide a direct means to interrogate data or use data illuminate our understanding. One of the main reasons for this is that they do not address two important ecological realities: that patches will be differ in area and thus differ in population sizes, and that they are different distances from each other. MacArthur and Wilson (1963) argued persuasively that extinction risk should be related to area, and that distance from a source should influence the probability of colonization. IIkka Hanski (1994) provided an approach using incidence functions, which predict the probability of occurrence. They allow us to incorporate area and distance in our model, and uses easily acquired patch occupancy data (presence/absence data) to evaluate metapopulation characteristics. The incidence of occupancy is determined by colonization and extinction probabilities. We will assume that if a patch \\(i\\) is empty in year \\(t\\), it will be recolonized in year \\(t+1\\) with a probability \\(C_i\\). This also means it will remain empty with probability of \\(1-C_i\\). If a patch \\(j\\) is occupied in year \\(t\\), it will become extinct in year \\(t+1\\) with probability \\(E_i\\). This also means that it will persist with probability \\(1-E_i\\). The two states for one patch are illustrated with the code and figure below. Each column of the matrix is the probabilities for one state. Te first column comprises the probabilities of remaining empty or changing from empty to occupied. The second column comprises the probabilities that an occupied patch becomes empty or remains occupied. C &lt;- .3; E &lt;- .5 M &lt;- matrix(c(1-C, E, C, 1-E), ncol=2, byrow=TRUE) colnames(M) &lt;- rownames(M) &lt;- c(&quot;empty&quot;, &quot;occupied&quot;) M ## empty occupied ## empty 0.7 0.5 ## occupied 0.3 0.5 { plotmat(M, pos=2) #requires the diagram package title(&quot;The two states of one patch&quot;) } The probability, \\(J_i\\), that a patch is occupied at any given time is, \\[J_i = \\frac{C_i}{C_i + E_i}.\\] We can show this by calculating the stable distribution of these states using eigenanalysis in the way we did for demographic matrices. # J (J &lt;- C/(C+E)) ## [1] 0.375 # The stationary distributions for the two states, empty and occupied eM &lt;- eigen(M) eM$vectors[,1]/sum(eM$vectors[,1]) ## [1] 0.625 0.375 We see that \\(J_i\\) is the stable state for being colonized. Extinction probability, \\(E\\), is determined by patch area \\(A_i\\) in our simple model. This is because we will assume that all patches have a similar quality and so support equal densities (individuals per unit area). Larger areas have more individuals and thus have lower risk of extinction. IIkka Hanski (1994) described this mathematically as \\[\\begin{align*} E_i = \\frac{e}{A_i^x} \\quad &amp;\\mathrm{if} A_i &gt; e^{1/x}\\\\ E_i = 1 \\quad &amp;\\mathrm{if} A_i \\le e^{1/x} \\end{align*}\\] where \\(e\\) and \\(x\\) are constants letting \\(E_i\\) vary for different systems. Parameter \\(x\\) controls the effect of area, where larger values \\(x&gt;1\\) mean that large patches have very low extinction risk. Smaller values of \\(x\\) (\\(x&lt;1\\)) mean that patches have to become exceedingly larger to appreciably reduce extinction risk. The parameter \\(e\\) is the area-independent measure of extinction risk, and so is related to intrinsic population dynamics and environmental stochasticity. We can illustrate extinction probability with toy code. # Extinction probability E.p &lt;- function(A, e=0.01, X=1.009){ Ei &lt;- ifelse(A &gt; e^(1/X), e/(A^X), 1) Ei } curve(E.p(x), 0, 0.2, ylim=c(0,1)) Figure 6.12: Extinction probabliity for a butterfly population (silver spotted skipper, Hanski 1994). ## The ggplot way # myData &lt;- data.frame( A=c(0, .2) ) # ggplot requires a data frame # ggplot(data=myData, aes(x=A)) + # set the basic properties of the plot # # in the stat_function, we indicate the parameters in our equation. # stat_function(fun=E.p, geom=&quot;line&quot;, # args=list(e = 0.01, X = 1.009)) Note that \\(A_0 = e^{1/x}\\) is the critical patch size where a population is not expected to persist a year. Colonization probability, \\(C_i\\), is more complicated. It is a function of the number of arriving migrants, which are themselves a function of distances from other patches and the area (and thus population sizes) of those patches. It is \\[C_i = \\frac{1}{1+\\left(\\frac{y^\\prime}{S_i}\\right)^2}\\] where \\(y^\\prime\\) is colonizing ability of the species, and \\(S_i\\) can be thought of as a measure of isolation of patch \\(i\\) from the rest of the patches. Formally, this is \\[S_i = \\sum_{j=1}^n\\left(p_j \\mathrm{exp}(-\\alpha d_{ij}) A_j\\right)\\] where there are a total \\(n\\) other patches \\(j\\) that are habitats, \\(p_j\\) is an indicator of whether a patch is currently occupied (0,1), \\(d_{ij}\\) is the distance from patch \\(j\\) to patch \\(i\\), \\(\\alpha\\) is the effect of distance, and \\(A_j\\) is the area of patch \\(j\\) and thus an index of population size. We can illustrate extinction probability with toy code. # Colonization probability from one patch to another, as a function of distance C.p &lt;- function(d, yprime, alpha, area){ Sij &lt;- exp(-alpha*d ) * area Ci &lt;- 1/(1 + (yprime/Sij)^2 ) Ci } # parameters yprime &lt;- 2.663; ha &lt;- 0.94; alpha &lt;- 2 km &lt;- seq(0, 1.5, by=0.01) C &lt;- sapply(km, function(d) {C.p(d=d, yprime=yprime, alpha=alpha, area=ha)}) qplot(km, C, geom=&quot;line&quot;) Figure 6.13: Colonization probabliity for a butterfly population (silver spotted skipper, Hanski 1994). There are additional details about the colonization function that I have buried, but the interested reader could consult sources of these ideas (I. Hanski 1994; IIkka Hanski 1994). Combining \\(C_i\\) and \\(E_i\\), we can define the incidence function, \\[J_i = \\frac{1}{1+ \\left(1+\\left[\\frac{y^\\prime}{S_i}\\right]^2\\right)\\frac{e}{A_i^x}}.\\] To use this model, we need the following data for each patch areas, \\(A_i\\), of each patch, locations of each patch, from which to calculate the distances between each pair of patches \\(i,j\\), presence or absence of the species in each patch, the distance parameter \\(\\alpha\\). From the distances, \\(\\alpha\\), and presence/absences, we calculate \\(S_i\\) for each patch. There are a couple of ways to estimate \\(\\alpha\\) but perhaps the best way is to do this using mark-recapture methods, but we will not explain those here. Other parameters, \\(e,\\,x,\\,y^\\prime\\), are estimated using nonlinear regression methods; we use these below. References "],
["competition.html", "7 Competition 7.1 Lotka-Volterra Interspecific Competition 7.2 Equilbria 7.3 Dynamics at the Equilibria 7.4 Return Time and the Effect of \\(r\\) 7.5 Indirect competition for resources 7.6 Summary", " 7 Competition Different species frequently compete for limiting resources, and as a result have negative impacts on each other. For example, change in species composition during secondary succession (Fig. 7.1) appears mediated by, among other things, a species’ ability to intercept light, grow, and cast shade over other species. This chapter addresses very simple ways to represent such interactions between species. Unless I specify otherwise, “competition” in this chapter will refer to competition between species, or interspecific competition. Figure 7.1: Changes in abundances of six species of asters during early secondary succession. This turnover of perennial weeds appears mediated by competition for light, among other factors (data from the long-term Buell-Small Succession study [http://www.ecostudies.org/bss/]). In this chapter we introduce direct and indirect interspecific competition (Fig. 7.2). Direct competition is an interaction in which individuals experience a direct negative effect of another individual through aggressive interaction via contact or signaling. Indirect competition are negative interactions mediated by another factor, such as a limiting resource. When grass species compete for nitrate and ammonium, it is the shortage of those nutrients that causes the negative effects, and that shortage results from their consumption by competing species. Figure 7.2: We can model competition as direct negative effects, or as indirect interactions mediated through a resource. We start with modeling direct interactions using the Lotka-Volterra framework. We then move on to indirect interactions using a consumer-resource model. 7.1 Lotka-Volterra Interspecific Competition Our models of density-dependent growth were built upon the assumption that individuals within a single population had negative effects on each other, which we refered to as intraspecific competition. Here we assume that individuals of different species also have negative effects on each other. The classic model of competitive interactions is the continuous Lotka-Volterra model of interspecific competition (Kingsland 1985). We build directly on the logistic growth model by adding an additional term for negative density dependence, this time, with the competing species. Now we have to label our populations and all of our parameters using subscripts. These subscripts identify the species to which the parameter relates. For instance, \\(r_1\\) is the intrinsic rate of increase for species 1, and \\(\\alpha_{12}\\) is the per capita effect of species 2 on 1. \\[\\begin{align} \\frac{d N_1}{d t}&amp;=r_1N_1\\left(1-\\alpha_{11}N_1-\\alpha_{12}N_2\\right)\\tag{7.1}\\\\ \\frac{d N_2}{d t}&amp;=r_2N_2\\left(1-\\alpha_{21}N_1-\\alpha_{22}N_2\\right) \\tag{7.2} \\end{align}\\] You will notice in (7.1) that the denisty-dependence term includes the total effect of species 1 on itself (\\(\\alpha_{11}\\)) and the total effect of species 2 and species 1 (\\(\\alpha_{12}\\)) (Table 7.1). It is useful to understand where these subscripts come from. Why are they read from right to left — why not left to right? As we saw in our models of structured population growth, it comes from the underlying linear algebra used to work with all these equations. We define all of the \\(\\alpha\\)’s together as a matrix, \\[\\begin{equation} \\tag{7.3} \\mathbf{\\alpha} = \\begin{pmatrix} \\alpha_{11} &amp; \\alpha_{12} \\\\ \\alpha_{21} &amp; \\alpha_{22} \\end{pmatrix} = \\begin{pmatrix} 0.010 &amp; 0.005\\\\ 0.008 &amp; 0.010 \\end{pmatrix} \\end{equation}\\] The subscripts on the \\(\\alpha\\)s represent the row and column of the coefficient; \\(\\alpha_{12}\\) is in the first row, second column. This merely reflects how mathematicians describe matrix elements and dimensions — row \\(\\times\\) column. When we use matrix multiplication, \\(\\alpha_{12}\\) becomes the effect of species 2 (column) on species 1 (row). In this case, \\(\\alpha_{11}=\\alpha_{22}=0.01\\), \\(\\alpha_{21}=0.008\\), and \\(\\alpha_{12}=0.005\\). Thus, both species have greater effects on themselves than on each other. Remember, the larger the \\(\\alpha\\), the larger the effect. Table 7.1: Parameters of the continuous 2 species Lotka-Volterra competition model. The rest of the chapter explains the meaning and motivation. Parameter Description \\(r_i\\) Instantaneous rate of increase; intrinsic rate of growth; individuals produced per individual per unit time. \\(\\alpha_{ii}\\) Intraspecific density dependence; intraspecific competition coefficient; the negative effect of an individual of species \\(i\\) on its own growth rate. \\(\\alpha_{ij}\\) Interspecific density dependence; interspecific competition coefficient; the effect of interspecific competition; the negative effect that an individual of species \\(j\\) has on the growth rate of species \\(i\\). \\(K_i\\) \\(1/\\alpha_{ii}\\); carrying capacity of species \\(i\\); the population size obtainable by species \\(i\\) in the absence of species \\(j\\). \\(\\alpha^\\prime_{ij}\\) \\(\\alpha_{ij}/\\alpha_{ii}\\); the relative importance of interspecific competition. \\(\\beta_{ij}\\) \\(\\alpha_{ij}/\\alpha_{jj}\\); the invasion criterion for species \\(i\\); the relative importance of interspecific competition; the importance of the effect of species \\(j\\) on species \\(i\\) relative to the effect of species \\(j\\) on itself. These equations are also commonly represented using carrying capacity, \\(K_i\\), to summarize intraspecific effects on abundance, and coefficients to modify the intraspecific effects quantified with \\(K_i=1/\\alpha_{ii}\\). This representation looks like \\[\\begin{align} \\frac{d N_1}{d t}&amp;=r_1N_1\\left(\\frac{K_1-N_1-\\alpha&#39;_{12}N_2}{K_1}\\right) \\tag{7.4}\\\\ \\frac{d N_2}{d t}&amp;=r_2N_2\\left(\\frac{K_2-N_2-\\alpha&#39;_{21}N_1}{K_2}\\right). \\tag{7.5} \\end{align}\\] In this version, \\(K_1=1/\\alpha_{11}\\), and note that \\(\\alpha&#39;_{12}\\) differs from \\(\\alpha_{12}\\). The \\(\\alpha&#39;_{12}\\) in eq. (7.4) merely modifies the effect of \\(1/K_1\\). It turns out the \\(\\alpha&#39;_{1,2}\\) is equal to the ratio of the interspecific and intraspecific per capita effects, or \\[\\begin{align} \\alpha_{12}&amp;=\\frac{\\alpha&#39;_{12}}{K_1}\\notag\\\\ \\alpha&#39;_{12}&amp;=\\frac{\\alpha_{12}}{\\alpha_{11}}. \\end{align}\\] Another useful measure of the relative importance of interspecific competition is \\(\\beta_{ij}=\\alpha_{ij}/\\alpha_{jj}\\) (see Invasion criteria, below). 7.2 Equilbria In this section, we describe how we find equilibria in a simple multispecies model, by solving the growth equations for zero, much the way we did in Chapters 3 and 4. We begin with isoclines, and move on to boundary and internal equilibria and invasion criteria. 7.2.1 Isoclines An isocline is, in general, a line connecting points on a graph or map that have equal value. For instance, a topographic map has elevation isoclines, connecting points of equal elevation. Here, our isoclines will connect points in state space at which the growth rate for species \\(i\\) equals zero — every point on that line will represent \\(\\dot{N}_i=0\\). We call these zero net growth isoclines (ZNGI), sometimes called “zingees” by people who prefer an economy of words. A zero net growth isocline is the set of all points for which the growth of a population is zero, when the population size of a competing species is held constant. A two-species equilibrium is a point at which the growth rates of both populations are zero. We saw previously that the carrying capacity of a single species logistic population is an equilibrium. With two species, it gets a tad trickier. We find the isocline of a species by setting its growth rate equal to zero and solving the equation for that species in terms of the other species. As an example, find the zero net growth isocline for \\(N_2\\). We find below that there is a straight line that describes all points for which \\(d N_2/dt=0\\), if \\(N_1\\) were held constant. We start by setting (7.2) to zero, and solving for \\(N_2\\). \\[\\begin{align*} \\frac{d N_2}{d t}&amp;=r_2N_2\\left(1-\\alpha_{21}N_1-\\alpha_{22}N_2\\right) \\\\ 0 &amp;=r_2N_2\\left(1-\\alpha_{21}N_1-\\alpha_{22}N_2\\right)\\\\ 0 &amp;= 1-\\alpha_{21}N_1-\\alpha_{22}N_2\\\\ N_2 &amp;=\\frac{1}{\\alpha_{22}} - \\frac{\\alpha_{21}}{\\alpha_{22}}N_1 .\\tag{7.6} \\end{align*}\\] Recall that the formula for a straight line is \\(y=mx + b\\) where \\(m\\) is the slope and \\(b\\) is the intercept on the \\(y\\) axis. We can see that the expression for \\(N_2\\) in (7.6) is a straight line, where \\(y=N_2\\), \\(m= \\alpha_{21}/\\alpha_{22}\\), and \\(b=1/\\alpha_{22}\\) (Fig. 7.3). When \\(N_1\\) is zero, \\(N_2=1/\\alpha_{22}\\). This is precisely what we saw in Chapter 3 (logistic growth), that a single species logistic population has an equilibrium at its carrying capacity, \\(K=1/\\alpha\\). The isocline (Fig. 7.3) shows that as the competitor’s population size, \\(N_1\\), becomes larger, \\(N_2\\) declines by \\(\\alpha_{21}/\\alpha_{22}\\) for each additional individual of the competing species 1, until finally \\(N_2=0\\) when \\(N_1=1/\\alpha_{21}\\). Graphing an isocline isn’t too hard, so let’s graph something similar to Fig. 7.3. First, we define a new matrix of competition coefficients, where \\(\\alpha_{11}=\\alpha_{22} &gt; \\alpha_{12}=\\alpha_{21}\\). a &lt;- matrix(c( 0.01, 0.005, 0.005, 0.01), ncol=2, byrow=TRUE) We create an expression to plot the \\(N_2\\) isocline, as a function of possible values of \\(N_1\\). N2iso &lt;- expression(1/a[2,2] - (a[2,1]/a[2,2])*N1) We then specify \\(N_1\\), and then evaluate and plot \\(N_2\\). We add arrows to remind us of what happens if \\(N_2\\) is above or below the value on the isocline. N1 &lt;- 0:200 plot(N1, eval(N2iso), type=&#39;l&#39;, ylim=c(0, 200), xlim=c(0, 200), ylab=expression(&quot;N&quot;[2])) arrows(x0=90, y0=150, x1=90, y1=80, length=0.1) arrows(x0=75, y0=0, x1=75, y1=50, length=0.1) The isocline for \\(N_2\\) (Fig. 7.3) is the line at which \\(d N_2/d t =0\\) for a fixed value of \\(N_1\\). Just as in the single species logistic growth model, if \\(N_2\\) exceeds its equilibrium, it declines, and if \\(N_2\\) is less than its equilibrium, it grows. The isocline (Fig. 7.3 is the set of balance points between positive and negative growth. This is reflected in the arrows in Fig. 7.3 — if the \\(N_2\\) is ever above this isocline, it declines and if it is ever below this isocline, it rises. This isocline shows that whether \\(N_2\\) increases or decreases depends on \\(N_1\\). Figure 7.3: Phase plane plots of each of the two competing species, with Lotka-Volterra zero growth isoclines. Arrows indicate population trajectories. Recall \\(K = 1/alpha\\). By analogy, the isocline for species 1 turns out to be \\[\\begin{align} N_1 &amp;=\\frac{1}{\\alpha_{11}} - \\frac{\\alpha_{12}}{\\alpha_{11}}N_2. \\tag{7.7} \\end{align}\\] Note that these isoclines are merely equations for straight lines, and it is easy to do nonsensical things, such as specify coefficients that result in negative population sizes. Therefore, let us proceed with some thoughtfulness and care. 7.2.2 Finding equilibria By themselves, the isoclines tell us that if species 2 becomes extinct (\\(N_2=0\\)), then species 1 reaches its carrying capacity (\\(N_1=1/\\alpha_{11}\\)) (Fig. 7.3). Similarly, if \\(N_1=0\\), then \\(N_2=1/\\alpha_{22}\\). These are important equilibria, because they verify the internal consistency of our logical, and they provide end-points on our isoclines. If the species coexist (\\(N_1,\\,N_2 &gt;0\\)) it means that they must share one or more points on their isoclines — such an equilibrium is the point where the lines cross. We find these equilibria by solving the isoclines simultaneously. A simple way to do this is to substitute the right hand side of the \\(N_2\\) isocline (7.6) in for \\(N_2\\) in the \\(N_1\\) isocline (7.7). That is, we substitute an isocline of one species in for that species’ abundance in another species’ isocline. Combining eqs. (7.6) and (7.7), we get \\[\\begin{align} N_1 &amp;=\\frac{1}{\\alpha_{11}} - \\frac{\\alpha_{12}}{\\alpha_{11}}\\left(\\frac{1}{\\alpha_{22}} - \\frac{\\alpha_{21}}{\\alpha_{22}}N_1 \\right)\\notag\\\\ N_1 &amp;=\\frac{1}{\\alpha_{11}} - \\frac{\\alpha_{12}}{\\alpha_{11}\\alpha_{22}}+ \\frac{\\alpha_{12}\\alpha_{21}}{\\alpha_{11}\\alpha_{22}}N_1 \\notag\\\\ N_1\\left(1-\\frac{\\alpha_{12}\\alpha_{21}}{\\alpha_{11}\\alpha_{22}}\\right)&amp;= \\frac{\\alpha_{22}-\\alpha_{12}}{\\alpha_{11}\\alpha_{22}} \\notag\\\\ N_1^*&amp;=\\frac{\\alpha_{22}-\\alpha_{12}}{\\alpha_{11}\\alpha_{22}-\\alpha_{12}\\alpha_{21}} \\tag{7.8} \\end{align}\\] When we do this for \\(N_2\\), we get \\[\\begin{align} N_2^*&amp;=\\frac{\\alpha_{11}-\\alpha_{21}}{\\alpha_{22}\\alpha_{11}-\\alpha_{12}\\alpha_{21}}\\tag{7.9} \\end{align}\\] We now have the values for \\(N_1^*\\) and \\(N_2^*\\) at the point at which their isoclines cross (Fig. 7.4, upper left). These equilibria apply only when isoclines cross within feasible state space. The expressions for \\(N_1^*\\) and \\(N_2^*\\) look pretty complicated, but can we use them to discern an intuitive understanding for species 1? First, we see that \\(r_i\\) is not in the expressions for the equilibria — they do not depend on \\(r_i\\) in this two-species model. Second, we can confirm that as interspecific competition intensity falls to zero (\\(\\alpha_{12}=\\alpha_{21}=0\\)), each species reaches its own carrying capacity. That is, when putative competitors occupy sufficiently different niches and no longer compete, then they both reach their own carrying capacities. We can also say something a little less obvious about species 1. What happens when the negative effect of the competitor, \\(N_2\\), starts to increase, that is, as \\(\\alpha_{12}\\) gets bigger? Or, put more obtusely but precisely, let’s find \\[\\begin{equation} \\label{eq:1} N_1^* = \\lim_{\\alpha_{12} \\to \\infty}\\frac{\\alpha_{22}-\\alpha_{12}}{\\alpha_{22}\\alpha_{11}-\\alpha_{12}\\alpha_{21}} \\end{equation}\\] that is, find the limit of the equilibrium (7.8) as \\(\\alpha_{12}\\) gets very large. Well, the \\(\\alpha_{ii}\\) become effectively zero because \\(\\alpha_{12}\\) gets so big. This leaves \\(-\\alpha_{12}/(-\\alpha_{12}\\alpha_{21})=1/\\alpha_{21}\\). Huh? This means simply that as the negative effect of the competitor increases, the abundance of species 1 becomes increasingly dependent upon \\(\\alpha_{21}\\), its negative effect on its competitor. Thus we have an arms race: as the negative effect of its competitor increases, the abundance of a species depends increasingly on its ability to suppress the competitor. Summarizing, we see that in the absence of interspecific competition, species are attracted toward their carrying capacities. Second, if interspecific competition is intense, then a species’ carrying capacity becomes less important, and its abundance is increasingly determined by its ability to suppress its competitor. 7.2.3 Coexistence — the invasion criterion Based on the numerators in eqs. (7.8) and (7.9), it seems that \\(N_1^*\\) and \\(N_2^*\\) may both be greater than zero whenever \\(\\alpha_{ii}-\\alpha_{ji} &gt;0\\). This is, indeed, the case. Below we step through the analysis of what we refer to as the “invasion criterion,” which specifies the conditions for \\(N_i^* &gt; 0\\). In general, the details of any model and its dynamics may be quite complicated, but as long as we know whether a species will always increase when it is rare, or invade,43 then we know whether it can persist in the face of complex interactions. Thus we don’t need to find its equilibrium, but merely its behavior near zero. How do we determine whether a species can increase when rare? Let’s explore that with the Lotka-Volterra competition model. We can start letting species 1’s growth equation (7.1) be greater than zero. \\[\\begin{equation*} \\tag{7.10} 0 &lt; r_1N_1\\left(1-\\alpha_{11}N_1-\\alpha_{12}N_2\\right). \\end{equation*}\\] From this we can see that in the absence of any density dependence (\\(\\alpha=0\\)) and assuming \\(r_1&gt;0\\), and \\(N_1&gt;0\\), the population grows exponentially. Further, we can see that \\(d N/d t &gt;0\\) as long as \\(\\left(1-\\alpha_{11}N_1-\\alpha_{12}N_2\\right)&gt;0\\). To determine whether \\(N_1\\) can increase when rare we want to figure out what happens when \\(N_1\\) gets very close to zero. We start by expressing \\(d N_1 / d t\\) completely in terms of \\(N_1\\) and \\(\\alpha\\). We do this by substituting \\(N_2\\)’s isocline (7.6) in place of \\(N_2\\) in (7.1). We then solve this for any growth greater than zero. \\[\\begin{align} 0&amp;&lt; \\left(1-\\alpha_{11}N_1-\\alpha_{12}N_2\\right)\\notag\\\\ 0&amp;&lt;\\left(1-\\alpha_{11}N_1-\\alpha_{12}\\left(\\frac{1}{\\alpha_{22}}-\\frac{\\alpha_{21}}{\\alpha_{22}}N_1\\right)\\right) \\tag{7.11} \\end{align}\\] Now — what is the value of (7.11) as \\(N_1 \\to 0\\)? We can substitute 0 for \\(N_1\\), and (7.11) becomes \\[\\begin{align} 0&amp;&lt;\\left(1-\\alpha_{12}\\left(\\frac{1}{\\alpha_{22}}\\right)\\right) \\notag\\\\ 0&amp;&lt;1-\\frac{\\alpha_{12}}{\\alpha_{22}}\\notag\\\\ \\alpha_{12}&amp;&lt;{\\alpha_{22}}. \\end{align}\\] What is this saying? It is saying that as long as \\(\\alpha_{12}&lt;\\alpha_{22}\\), then our focal species can persist, increasing in abundance from near zero — \\(N_1\\) will increase when rare, that is, it will successfully invade. For two species to both persist, or coexist, it must be that case that \\[\\begin{equation*} \\alpha_{12}&lt;\\alpha_{22} \\quad , \\quad \\alpha_{21}&lt;\\alpha_{11} . \\tag{7.12} \\end{equation*}\\] Simply put, for species to coexist stably, their effects on themselves must be greater than their effects on each other (Fig. 7.4, upper left). 7.2.4 Other equilibria Given our isoclines and equilibria above, what other logical combinations might we see, other than coexistence? Here we list others, and provide graphical interpretations (Fig. 7.4). Species 1 can invade when rare, but species 2 cannot (Fig. 7.4, lower left) \\[\\begin{equation*} \\alpha_{12} &lt; \\alpha_{22} \\quad,\\quad \\alpha_{21}&gt;\\alpha_{11} \\end{equation*}\\] This leads to competitive exclusion by species 1 — species 1 wins. This is referred to as a boundary equilibrium, because it is on the boundary of the state space for one species. Equilibria where all \\(N_i&gt;0\\) are referred to as internal equilibria. Species 2 can invade when rare, but species 1 cannot (Fig. 7.4, upper right) \\[\\begin{equation*} \\alpha_{12}&gt;\\alpha_{22} \\quad,\\quad \\alpha_{21}&lt;\\alpha_{11} \\end{equation*}\\] This leads to competitive exclusion by species 2 — species 2 wins. This is the other boundary equilibrium. Note that for both this and the previous boundary equilibrium, the equilibrium equations, (7.8) &amp; (7.9), can return \\(N^*\\) that are negative or too large (\\(&gt;K\\)). Recall that these equations derive from simple equations of straight lines, and do not guarantee that they are used sensibly — equations aren’t dangerous, theoreticians who misuse equations are dangerous. Neither species can invade when rare (Fig. 7.4, lower right). \\[\\begin{equation*} \\alpha_{12} &gt; \\alpha_{22} \\quad,\\quad \\alpha_{21} &gt; \\alpha_{11} \\end{equation*}\\] This creates an unstable internal equilibrium—exclusion will occur, but either species could win. This condition is sometimes referred to as founder control (Bolker, Pacala, and Neuhauser 2003) because the identity of the winner depends in part on the starting abundances. It creates a saddle in state space. What the heck is a saddle? More on that below. It suffices to say that from some directions, an saddle attracts the trajectories of the populations, while from other directions, it repels the trajectories.44 Figure 7.4: Phase plane diagrams of Lotka-Volterra competitors under different invasion conditions. Horizontal and vertical arrows indicate directions of attraction and repulsion for each population (solid and dased arrows); diagonal arrows indicate combined trajectory. Circles indicate equilibria; additional boundary equilibria can occur whenever one species is zero. Left to right: stable eq., \\(a_{ji} &lt; a_{ii}\\); \\(N_2\\) wins, \\(a_{12} &gt; a_{22}\\); \\(N_1\\) wins, $a_{21} &gt; a_{11}; saddle attractor-repellor, \\(a_{ji} &gt; a_{ii}\\). 7.3 Dynamics at the Equilibria Here we use eigenanalysis to analyze the properties of the equilibrium, whether they are attractors, repellers, or both, and whether the system oscillates around these equilibria. For logistic growth, we assessed stability with the partial derivative of the growth rate, with respect to population size. If it was negative the population was stable, and the more negative the value, the shorter the return time. Here we build on this, and present a general recipe for stability analysis (Morin 1999): Determine the equilibrium abundances of each species by setting its growth equation to zero, and solving for \\(N\\). Create the Jacobian matrix. This matrix represents the response of each species to changes in its own population and to changes in each other’s populations. The matrix elements are the partial derivatives of each species’ growth rate with respect to each population. Solve the Jacobian. Substitute the equilibrium abundances into the partial derivatives of the Jacobian matrix to put a real number into each element of the Jacobian matrix. Use the Jacobian matrix to find the behavior of the system near the equilibria. The trace, determinant, and eigenvalues of the Jacobian can tell us how stable or unstable the system is, and whether and how it cycles. 7.3.1 Determine the equilibria We just did this above. Given (7.8) and (7.9), we see that the \\(\\alpha\\) determine completely \\(N_1^*\\) and \\(N_2^*\\). This is not true for Lotka-Volterra systems with more than two species; such systems also depend on \\(r_i\\). Finding equilibria in R can be done using expressions for the equilibria, \\(N_1^*\\) and \\(N_2^*\\). An R expression is a symbolic representation of an equation. These will be symbolic representations that we later evaluate using eval(). N1Star &lt;- expression( (a22-a12)/(a22*a11 - a12*a21) ) N2Star &lt;- expression( (a11-a21)/(a22*a11 - a12*a21) ) Next we create the \\(\\mathbf{\\alpha}\\) and evaluate our expressions. a11 &lt;- a22 &lt;- 0.01; a12 &lt;- 0.001; a21 &lt;- 0.001 N1 &lt;- eval(N1Star); N2 &lt;- eval(N2Star) N1 ## [1] 90.90909 7.3.2 Create the Jacobian matrix The next step is to find each partial derivative. The partial derivatives describe how the growth rate of each species changes with respect to the abundance of each other species and with respect to its own abundance. Thus a positive value indicates that a growth rate increases as another population increases. This might be the case with predator growth rate and its prey population. A negative value indicates a growth rate decreases as another population increases. This is likely to be true for competitors or prey growth rate and its predator population. Here, we work through an example, deriving the partial derivative of species 1’s growth rate with respect to itself. First let’s expand the growth rate of species 1 (7.1)45 \\[\\begin{align} \\frac{d N_1}{d t}&amp;=\\dot{N_1} =r_1N_1 - r_1\\alpha_{11}N_1^2 - r_1\\alpha_{12}N_2N_1. \\end{align}\\] Now we derive the partial differential equation (PDE)46 with respect to \\(N_1\\), treating \\(N_2\\) as a constant. \\[\\begin{equation} \\frac{\\partial \\dot{N_1} }{\\partial N_1}=r_1 - 2r_1\\alpha_{11}N_1 - r_1\\alpha_{12}N_2 \\end{equation}\\] We should think of this as the per capita effect of species 1 on its growth rate. To derive the PDE with respect to \\(N_2\\), we treat \\(N_1\\) as a constant, and find \\[\\begin{equation} \\frac{\\partial \\dot{N_1} }{\\partial N_2}= - r_1\\alpha_{12}N_1. \\end{equation}\\] This is the per capita effect of species 2 on species 1’s growth rate. We then do the same for \\(\\dot{N_2}\\), and so derive the full matrix of PDE’s, \\[\\begin{align} \\tag{7.13} \\left( \\begin {array}{cc} \\frac{\\partial \\dot{N_1}}{\\partial N_1}&amp;\\frac{\\partial \\dot{N_1}}{\\partial N_2}\\\\ \\frac{\\partial \\dot{N_2} }{\\partial N_1}&amp;\\frac{\\partial \\dot{N_2}}{\\partial N_2} \\end {array} \\right) = \\left( \\begin {array}{cc} r_1 - 2r_1\\alpha_{11}N_1 - r_1\\alpha_{12}N_2&amp; - r_1\\alpha_{12}N_1\\\\ - r_2\\alpha_{21}N_2&amp;r_2 - 2r_2\\alpha_{22}N_2 - r_2\\alpha_{21}N_1\\\\ \\end {array} \\right). \\end{align}\\] This matrix of PDEs is the Jacobian matrix, or simply the “Jacobian.” As differential equations, they describe the slopes of curves (i.e. the slopes of tangents of curves) at a particular point. That is, they describe the straight line interpretations as that point. As partial differential equations, they describe how the growth rates change as population sizes change. Finding partial differential equations and the Jacobian matrix in R can be done using expressions. Here we create equations or expressions for the for the growth rates, \\(\\dot{N_1}\\) and \\(\\dot{N_2}\\), and use these to find the partial derivatives. First, expressions for the growth rates: dN1dt &lt;- expression( r1 * N1 - r1 * a11 * N1^2 - r1 * a12 * N1 * N2 ) dN2dt &lt;- expression(r2*N2 - r2*a22*N2^2 - r2*a21*N1*N2) Next, we use each expression for \\(\\dot{N}\\) to get each the partial derivatives with respect to each population size. Here we use the R function D() (see also ?deriv). We reveal here the result for the first one only, the partial derivative of \\(\\dot{N_1}\\) with respect to itself, and then get the others. ddN1dN1 &lt;-D(dN1dt, &quot;N1&quot;) ddN1dN1 ## r1 - r1 * a11 * (2 * N1) - r1 * a12 * N2 Here we find the remaining PDEs. ddN1dN2 &lt;- D(dN1dt, &quot;N2&quot;) ddN2dN1 &lt;- D(dN2dt, &quot;N1&quot;) ddN2dN2 &lt;- D(dN2dt, &quot;N2&quot;) Last we put these together to create the Jacobian matrix, which is itself an expression that we can evaluate again and again. J &lt;- expression( matrix(c(eval(ddN1dN1), eval(ddN1dN2), eval(ddN2dN1), eval(ddN2dN2)), nrow=2, byrow=TRUE) ) 7.3.3 Solve the Jacobian at an equilibrium To solve the Jacobian at an equilibrium, we substitute \\(N_1^*\\) (7.8) and \\(N_2^*\\) (7.9) into the Jacobian matrix (7.13). Refer to those equations now. What is the value of \\(N_1\\) in terms of \\(\\alpha_{ii}\\) and \\(\\alpha_{ij}\\)? Take that value and stick it in each element of the Jacobian (7.14). Repeat for \\(N_2\\). When we do this, and rearrange, we get, \\[\\begin{align} \\mathbf{J}= \\left( \\begin {array}{cc} -r_1\\alpha_{11}\\left(\\frac{\\alpha_{22}-\\alpha_{12}}{\\alpha_{11}\\alpha_{22}-\\alpha_{12}\\alpha_{21}}\\right)&amp; - r_1\\alpha_{12}\\left(\\frac{\\alpha_{22}-\\alpha_{12}}{\\alpha_{11}\\alpha_{22}-\\alpha_{12}\\alpha_{21}}\\right)\\\\ - r_2\\alpha_{21} \\left(\\frac{\\alpha_{11}-\\alpha_{21}}{\\alpha_{11}\\alpha_{22}-\\alpha_{12}\\alpha_{21}}\\right)&amp; -r_2\\alpha_{22}\\left(\\frac{\\alpha_{11}-\\alpha_{21}}{\\alpha_{11}\\alpha_{22}-\\alpha_{12}\\alpha_{21}}\\right)\\\\ \\end {array} \\right). \\tag{7.14} \\end{align}\\] Yikes \\(\\ldots\\) seems a little intimidating for such a small number of species. However, it is remarkable how each element can be expressed as a product of \\(-r_i\\alpha_{ij}N_i^*\\), where \\(i\\) refers to row, and \\(j\\) refers to column. Evaluating the Jacobian matrix in R is the easy part, if we defined it as above. Assuming that above we selected particular \\(\\mathbf{\\alpha}\\), used these to determine \\(N_1^*\\) and \\(N_2^*\\), found the PDEs and created an expression for the Jacobian matrix, and labeled everything appropriately, we can then evaluate the Jacobian at an equilibrium. For \\(\\alpha_{ii}=0.01\\) and \\(\\alpha_{ij}=0.001\\) (see above) we find r1 &lt;- r2 &lt;- 1 J1 &lt;- eval(J) J1 ## [,1] [,2] ## [1,] -0.90909091 -0.09090909 ## [2,] -0.09090909 -0.90909091 Note that all of these PDEs are negative for this equilibrium. This indicates a stable equilibrium, because it means that each population’s growth rate slows in response to an increase in any other. 7.3.4 Use the Jacobian matrix Just the way we used eigenanalysis to understand long term asymptotic behavior of demographic matrices, we can use eigenanalysis of the Jacobian to assess the long-term asymptotic behavior of these competing Lotka-Volterra populations. We can again focus on its dominant, or leading, eigenvalue (\\(\\lambda_1\\)). The dominant eigenvalue will be the eigenvalue with the greatest real part, and not necessarily the eigenvalue with the greatest magnitude.47 In particular, the dominant eigenvalue, \\(\\lambda_1\\), may have a real part for which the magnitude48 is smaller, but which is less negative or more positive (e.g., \\(\\lambda_1=-.01\\), \\(\\lambda_2=-1.0\\)). For continuous models, the dominant eigenvalue, \\(\\lambda_1\\), is approximately the rate of change of a perturbation, \\(x\\), from an equilibrium, \\[\\begin{equation} \\tag{7.15} x_t=x_0e^{\\lambda_{1}t}. \\end{equation}\\] Thus, the more negative the value, the faster the exponential decline back toward the equilibrium (i.e., toward \\(x=0\\)). As we did for logistic growth, we should think of the dominant eigenvalue as a “perturbation growth rate”: negative values mean a decline of the perturbation, and positive values indicate an increase in the perturbation, causing the system to diverge or be repelled away from the equilibrium. In addition to the dominant eigenvalue, we need to consider the other eigenvalues. Table 7.2 provides a summary for interpreting eigenvalues with respect to the dynamics of the system. The eigenvalues depend upon elements of the Jacobian, and values calculated from the elements, notably the determinant, the trace, and the discriminant; a similar set of rules of system behavior can be based upon these values (Roughgarden 1998). For instance, the Routh-Hurwitz criterion for stability tells us that a two-species equilibrium will be locally stable, only if \\(\\mathbf{J_{11}} + \\mathbf{J_{22}} &lt; 0\\) and if \\(\\mathbf{J_{11}}\\mathbf{J_{22}-\\mathbf{J_{12}}\\mathbf{J_{21}}} &gt; 0\\). The biological interpretation of this criterion will be posed as a problem at the end of the chapter. For now, Table 7.2 will suffice. Table 7.2: Interpreting eigenvalues of a Jacobian matrix. Eigenvalues Interpretation All real parts \\(&lt; 0\\) Globally Stable Point (Point Attractor) Some real parts \\(&lt; 0\\) Saddle (Attractor-Repellor) No real parts \\(&lt; 0\\) Globally Unstable Point (Point Repellor) Real parts \\(= 0\\) Neutral Imaginary parts absent No oscillations Imaginary parts present (\\(\\pm\\omega i\\)) Oscillations with period \\(2\\pi/\\omega\\) Eigenanalysis of the Jacobian matrix in R is easy once we evaluated the Jacobian matrix at its equilibrium (above). We simply perform eigenanalysis on the matrix (from previous boxes: \\(\\alpha_{11}=\\alpha_{22}=0.01,\\,\\alpha_{12}=\\alpha_{21}=0.001,\\, r=1\\)). eigStable &lt;- eigen(J1); eigStable[[&quot;values&quot;]] ## [1] -0.8181818 -1.0000000 The dominant eigenvalue is negative (the larger of the two: \\(\\lambda_1\\) = -0.818) indicating a globally stable equilibrium (Table 7.2. Both eigenvalues are real, not complex, indicating that there would be no oscillations (Table 7.2). 7.3.5 Three interesting equilbria Here we examine the dynamical properties of three particularly interesting internal equilibria that are, respectively, stable, unstable, and neutral. In each case, our examples use \\(\\alpha_{11}=\\alpha_{22}=0.01\\) and \\(r_1=r_2=1\\). What is most important, however, is not the particular eigenvalues, but rather their sign, and how they vary with \\(\\alpha_{12}\\) and \\(\\alpha_{21}\\), and the resulting stability properties and trajectories. Given our stability criteria above, let us next examine the dominant eigenvalue of the Jacobian for each equilibrium but which values of \\(\\alpha_{ij},\\,\\alpha_{ji}\\) should we choose? We can describe our invasion criterion for species \\(i\\) as \\[\\begin{equation} \\tag{5.5} \\beta_{ij}=\\alpha_{ij}/\\alpha_{jj} \\end{equation}\\] where, if \\(\\beta_{ij}&lt;1\\), species \\(i\\) can invade. This ratio is the relative strength of inter- vs. intraspecific competitive effect. It turns out to be useful to calculate \\(\\lambda_1\\) (``perturbation growth rate’’) for combinations of \\(\\beta_{ij},\\,\\beta_{ji}\\). Stable equilibrium – \\(\\beta_{ij},\\, \\beta_{ji} &lt;1\\): These criteria correspond to \\(\\alpha_{12}&lt;\\alpha_{22}\\, , \\, \\alpha_{21}&lt;\\alpha_{11}\\). As the relative strength of interspecific effects increases toward 1.0, \\(\\lambda_1\\) approaches zero, at which point the system would no longer have a single global point attractor. When \\(\\beta_{ij},\\, \\beta_{ji} &lt;1\\), then both species can invade each other. We find that all of the eigenvalues of the Jacobian are negative and real (Fig. 7.5, demonstrating that these populations will reach a stable equilibrium (Table 7.2. When we plot these eigenvalues for these combinations of \\(\\beta\\), we see that the dominant eigenvalue increases from negative values toward zero as either \\(\\beta_{12}\\) or \\(\\beta_{21}\\) approaches 1 (Fig. 7.5). Figure 7.5: Stable equilibria: as the relative strength of interspecific competition increases (B(ij) increases toward 1), instability increases (lambda(1) increases toward 0). Solid dots represent initial abundances. Unstable equilibria – \\(\\beta_{ij}, \\, \\beta_{ji} &gt; 1\\) These criteria correspond to \\(\\alpha_{12}&gt;\\alpha_{22} ,\\, \\alpha_{21}&gt;\\alpha_{11}\\) (Fig. 7.6). As we saw above, the Lotka-Volterra competition model has not only stable equilibria, but also unstable equilibria, when both populations are greater than zero. Although an unstable equilibrium cannot persist, \\(\\beta_{ij}, \\, \\beta_{ji} &gt; 1\\) creates interesting and probably important dynamics(Hastings 2004). One of the results is referred to as founder control, where either species can colonize a patch, and whichever species gets there first (i.e. the founder) can resist any invader (Bolker, Pacala, and Neuhauser 2003). Another interesting phenomenon is the saddle itself; this unstable equilibrium is an attractor-repeller, that is, it attracts from some directions and repels from others (Fig. 7.6). This implies that the final outcome of dynamics may be difficult to predict from initial trajectories. Figure 7.6: Unstable equilibria: as the relative strength of interspecific competition increases (B(ij) &gt; 1), instability increases (lambda(1) &gt; 0). The unstable equilibrium may attract trajectories from some initial states, but repel from others (solid dots represent initial abundances). Recall the geometric interpretation of this unstable equilibrium — a saddle. The trajectory of a ball rolling across a saddle can depend to a very large degree on where the ball starts. Place it on the crown of the saddle, and it will tend to roll in a very deterministic fashion directly toward the unstable equilibrium, even if it eventually rolls off the side. Eigenanalysis in R of the Jacobian where \\(\\beta_{ij}, \\, \\beta_{ji} &gt; 1\\): Here we create values for \\(\\mathbf{\\alpha}\\) that create an unstable equilbrium. a11 &lt;- a22 &lt;- 0.01 a12 &lt;- a21 &lt;- 0.011 N1 &lt;- eval(N1Star); N2 &lt;- eval(N2Star) eigen( eval(J) )[[&quot;values&quot;]] ## [1] 0.04761905 -1.00000000 The dominant eigenvalue is now positive, while the other is negative, indicating a saddle (Table 7.2. Neutral equilibria — \\(\\beta_{ij} = \\beta_{ji} = 1\\): What happens when the inter- and intraspecific effects of each species are equal? This puts the populations on a knife’s edge, between an unstable saddle and a stable attractor. Let’s think first about a geometric interpretation, where we shift between a bowl, representing a stable attractor, and a saddle, representing what we call a neutral saddle. Imagine that we begin with a stable attractor, represented by a bowl, where \\(\\alpha_{ij} &lt; \\alpha_{ii}\\). We drop a ball in a bowl, and the bowl rolls to the bottom — the global attractor. As we increase the interspecific competition coefficients, \\(\\alpha_{ij} \\to \\alpha_{ii}\\), we are pressing down on just two points on opposite sides of the bowl. Our hands push down on two opposite sides, until the bowl is flat in one direction, but has two remaining sides that slope downward. Perhaps you think this looks like a taco shell? The same shape is easily replicated by just picking up a piece of paper by opposite edges, letting it sag in the middle. This is the neutral saddle. What would eigenanalysis tell us? Let’s find out. We could just charge ahead in R, and I encourage you to do so, repeating the steps above. You would find that doesn’t work because when \\(\\beta_{ij} = \\beta_{ji} = 1\\), our equilibria are undefined (numerator and denominator are zero in (7.8), (7.9). Hmmm. Perhaps we can simplify things by taking the limit of the equilibrium, as \\(\\alpha_{ij} \\to \\alpha_{jj}\\). Let \\(\\alpha_{12}=a\\) and \\(\\alpha_{22}=a+h\\), and let \\(\\alpha_{21}=b\\) and \\(\\alpha_{11}=b+h\\). Then we want the limit of the equilibrium as \\(h\\) goes to zero. \\[\\begin{align} \\tag{7.16} \\lim_{h \\to 0}\\frac{\\left(a+h\\right)-a}{\\left(a+h\\right)\\left(b+h\\right) - ab} &amp;=\\frac{1}{a+b} \\end{align}\\] Thus, \\(N_1^* = 1/(\\alpha_{11}+\\alpha_{22})\\), assuming \\(\\alpha_{12} = \\alpha_{22}\\) and \\(\\alpha_{21}=\\alpha_{11}\\). Therefore, the equilibrium population size is simply the inverse of the sum of these coefficients. Eigenanalysis in R of the Jacobian where \\(\\beta_{ij} = \\beta_{ji} = 1\\): Here we create values for \\(\\mathbf{\\alpha}\\) that create a neutral equilbrium. a11 &lt;- a21 &lt;- 0.01; a22 &lt;- a12 &lt;- 0.015 We determine \\(N^*\\) using (7.16) because the usual expression, (7.9), fails because the denominator equals 0. N1 &lt;- N2 &lt;- 1/(a11+a22) eigen( eval(J) )[[&quot;values&quot;]] ## [1] -1 0 The dominant eigenvalue is now zero, indicating a neutral equilibrium (Table 7.2. The neutral nature of this equilibrium results in more than one equilibrium. Let’s try a different one, also on the isocline. N1 &lt;- 1/(a11); N2&lt;-0 eigen( eval(J) )[[&quot;values&quot;]] ## [1] -1 0 Again \\(\\lambda_1=0\\) so this equilibrium is also neutral. When we perform eigenanalysis, we find that the largest of the two eigenvalues is zero, while the other is negative. This reveals that we have neither a bowl nor an unstable saddle, but rather, a taco shell, with a level bottom — a neutral saddle. Figure 7.7: Trajectories of N(1),N(2) for \\(eta_{12} = eta_{21} = 1\\). The entire isocline is an attractor, a neutral saddle, and the final abundances depend on the initial abundances and the ratio of \\(lpha_{11}/lpha_{22}\\). The circle represents our one derived equilibrium. For example, if the populations start at low abundances, both populations will tend to increase at constant rates until they run into the isocline. Thus, both populations can increase when rare, but the relative abundances will never change, regardless of initial abundances. Recall the Lotka-Volterra isoclines, and what we originally stated about them. We stated that the equilibrium will be the point where the isoclines cross. When all \\(\\beta_{ij} = \\beta_{ji} = 1\\), the isoclines completely overlap, so we have an infinite number of equilibria—all the points along the line \\[\\begin{equation} N_2= \\frac{1}{\\alpha_{22}} - \\frac{\\alpha_{11}}{\\alpha_{22}}N_1 \\end{equation}\\] and the initial abundances determine the trajectory and the equilibrium (Fig. 7.7). 7.4 Return Time and the Effect of \\(r\\) Above, we referred to \\(\\lambda_1\\) as the perturbation growth rate. More commonly, people refer to another quantity known as characteristic return time. Return time is commonly calculated as the negative inverse of the largest real part of the eigenvalues, \\[\\begin{equation} \\tag{7.17} RT = -\\frac{1}{\\lambda_1}. \\end{equation}\\] It is the time required to return a fraction of the distance49 back toward an equilibrium. Negative return times (\\(\\lambda_1&gt;0\\)) refer to “backward time,” or time into the past when this population would have been this far away (Fig. 7.8. If we envision the populations sitting at an equilibrium, we can then envision a small perturbation that shifts them away from that point in state space. Let’s call this displacement \\(x_0\\). The rate of change of in \\(x\\) is approximately the exponential rate, \\[\\begin{equation} \\tag{6.5} \\frac{d x}{d t} \\approx c\\lambda_1 t. \\end{equation}\\] where \\(c\\) is a constant, so the distance traveled, \\(x\\), is given by (7.15). Therefore, a negative \\(\\lambda_1\\) indicates an exponential decline in the disturbance, back toward the equilibrium (Fig. 7.8. The units of return time are the same as for \\(r\\). Recall that all of this depends on the linearization of the curved surface around an equilibrium; it therefore applies exactly to only an infinitesimally small region around the equilibrium. It also usually provides the average, regardless of whether the perturbation is a population decline or a population increase. Figure 7.8: For \\(eta_{ij} &lt; 1\\), return time is positive because some time will lapse before the system returns toward to its equilibrium. For \\(eta_{ij}&gt;1\\), return time is negative, because the system was closer to the (unstable) equilibrium in the past. Effect of \\(r\\) on stability and return time Consider the Jacobian matrix (7.14), and note that \\(-r_i\\) appears in each Jacobian element. Therefore, the larger the \\(r\\), the greater the magnitude of the Jacobian elements. This causes \\(\\lambda_1\\) to increase in magnitude, reflecting greater responsiveness to perturbation at the equilibrium (Fig. 7.9. If we consider return time for continuous models where \\(\\beta_{12},\\,\\beta_{21} &lt; 1\\), greater \\(r\\) shortens return time, increasing stability (Fig. 7.9. For continuous models where \\(\\beta_{12},\\,\\beta_{21} &gt; 1\\), greater \\(r\\) increases perturbation growth rate, decreasing stability (Fig. 7.9. For discrete models, which we have not discussed in this context, recall that increasing \\(r_d\\) of discrete logistic growth can destabilize the population because of the built-in lag. The same is true for discrete competition models — increasing \\(r_d\\) too much destabilizes the interaction. Figure 7.9: The dominant eigenvalue of the Jacobian matrix varies with r as well as with \\(eta\\) — higher r causes greater responsiveness to perturbations around an internal equilibrium for r = 1 and r = 0.5. 7.5 Indirect competition for resources Consumption is key to life. Energy consumption occurs as heterotrophs consume inorganic material and autotrophs use the sun or oxidation of inorganic molecules to acquire energy. All organisms require carbon and inorganic materials such as nitrogen and phosphorus as basic building blocks of cells. when one or more of these limit growth, we refer to these as limiting resources, and when differential growth limitation among species occurs as a result of this short supply, we refer to this as resource limitation and consequently resource competition. In this chapter, we work through an example of resource competition among photoautotrophs for inorganic resources (Tilman 1982). As with nearly all the models in this book, We represent the growth of resources and consumers as growth rate = gains - losses. Here we start with a relatively simple version, with two plant species competing for one limiting resource such as nitrogen (Roughgarden 1998). 7.5.1 Linear and nonlinear responses Let our resource \\(R\\) be supplied at a constant rate, \\(S\\), perhaps determined by nitrifying soil microbes at steady state. This rate declines as the amount of resource grows, or \\(S-aR\\). This is likely to happen when a resource is washed out of the soil, or if a high amount of resource suppresses its production. \\[\\frac{dR}{dt} = S-aR\\] In the absence of anything else removing the resource, the equilibrium amount would be \\(R^* = S/a\\). However, our plant species will remove resource from the resource pool. Let our competitors be measured in grams of biomass, where their growth rate depends on resource uptake and a constant loss rate, \\[\\frac{dP_1}{dt} = (u_1 R - d_1)P_1\\] \\[\\frac{dP_2}{dt} = (u_2 R - d_2)P_2\\] As we can see, these two species do not interact directly. Parameters \\(d_i\\) are grams lost per gram of plant per unit time. The parameters \\(u_i\\) are the rates of grams gained per gram of plant per unit resource per unit time. They do interact with resources. Here we graph mass-specific growth rates (analogous to per capita growth rates)as a funciton of resource concentrations. u1 &lt;- 1; d1 &lt;- .3 u2 &lt;- .5; d2 &lt;- 0.1 { par(mar=(c(5, 4,.5,.5))) curve(u1*x - d1, ylab=&quot;dP/(Pdt)&quot;, xlab=&quot;Resource concentration&quot;) curve(u2*x - d2, lty=2, col=2, add=TRUE) abline(h=0, lty=3) legend(&quot;topleft&quot;, c(&quot;Sp. 1&quot;, &quot;Sp. 2&quot;), lty=1:2, col=1:2, bty=&#39;n&#39;) } Figure 7.10: Mass-specific growth rates of two species across a range of resource concentrations. From Fig. 7.10, we see that at high resource concentrations, species 1 grows faster than species 2. However, at low resource concentrations, species 2 grows faster than species 1. Resource concentrations change as plants take up resources, so when does the whole system reach an equilibrium? Both species (Fig. 7.10) increase in biomass as long as resources are high enough to allow growth, whereas resources will decline as plant grow more and more and take up increasing amounts of resources. Eventually plant biomass is high enough to drive down resources so low that mass-specific growth rate is zero. This will happen at different resource concentrations for our two species. We see that species 2 has a positive growth rate when species 1 does not (Fig. 7.10). If we try to solve for the equilibrium for \\(P_1\\), we get \\[\\begin{align*} 0&amp;=(u_1 R -d_1)P_1\\\\ 0&amp;=(u_1 R - d_1)\\\\ R_{P1}^* &amp;= d_1 / u_1 \\end{align*}\\] where we get an equilibrium resource concentration in the presence of only species 1, but not \\(P_1^*\\). Similarly, we would find \\(R_{P2}^* = d_2 / u_2\\). So, for the above species, the equlibirum resource concentrations are the \\(x\\)-intercepts, or (Rstar &lt;- c(R1=d1/u1, R2=d2/u2)) ## R1 R2 ## 0.3 0.2 Just as we saw in Fig. 7.10, these values predict that species 2 will grow at a lower resource levels than species 1 and is therefore predicted to exclude species 1. This type of resource competition for a single limiting resource was named the \\(R^*\\) rule (“R-star”): The species with the lowest \\(R^*\\) for the shared limiting resource will exclude all others. We refer to this type of resource competition as \\(R^*\\) competition. When one species excludes the other, what will the equilibrium value, \\(P^*\\), be? For that, we need to refine our expression for \\(R\\) to include uptake by plants: \\[\\frac{dR}{dt} = S-aR - w_1u_1P_1R - w_2u_2P_2R\\] Parameters \\(w_1\\) and \\(w_2\\) are the amount of resource per gram of biomass, or the resource concentrations in the two plant species. Now that we have an explicit expression for resource dynamics, we can create a model to integrate the dynamics of these three components. rcomp &lt;- function(time, y, parameters){ P1 &lt;- y[1]; P2 &lt;- y[2]; R &lt;- y[3]; with( as.list(parameters),{ dP1 &lt;- (u1*R - d1)*P1 dP2 &lt;- (u2*R - d2)*P2 dR &lt;- S -a*R - w1*u1*P1*R - w2*u2*P2*R return(list(c(dP1, dP2, dR))) }) } Now we run the model. t &lt;- seq(0, 150, by=.5) p &lt;- list(u1=1, u2=0.5, d1=0.3, d2=0.1, w1=.01, w2=.01, S=1, a=.1) Peq &lt;- with(as.list(p),{ c( P1=(S*u1 - a*d1)/(w1*d1*u1), P2=(S*u2 - a*d2)/(w2*d2*u2)) }) Peq ## P1 P2 ## 323.3333 980.0000 y.initial &lt;- c(P1=200, P2=50, R=1) rout &lt;- ode(y=y.initial, time=t, fun=rcomp, parms=p) rdf &lt;- data.frame( rout) r.long &lt;- pivot_longer(rdf, -time, names_to = &quot;State&quot;, values_to = &quot;Grams&quot;) ggplot(data=r.long, aes(time, Grams, colour=State, linetype=State)) + geom_line() + facet_wrap(~State, scales=&quot;free&quot;) Now if we like, we can find \\(P_2^*\\) when \\(R^*=d_2/u_2\\), and \\(P_1 =0\\). \\[\\begin{align*} \\frac{dR}{dt} = 0 &amp;= S-a(d_2/u_2) - w_2u_2P_2(d_2/u_2)\\\\ w_2d_2P_2 &amp;= S-ad_2/u_2\\\\ P^*_2 &amp;= \\frac{S u_2 - a d_2}{u_2 w_2 d_2} \\end{align*}\\] It is clear from this expression that increasing the death rate (\\(d\\)) will drive down \\(P^*_2\\), and so will \\(w\\) because it is less efficient—as the nutrient content of the plant increases, the amount of biomass it can make declines. We also see that increasing the supply rate, \\(S\\), and decreasing the background resource loss rate, \\(a\\), will drive up biomass. In addition, as long as \\(S &gt; w_2 d_2\\) increasing resource-dependent gain rate, \\(u_2\\) will also drive up equilibrium biomass. # let u_2 be &#39;x&#39; # I use bquote() for math-friendly labels, but you don&#39;t have to. with( as.list(p), { curve( (S *x - a*d2)/(x*w2*d2), 0, 3, ylab=bquote((S *u[2] - a*d[2])/(u[2]*w[2]*d[2])), xlab=bquote(u[2]) ) }) Figure 7.11: As uptake rate (\\(u\\)) increases, euilibrium biomass will increase as well. In the above model, per capita growth rates were linear functions of resource concentration. In Tilman’s presentation of resource competition, the consumers had nonlinear resource-dependent growth rates, \\[\\frac{dP_i}{Pdt}= r_i\\frac{R}{k_i + R} - d_i\\] You might recognize this as related to Michaelis-Menton enzyme kinetics. It was used in bacteriology by Monod to model culture growth in chemostats. It looks like Fig. 7.12. r &lt;-c(1, .5); k=c(5, .1); d = 0.3 {curve(r[1]*x/(k[1]+x) - d, 0, 10, ylab=bquote(dP/(Pdt)), xlab=&quot;R&quot;) curve(r[2]*x/(k[2] + x) - d, lty=2, add=TRUE) abline(h=0, lty=3); text(7.5, 0, &quot;gain = loss&quot;, adj=c(.5, -.3)) } Figure 7.12: The Monod function for per capita resource-dependent growth rates of two different populations. As we saw earlier with linear mass-specific growth rates, one species will have a lower \\(R^*\\) than the other, and this model predicts that it will outcompete the other. 7.5.2 Relative nonlinearity The \\(R^*\\) model does not permit coexistence in part because of how the resource replenishes. Our above model of the resource \\(R\\) permits only a declining rate of change (rate of renewal declines with increasing R). In contrast, if the resource is biotic, such as a rapidly growing prey population, the renewal may accelerate with increasing population size. Figure 7.13: Different types of resources can renew in different ways. An inorganic soil nutrient might renew the way we modeled it in R competition, whereas a prey population might renew via exponential growth.* Under these circumstances, it is possible for our model to predict coexistence, if the two competitors have sufficiently different curvature in their growth responses (Armstrong and McGehee 1980). This gives rise to the name “relative nonlinearity”. Here is a sample model: \\[\\begin{align*} \\frac{d P_1}{dt} &amp;= m_1\\left(-1 + \\alpha_1 \\frac{R}{k_1 + R} \\right)P_1 \\\\ \\frac{d P_2}{dt} &amp;= m_2\\left(-1 + \\alpha_2 \\frac{R}{k_2 + R} \\right)P_2 \\\\ \\frac{dR}{dt} &amp;= rR(1-\\alpha_3 R) - \\alpha_1 P_1\\frac{R}{k_1 + R} - \\alpha_2 P_2\\frac{R}{k_2 + R} \\end{align*}\\] Figure 7.14: The type of fixed oscillations possible given a self-reproducing resource and consumers with whose nonlinear growth rates differ in their curvature. The parameters are the same as in the previous figure. 7.5.3 Competition for two resources: the resource ratio model The \\(R^*\\) model predicts no coexistence, and relative nonlinearity works with only a biotic resource. Tilman (1982) proposed the resource ratio model, that uses two resources with two or more competitors. In this model, what determines competitive outcomes are the ratios of the supply rates of the two resources, and the uptake rates of each species. Coefficients reflect resource \\(i\\) and species \\(j\\). \\[ \\frac{1}{R_1}\\frac{dR_1}{dt} = a_1\\left(S_1-R_1\\right) - \\left( dN_1/dt + m_1 \\right) / e_{11} - \\left( dN_2/dt + m_2 \\right) /e_{12} \\] \\[ \\frac{1}{R_2}\\frac{dR_2}{dt} = a_2\\left(S_2-R_2\\right) - \\left( dN_1/dt + m_1 \\right) / e_{21} - \\left( dN_2/dt - m_2 \\right) /e_{22} \\] \\[ \\frac{1}{N_1}\\frac{ dN_1 }{dt} = r_1 \\,\\mathrm{MIN}\\left(c_{11}\\frac{R_1}{k_{11} + R_1} \\, , \\, c_{21}\\frac{R_2}{k_{21} + R_1}\\right) - m_1\\] \\[ \\frac{1}{N_2}\\frac{ dN_2 }{dt} = r_2 \\,\\mathrm{MIN}\\left(c_{12}\\frac{R_1}{k_{12} + R_1} \\, , \\, c_{22}\\frac{R_2}{k_{22} + R_1}\\right) - m_2\\] This model might be used to represent algae competing for nitrogen and phosphorus. In our description below, we’ll use the example of eastern red cedar (Juniperus virginiana) and red maple competing for nitrogen and light. Here we present one of the cases proposed by Tilman, in which resources are not substitutable. This means that getting more of one doesn’t help compensate for a shortage of the other. This is reflected in the zero net growth isoclines (ZNGI) in Fig. ??. Each ZNGI is perpendicular to the relevant resource axis. For instance, the ZNGI for light is flat; it doesn’t matter how much nitrogen maple gets, its minimum light requirement remains the same. Figure 7.15: Two resources, and the zero net growth isoclines for two competing species. These show that maple has a higher minimum requirement for nitrogen than for light, and the reverse for juniper. The arrows show how each species consumes the two resources simultaneously—they are the ‘consumption vectors’. Their direction shows how maple and juniper drive down light and nitrogen levels. The different slopes show us that us that each species consumes the two resources at different rates. Maple consumes twice as much light as nitrogen, and reverse for juniper. The units are arbitrary. If we put these species on the same graph, we get Fig. 7.16. Here we see what happens to light and N levels when both species are driving down resource levels at the same time: their consumption vectors sum so that the slope of the combined vector (grey) is intermediate between the two different species consumption vectors (black or dashed). Fig. 7.16 helps illustrate three different environments: high light, low nitrogen (B), intermediate levels of both (A), and low light, high nitrogen (C). When both resources are supplied at intermediate rates (A), the juniper and maple drive down light and N until these resources limit both species simultaneously and the coexist. If light is supplied at a much higher rate (B), the high light levels favor juniper because juniper can do very well if it gets lots of light. This illustrates a key insight from resource competition theory. Juniper succeeds in a high light envornment precisely it is a good competitor for resources other than light. In this example, juniper is not a good competitor for light. Light is supplied at a high rate. All species have enough light. The species that succeeds is the one that competes well for what is in shorter supply. To repeat that idea: the species that succeeds in a resource rich environment is not a good competitor for that resource. Instead, it is released from limitation by that resource. It may be a good competitor for some resource that is in short supply. Figure 7.16: Two resources, and the zero net growth isoclines for two competing species. This figure merely combines the two previous figures. As above, each species consumes more of the resource for which they have a higher requirement. A-C illustrate different resource supply rates. A, Light and nitrogen are supplied at equal rates. B, Light is supplied at a higher rate than nitrogen. C, Nitrogen is supplied at a higher rate than light. In contrast to the above scenario, species will not coexist if they consume more of the resource that is less limiting and less of the resource that is more limiting (Fig. 7.17). \\(\\frac{R_{2,i}^*}{R_{1,i}^*}\\) Figure 7.17: What happens with greedy species. When species consume more of the resource for which they have lower reuirements, theory predicts competitive exclusion, where the outcome is determined by initial abundances. resratio &lt;- function(t, y, parameters){ R1 &lt;- y[1]; R2 &lt;- y[2]; N1 &lt;- y[3] ; N2 &lt;- y[4] ; with(as.list(parameters), { N1.dot &lt;- r1 * N1 * ( min( c( c11*R1/(k11 + R1), c21*R2/(k21 + R2) ) ) - m1 ) N2.dot &lt;- r2 * N2 * ( min( c( c12*R1/(k12 + R1), c22*R2/(k22 + R2) ) ) - m2 ) ## R.dot must follow N.dot because we use N.dot in R.dot R1.dot &lt;- a1 * (S1 - R1) - (N1.dot + m1*N1)/e11 - (N2.dot + m2*N2)/e12 R2.dot &lt;- a2 * (S2 - R2) - (N1.dot + m1*N1)/e21 - (N2.dot + m2*N2)/e22 return( list(c(R1.dot, R2.dot, N1.dot, N2.dot)) ) } ) } (#fig:pcgr.RR)Per capita growth rate. Figure 7.18: Dynamics of competing species and the resources that they consume. 7.6 Summary This chapter has provided several useful results. We can represent species effects on each other in precisely the same way we represented their effects on themselves. Considering only two species, species \\(i\\) can invade species \\(j\\) when the effect of species \\(j\\) on species \\(i\\) is less than its effect of species \\(j\\) on itself. Two species coexist stably when their effects on each other are smaller than their effects on themselves. The dominant eigenvalue of the Jacobian matrix (perturbation growth rate), and its negative inverse, return time, are useful mathematical definitions of stability. Perturbation growth rate decreases as \\(\\beta_{ij},\\, \\beta_{ji}\\) decrease, and are either both less than one or both greater than 1 (\\(\\beta_{ij} = \\alpha_{ij}/\\alpha_{jj}\\)). The magnitude of perturbation growth rate increases with \\(r\\). References "],
["mutualisms.html", "8 Mutualisms 8.1 Background 8.2 Lotka-Volterra mutualism 8.3 Consumer-resource mutualism 8.4 Plant-soil feedbacks 8.5 Simulations for learning", " 8 Mutualisms 8.1 Background Mutualisms occur in a wide variety of different species. Mutualisms form the foundations of ecosystems including coral reefs (coral and zooxanthellae), grasslands, and forests (plants and mycorrhizal fungi, pollinators, and dispersers). The natural history of mutualisms are wildly diverse and complex, and and Boucher, James, and Keeler (1982) list types of mutualisms: Energetic Nutritional Defense Transport Obligate vs. facultative Direct vs. indirect Symbiotic vs. independent One of the most common of these is indirect mutualism (Fig. 8.2). In this case, a series of negative direct interactions can yield net positive indirect interactions, as in the classic case where ``the enemy of my enemy is my friend.’’ For instance, consider a three plant species that all compete for the same limiting resource. When species A suppresses species B, it is indirectly helping species C (Miller 1994). We will focus on direct mutualisms, and in this chapter, we’ll explore two approaches to modeling mutualisms, Lotka-Volterra models and consumer-resource models. 8.2 Lotka-Volterra mutualism Lotka-Volterra mutualism is very straightforward, following the same template as competition. All that we have to do is change the sign associated with the other species. As usual, \\(\\alpha_{ij}\\) is the per capita effect of species \\(j\\) on species \\(i\\). \\[\\begin{align*} \\frac{dN_1}{dt} &amp;= r_1N_1\\left( 1 - \\alpha_{11}N_1 + \\alpha_{12}N_2\\right)\\\\ \\frac{dN_2}{dt} &amp;= r_2N_2 \\left(1 + \\alpha_{21}N_1 - \\alpha_{22}N_2\\right) \\end{align*}\\] In the above equations we see the sign of the intraspecific terms \\(\\alpha_{ii}N_i\\) is negative, while the sign of the interspecific terms \\(\\alpha_{ij}N_j\\). The zero net growth isoclines are found the same way we found those for interspecific competition, by solving \\(dN_1/dt\\) (for zero). We will graph these, so we solve each in terms of species 1. \\[\\begin{align*} 0 &amp;= 1 + \\alpha_{21}N_1 - \\alpha_{22}N_2\\\\ N_2 &amp;= 1/\\alpha_{22} + \\frac{\\alpha_{21}}{\\alpha_{22}}N_1 \\end{align*}\\] \\[\\begin{align*} 0 &amp;= 1 - \\alpha_{11}N_1 + \\alpha_{12}N_2\\\\ N_2 &amp;=\\frac{\\alpha_{11}}{\\alpha_{12}}N_1 - 1/\\alpha_{12} \\end{align*}\\] The equilibria are \\[N_i^* = \\frac{\\alpha_{jj} + \\alpha_{ij}}{\\alpha_{ii}\\alpha_{jj} - \\alpha_{ij}\\alpha_{ji}}\\] Note this assumes that both \\(\\alpha_{jj}\\) and \\(\\alpha_{ji}\\), per se, are greater than zero, because our equation assumed it was so. Let’s use this to describe a facultative mutualism, that is, one in which neither species needs the other to persist, but in which they each do better. What we mean by that is that let \\(r&gt;0\\). For now, we will also assume that the mutualism provides only a modest benefit, where species benefits to each is smaller than the negative effects on themselves (\\(\\alpha_{ii} &gt; \\alpha_{ij}\\)). The dynamics are stable (Fig. 8.1) To illustrate the dynamics of this population, we will parameterize an ODE model. Our parameters meet our assumptions stated above. parameters &lt;- c(alpha11 = .2, alpha22 = .2, alpha12 = .1, alpha21=.1, r1=.01, r2=.01) Here we write an ODE model to help anaylze dynamics. mutualism.LV &lt;- function(t, y, params){ n1 &lt;- y[1]; n2 &lt;- y[2] with(as.list(params), { dn1.dt = r1*n1*(1 - alpha11*n1 + alpha12*n2) dn2.dt = r2*n2*(1 + alpha21*n1 - alpha22*n2) return(list( c(dn1.dt, dn2.dt) ) ) }) } The Lotka-Volterra approach predicts exclusion of one species in two realistic scenarios, obligate mutualisms and mutualisms with large effects. An obligate mutualism is one in which growth rate is negative in the absence of the mutualism. The way to describe that in Lotka-Volterra models is to set \\(r &lt; 0\\). This results in an unstable equilibrium which is a global repellor which results in the loss of one species. Second, if the benefit is greater than the negative intraspecific effect, we get an uncontrolled positive feedback loop leading to infinite population sizes. In this sense, it is like exponential growth: a potentially very useful idea, but it must be moderated somehow in order to reflect long term trajectories. Figure 8.1: Only weak facultative mutualisms are stable. 8.3 Consumer-resource mutualism In this section, we will model mutualisms using a framework that, unlike our Lotka-Volterra approach, is intended specifically to describe resource consumption by one or both partners (MacArthur 1972). Sometimes mutualists share resources, as with mycorrhizal associations, where species share a resource or a product that they can acquire or manufacture in surplus and trade it for a resource or product that is limiting. This is a bi-drectional mutualism (Fig. 8.2) because the flow of are bidirectional: both species provide a resource to the other (Holland and Deangelis 2010). Figure 8.2: Bidirection, unidirectional, and indirect mutualisms. Normal arrowhead is a positive effect, whereas an open dot arrowhead is a negative effect. A dashed line indicates a service, and a solid line indicates a consumable resource. In other cases, mutualists may share services, as with moray eel-grouper foraging. In this particular case, grouper and the giant moray eel have different foraging strategies, with the eel going into reef crevices and the grouper waiting outside to pick off prey that escape the eel (Bshary et al. 2006). Sometimes these mutualisms are called by-product mutualisms, in cases where there is no evidence of coordinated behavior, but nonetheless a mutualism arises via the independent activities of each species. In the following, we explore the type of mutualism in which one species provides a resource and the other species provides a service (Fig. 8.2). This is a uni-directional mutualism because the flow of resources is only unidrectional, from one species to the other (Holland and Deangelis 2010). A good example of a uni-directional of mutualism is seed dispersal via a frugivore that disperses seeds. A plant species provides a fruit that is nutritious for an animal. A primary benefit for the plant is that seeds are carried away from the parent plant. This may help seeds escape enemies that accumulate near parent plants (Connell-Janzen hypothesis). In addition, it provides a bet hedging opportunity wherein seeds are dispersed to a variety of habitats any one of which may be better for survival than the current location. It is even possible that dispersal is directed to preferred habitat that is consistently better than under the parent plant due to better resource levels or environmental conditions (Wenny and Levey 1998). The animal benefits by consuming the fleshy part of the fruit surrounding the seed. An interesting case arises when seed predators collect seeds but do not kill them before having buried, cached, or moved seeds. Another very important example example of this type of mutualism is pollination. Pollinators (bats, insects, birds) receive resources (nectar, pollen) and provide services (pollination, gene flow). 8.3.1 A model of uni-directional mutualism Here we describe a model of a facultative unidirectional mutualism that uses type II foraging model for both consumption of the resource and provision of the service. The growth equation for the plant species, \\(M_1\\), includes logistic growth, and has terms for the benefit it receives from its mutualist frugivore and the cost paid to that frugivore. \\[\\frac{dM_1}{dt} = r_1 M_1\\left(1-d_1M_1\\right) - aM_2\\left(\\frac{M_1}{h_1 + M_1}\\right) + sM_1\\left(\\frac{M_2}{h_2 + M_2}\\right)\\] The plant species (\\(M_1\\)) grows logistically in the absence of fruit consumption or seed dispersal \\(r_1 M_1\\left(1-d_1M_1\\right)\\). Consumption of fruits are governed by a type II functional response by the frugivore \\(aM_2\\left(\\frac{M_1}{h_1 + M_1}\\right)\\), so that the consumption rate of a single frugivore has an upper limit (Fig. 8.3). Successful seed dispersal and establishment is also governed by a type II functional response. The success of a single seed reaches an upper limit as the number of frugivores continues to increase, \\(c_1M_1\\left(\\frac{M_2}{h_2 + M_2}\\right)\\) (Fig. 8.3). ggplot(data.frame(x=c(0, 1)), aes(x=x) ) + stat_function(fun=function(x) { 10*x/(1+10*x) }) + labs( x=&quot;Fruit abundance&quot;, y=&quot;Consumption Rate of a frugivore&quot;) ggplot(data.frame(x=c(0, 1)), aes(x=x) ) + stat_function(fun=function(x) { 10*x/(1+10*x) }) + labs( x=&quot;Frugivore abundance&quot;, y=&quot;Dispersal rate of a seed&quot;) Figure 8.3: Fruit consumption by a single frugivore is governed by a type II functional response as fruit abundance increases. Successful seed dispersal and establishment is governed by a type II functional response as frugivores increase. The growth equation for the frugivore species, \\(M_2\\), includes logistic growth, and one term for the benefit gained from the plant. \\[\\frac{dM_2}{dt} = r_2M_2\\left(1-d_2M_2\\right) + eaM_2\\left(\\frac{M_1}{h_1+M_1}\\right) \\] The animal seed disperser grows logistically in in the absence of consuming this particular plant species \\(r_2M_2\\left(1-d_2M_2\\right)\\). The animal benefits from consuming the fruit which it attacks at the same rate as for \\(M_1\\), \\(aM_2\\left(\\frac{M_1}{h_1+M_1}\\right)\\), but converts the fruit into new individuals with efficiency \\(e\\). consumption &gt; service = net predation service &gt; consumption = net mutualism Here we provide code for the ODE for the complete bidirectional mutualism. When we define the parameters, we will set some of them equal to zero so that it represents a unidirectional consumer-resource mutualism. # The derivative ## A two-species consumer-resource mutualism ## Holland and DeAngelis 2009, Ecology Letters Ecology Letters, 12: 1357–1366. ## The parameterization follows that in this article. It differs from those ## in the above equations. Can you see the differences? cr_bimut &lt;- function(t,y,parameters) { M1 &lt;- y[1] # M2 &lt;- y[2] # with( as.list( parameters ), { dM1 &lt;- M1 * (r1 - d1*M1 + a12*M2/(h2 + M2) - B1*M2/(e1+M1) ) dM2 &lt;- M2 * (r2 - d2*M2 + a21*M1/(h1 + M1) - B2*M1/(e2+M2) ) list( c( dM1, dM2 )) } ) } And here are the parameters, and we graph the time series. ### These parameters create a unidirectional, resource-service mutualism (B2 = 0) ## Translating, a12 = a above, and a21 = ea above, and B1 = s above ## therefore e = a21/a12 p.u &lt;- list(r1 = 1, r2 = 1, d1=0.01, d2=0.01, a12 = 0.4, a21 = 0.25, B1 = 0.3, B2 = 0, h1=0.3, h2=0.3, e1=0.3, e2=0.3) ##### # times series t &lt;- seq(0,25, by=.1) y &lt;- c(M1=50, M2=1) out &lt;- ode(y=y, times=t, func= cr_bimut, parms=p.u) outdf &lt;- data.frame(out) outL &lt;- pivot_longer(outdf, -time, names_to=&quot;State_var&quot;, values_to=&quot;N&quot;) ggplot(outL, aes(time, N, colour=State_var)) + geom_line() The dynamics can result in multiple basins of attraction or alternative stable states (Fig. 8.4). Figure 8.4: A resource-service mutualism may result in alternative stable states. If both species achieve moderate abundance, then both species increase toward a stable mutualism. However, if the frugivore is too abundant relative to the plant, then its consumption dominates the interaction and drives the equilibrium mutualism. Holland and DeAngelis (2009) vary \\(a_{21}\\) between \\((0.25,\\ldots,\\,0.4)\\) to vary the relation from mutualism to predation. Try that now. Save a picture of your results. 8.4 Plant-soil feedbacks Vascular plants form the basis of terrestrial ecosystems, and they live in intimate contact with the most diverse group of organisms on Earth–soil microbes. Ecologists have begun to focus on this intimate relationship, and Jim Bever (Bever 2003) has been one of ecologists helping lead the way (Fig. 8.5). Figure 8.5: Plants and soil microbes can interact in negative or positive ways. Plants may grow more poorly with their own soil flora than with that of a competitor’s. Fig. 8.5 reflects the following Lotka-Volterra style model of plant species \\(N_A\\) and \\(N_B\\), and soil microbial floras \\(S_A\\) and \\(S_B\\): \\[\\begin{equation} \\frac{dN_A}{dt} = r_A N_A \\left( 1 + \\alpha_A S_A + \\beta_A S_B - \\frac{N_A + c_B N_B}{K_A}\\right) \\end{equation}\\] where the effects of microbes (\\(\\alpha\\), \\(\\beta\\)) could be positive or negative (e.g. pathogenic). The plants each have their own carrying capacities (\\(K\\)), and negative effects on each other (\\(c\\)). The corresponding equation for the other plant species is \\[\\begin{equation} \\frac{dN_B}{dt} = r_B N_B \\left( 1 + \\alpha_B S_A + \\beta_B S_B - \\frac{c_A N_A + N_B}{K_B}\\right). \\end{equation}\\] We often refer to the soil flora associated with a single plant species as its home flora, and the other as the away flora. Each microbial flora comprises many, many species and we aggregate the net effects. Bever (2003) further simplified his model by placing constraints on soil microbes, so that \\(S_A + S_B=1\\). This allows him to focus on the relations among microbes and plants. With these assumptions, he showed that the net effect of each flora as a single state variable for the home flora of each species: \\[\\frac{dS_A}{dt} = S_A(1-S_A) \\left( \\frac{N_A}{N_A + N_B} - \\nu\\frac{N_B}{N_A + N_B}\\right)\\] and that \\[S_B=1-S_A\\]. Coexistence criteria Bever states that (2003, p. 467, bottom of the second column) out that the interactions are more stable if \\[\\alpha_A + \\beta_B &lt; \\alpha_B + \\beta_A \\] which means that the effects of the home floras own their home plants are less positive (or more negative) then on the other species. Bever also argued that for either plant species to increase when rare (i.e. coexist), that the interspecific competition has to be less than the benefits of the interactions of the soil floras. However, his criterion in eqn 5 (p. 469) is not sufficient, and this is revealed by its lack of consistency with the parameter set and outcomes in Fig. 4. So, we will alter his equation a bit to reveal what probably would work. We use the parameterization from Chapter ?? so that it is consistent with others (Bolker, Pacala, and Neuhauser 2003; Chesson 2000). We reformulate the carrying capacities and \\(c_A\\) and \\(c_B\\) as \\[\\alpha_{AA}=1/K_A;\\,\\alpha_{BB}=K_B;\\,\\alpha_{BA}= c_A/K_B;\\,\\alpha_{AB}=c_B/K_A\\] If we recall our earlier work, we showed that each species \\(i\\) can invade when \\[\\frac{\\alpha_{ij}}{\\alpha_{jj}} &lt; 0\\] This translates to the Lotka-Volterra invasion criterion for species A is \\[\\frac{\\alpha_{AB}}{\\alpha_{BB}} =\\frac{c_b}{K_A}K_B\\] The invasion criterion for species B is \\[\\frac{\\alpha_{BA}}{\\alpha_{AA}} =\\frac{c_a}{K_B}K_A\\] The coexistence criterion is that each species must be able to invade when rare, including when the soil flora has no effect. Therefore, we have \\[\\begin{equation} \\left(\\frac{c_b}{K_A}K_B,\\, \\frac{c_a}{K_B}K_A\\right) &lt; \\frac{(1+\\alpha_B)(1+\\beta_A)}{(1+\\alpha_A)(1+\\beta_B)} \\tag{8.1} \\end{equation}\\] where both conditions on the left must be satisfied. In the numerator on the right, we have the effect of each soil flora on their away plant species. In the denominator, we have the effects of each flora on the home plant species. Thus, the fraction on the right is the relative benefit of the soil flora. Now we will create an ODE function that will let us see the dynamics play out. We need only model one soil flora because \\(S_B = 1-S_A\\). bever3 &lt;- function(t,y,p){ with(as.list(c(y,p)), { dNa &lt;- ra * Na * (1+alphaA*SA + betaA*(1-SA) - (Na + cB*Nb)/Ka) dNb &lt;- rb * Nb * (1+alphaB*SA + betaB*(1-SA) - (cA*Na + Nb)/Kb) dSA &lt;- SA*(1-SA) * ( Na/(Na+Nb) - nu*Nb/(Na+Nb) ) return(list(c(dNa, dNb, dSA), SB=1-SA)) }) } We will parameterize the model in a way that reveals the importance of the soil floras to coexistence, according to criteria stated above (8.1). We will create a vector of parameters, and then test whether the inequality in (8.1) is true. We start with an absence of a soil flora effect. p0 &lt;- list(ra=0.7, rb=0.5, Ka = 10, Kb=12, cA=.98, cB=.98, alphaA=0, alphaB=0, betaA=0, betaB=0, nu=0.8) Use the criterion above, and paper and a pencil, and see what you discover. We could also do it in R. with(p0, { cA/Kb*Ka &lt; (1+alphaB)*(1+betaA) / ( (1+alphaA)*(1+betaB)) }) ## [1] TRUE with(p0, { cB/Ka*Kb &lt; (1+alphaB)*(1+betaA) / ( (1+alphaA)*(1+betaB)) }) ## [1] FALSE This shows us we will not get coexistence in the absence of soil flora. Now we add the soil flora. p &lt;- list(ra=0.7, rb=0.5, Ka = 10, Kb=12, cA=.98, cB=.98, alphaA=-0.03, alphaB=0.1, betaA=0.1, betaB=-0.2, nu=0.8) Try your hand again, with paper and pencil. And then do it in R. with(p, { cA/Kb*Ka &lt; (1+alphaB)*(1+betaA) / ( (1+alphaA)*(1+betaB)) }) ## [1] TRUE with(p, { cB/Ka*Kb &lt; (1+alphaB)*(1+betaA) / ( (1+alphaA)*(1+betaB)) }) ## [1] TRUE On this basis, we should see that each species can invade when rare. Now let’s see the dynamics play out. Figure 8.6: Dynamics of competing plant species, subject to self-limiting negative feedbacks with soil pathogens. 8.5 Simulations for learning Often, we learn a lot by describing interactions in simple enough terms that we can analyze the interaction analytically, such as the way we analyzed Lotka-Volterra competition and mutualism. In more complex cases, we often cannot find an analytical, or closed form, solution, or if we do, it is so complex that it is difficult to extract meaning. In those cases, we may be able to learn a lot about the consequences of our model’s assumptions through simulation. Using simulation, we examine the observed dynamics for a wide range of parameter values and then infer general rules about how parameters or parameter combinations influence dynamics. In this study, we will use simulations to attempt to determine rules that govern the long-term dynamics of the mutualism model with linear density dependence in both intra- and interspecific interactions. We will also use simulation to confirm our earlier analytical solution and vice versa. 8.5.1 lvg() The core of our simulations will use a general purpose Lotka-Volterra model that simpy takes an interaction matrix and \\(r\\) as inputs. lvg &lt;- function (time, n, parameters) { r &lt;- parameters[[1]] a &lt;- parameters[[2]] dns.dt &lt;- r * n * (1 + (a %*% n)) return(list(c(dns.dt))) } In this model, the parameters are a list (a type of R data object) with two components. The first is a vector of r, one for each species we want to model. The second component of the list is the matrix of interaction coefficients. This matrix is square (same number of rows and columns). The elements of this matrix must have the correct sign. For instance, to represent competition, the relevant elements would have to be negative. Here we create an interaction matrix for a two-species Lotka-Volterra mutualism, where each species suffers from intraspecific competition, and benefits from its mutualist. a &lt;- matrix(c( -.1, .02, .02, -.09), nrow = 2, byrow=TRUE) a ## [,1] [,2] ## [1,] -0.10 0.02 ## [2,] 0.02 -0.09 Now let’s numerically integrate, or simulate, the model and plot the outcome. Comment your code to help remind you what is going on. # Let r be the same fpor each species r &lt;- c(1,1) parms &lt;- list(r=r, a=a) parms ## $r ## [1] 1 1 ## ## $a ## [,1] [,2] ## [1,] -0.10 0.02 ## [2,] 0.02 -0.09 t=seq(0,30, by=.1) N0 &lt;- c(N1=20, N2=5) lvout &lt;- as.data.frame( ode(N0, t, lvg, parms) ) lvL &lt;- pivot_longer(lvout, -time, names_to=&quot;State_vars&quot;, values_to=&quot;N&quot;) ggplot(lvL, aes(time, N, colour=State_vars, linetype=State_vars)) + geom_line() + geom_hline(yintercept=c(-1/a[1,1], -1/a[2,2]), linetype=c(1,3)) + annotate(geom=&quot;text&quot;, x=c(15, 20),y=c(-1/a[1,1], -1/a[2,2]), label=c(&quot;K1&quot;, &quot;K2&quot;), vjust=-0.2 ) Figure 8.7: Dyanmics of a Lotka-Volterra mutualism. 8.5.2 Systematic simulations When we use a model to explore the consequences of our assumptions, we want to use a range of plausible assumptions. In a case like this one where we are exploring a model more than the natural phenomenon it represents, we should use a wide range of parameter values that include cases where it is likely to fail. In our case, we will hold intraspecific density dependence constant and vary interspecific interaction coefficients from zero to twice the value of intraspecific interactions. We start with building the bits and pieces that the simulation will use, and then use a for-loop to cycle through all the parameter combinations we are interested in. # Use expand.grid to create systematically combinations of parameters df &lt;- expand.grid(a11 = -0.1, a12=seq(0, .2, by =.02), a21 = seq(0, .2, by=.02), a22=-0.1 ) dim(df) # The number of rows and columns ## [1] 121 4 head(df) # the top of the data frame ## a11 a12 a21 a22 ## 1 -0.1 0.00 0 -0.1 ## 2 -0.1 0.02 0 -0.1 ## 3 -0.1 0.04 0 -0.1 ## 4 -0.1 0.06 0 -0.1 ## 5 -0.1 0.08 0 -0.1 ## 6 -0.1 0.10 0 -0.1 # set intrinsic rates of increase... r &lt;- c(1,1) # and starting values... N0 &lt;- c(N1 = 10, N2= 10.001) # and times for which to return output. t &lt;- 0:200 # Set values that will be useful later on in our for-loop. n &lt;- length( t + 1 ) npar &lt;- nrow( df ) # create an empty data frame to hold our simulation output. output &lt;- data.frame( t = numeric(npar), N1 = numeric( npar ), N2 = numeric( npar ) ) ### USE A FOR-LOOP TO INTEGRATE THE MODEL FOR EACH COMBINATION OF PARAMETERS for( i in 1:npar ) { coefs.true &lt;- matrix( as.numeric( df[i,] ), nrow = 2, byrow = TRUE) invisible( capture.output( # capture.output is a function that allows us to avoid seeing warnings... # not usually a good idea to ignore warnings!!! # but it is OK here.... lvout &lt;- ode(N0, t, lvg, parms = list(r, coefs.true) ) ) ) # hang on to only the last row of output, and # put it in the i-th row of our output data frame. last &lt;- nrow(lvout) output[i,] &lt;- lvout[last,] } # Combine columns of parameters and output. simdat &lt;- cbind(df, output) 8.5.3 Checking simulation results Let’s look for anomalous results, such as negative population sizes, or infinite or “too” large sizes. # Do simplistic numerical summaries. summary(simdat[,5:7]) ## t N1 N2 ## Min. : 0.6931 Min. : 1.000e+01 Min. : 1.000e+01 ## 1st Qu.: 1.5576 1st Qu.: 2.100e+01 1st Qu.: 2.100e+01 ## Median :200.0000 Median : 7.000e+01 Median : 7.000e+01 ## Mean :122.9019 Mean :3.355e+146 Mean :3.355e+146 ## 3rd Qu.:200.0000 3rd Qu.:8.858e+145 3rd Qu.:8.858e+145 ## Max. :200.0000 Max. :8.187e+147 Max. :8.187e+147 If we run this, we see some strange population sizes and time was not always 200, showing that the numerical integration failed before completing. Also, \\(N\\) included unreasonably large values. Let’s look for all rows in which either \\(N_1\\) or \\(N_2\\) are huge (\\(&gt; 10\\,000\\)). # the vertical bar | means &quot;or&quot; sim.N &lt;- subset(simdat, N1 &gt; 10000 | N2 &gt; 10000) head(sim.N) ## a11 a12 a21 a22 t N1 N2 ## 43 -0.1 0.18 0.06 -0.1 3.241398 2.434044e+103 1.390882e+103 ## 44 -0.1 0.20 0.06 -0.1 2.399838 1.164783e+99 6.212179e+98 ## 52 -0.1 0.14 0.08 -0.1 2.889456 1.856660e+65 1.392495e+65 ## 53 -0.1 0.16 0.08 -0.1 2.139629 1.175804e+109 8.140182e+108 ## 54 -0.1 0.18 0.08 -0.1 1.774181 9.054385e+146 5.820676e+146 ## 55 -0.1 0.20 0.08 -0.1 1.541959 1.041579e+147 6.249472e+146 Notice also that values for \\(t\\) indicate that the integration couldn’t find values beyond a certain time point. Hmm. For now, let’s assume our simulation is doing what we think it is and that these results indicate a true lack of equilibrium. What could we do to learn the emerging rules? What if we just plot the values of \\(\\alpha_{ij},\\,\\alpha_{ji}\\) where \\(N\\) is really, really big? ggplot(sim.N, aes(a12, a21)) + geom_point() Figure 8.8: Values of \\(alpha\\) when N is extraordinarily large. What do we learn from just this figure? Write down a possible set of conditions necessary to get these anomalous results. 8.5.4 Comparing simulation results to analytical solutions Any time we do something novel in our modeling, we need to find a way to evaluate the novel approach to make sure it is doing what we think it is. When we have an analytical solution for our model, it is great to compare the analytical solution to the simulations. One thing we can do is to compare the long-term steady state values we get in simulation to the analytical equilibria of this mutualism model. First, we find analytical solutions for all of the equilibria predicted by the coefficients. Consult the equilibrium solution in the first section of the chapter. We then compare these to numerical solutions. Here we calculate the predicted equilibria for each row of our coefficients, using the above solution. denom &lt;- simdat[,1] * simdat[,4] - simdat[,2] * simdat[,3] # note this solution is subtracting the negative intraspecific comp coef. # making it consistent with our equations in section 1 num1 &lt;- simdat[,2] - simdat[,4] num2 &lt;- simdat[,3] - simdat[,1] N1.eq &lt;- num1 / denom N2.eq &lt;-num2 / denom # combine with simulation data set sim.check1 &lt;- cbind(simdat, N1.eq, N2.eq) # sim.check1[order(sim.check1$a12, sim.check1$a21),] Let’s find the subset with potential problems, such as for \\(N_1\\) or \\(N_2\\) less than than zero or really, really big (\\(&gt;10000\\)). problems1 &lt;- subset(sim.check1, (N1 &lt; 0 | N2 &lt; 0 | N1 &gt; 1e4 | N2 &gt; 1e4 ) ) # look at the subset ggplot(problems1, aes(N1, N1.eq)) + geom_point() Figure 8.9: Analytically calculated predictions for \\(N^*\\) vs. observed simulated \\(N\\). Fascinating! Both the analytical and the simulated results give us wacky, but very different results. Let’s examine the coefficients that generated these results. problems1[1:5,] ## a11 a12 a21 a22 t N1 N2 N1.eq ## 43 -0.1 0.18 0.06 -0.1 3.241398 2.434044e+103 1.390882e+103 -350.00000 ## 44 -0.1 0.20 0.06 -0.1 2.399838 1.164783e+99 6.212179e+98 -150.00000 ## 52 -0.1 0.14 0.08 -0.1 2.889456 1.856660e+65 1.392495e+65 -200.00000 ## 53 -0.1 0.16 0.08 -0.1 2.139629 1.175804e+109 8.140182e+108 -92.85714 ## 54 -0.1 0.18 0.08 -0.1 1.774181 9.054385e+146 5.820676e+146 -63.63636 ## N2.eq ## 43 -200.00000 ## 44 -80.00000 ## 52 -150.00000 ## 53 -64.28571 ## 54 -40.90909 What do you notice about these coefficients? What would you get for each term in the for the analytical equilibrium using the first row of data? How do you reconcile these results? Once we understand the anomalous results above, let’s compare the simulated and the analytical solutions for \\(N_1\\) and \\(N_2\\) both greater than zero and both less than a huge number. check2 &lt;- subset(sim.check1, (N1.eq &gt; 0 &amp; N2.eq &gt; 0) &amp; (N1 &lt; 1e4 &amp; N2 &lt; 1e4 )) Next we calculate the differences between the analytical solutions and the simulated values. N1.diff &lt;- check2$N1 - check2$N1.eq N2.diff &lt;- check2$N2 - check2$N2.eq summary(N1.diff); summary(N2.diff) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -1.421e-14 1.776e-15 3.553e-15 1.363e-13 7.105e-15 3.183e-12 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.842e-14 1.776e-15 3.553e-15 1.558e-13 7.105e-15 5.230e-12 These summaries show us that the differences between the analytical solutions and the numerical approximations are very, very, very small. That is a good thing. It gives us confidence that our simulations are doing what we think they are doing. So, we can now tentatively assume that our simulations are doing what we think they are, and we could have confidence with results that we generate. In practice, sometimes we simulate a very complex model and compare the results with a simpler, tractable analytical solution. Here, we get the hang of the approach by comparing simulations against known solutions. 8.5.5 One last thing: using the Jacobian matrix Use eigenanalysis of the Jacobian matrix to assess the stability of these equilibria. Consult eq. 5.21 and Table 5.2 of Stevens (2009). A sensible equilibrium. subset(sim.check1, a12 == .02 &amp; a21 == .02) ## a11 a12 a21 a22 t N1 N2 N1.eq N2.eq ## 13 -0.1 0.02 0.02 -0.1 200 12.5 12.5 12.5 12.5 # form remember that we set r = 1 J1 &lt;- matrix(c(-.1*12.5, -.02*12.5, -.02*12.5, -.1*12.5), nrow=2, byrow=TRUE) eigen(J1) ## eigen() decomposition ## $values ## [1] -1.0 -1.5 ## ## $vectors ## [,1] [,2] ## [1,] -0.7071068 0.7071068 ## [2,] 0.7071068 0.7071068 What do these results mean? A nonsensical equilibrium subset(sim.check1, a12 == .2 &amp; a21 == .2) ## a11 a12 a21 a22 t N1 N2 N1.eq N2.eq ## 121 -0.1 0.2 0.2 -0.1 0.6931166 8.389656e+145 8.389656e+145 -10 -10 J2 &lt;- matrix( c( -.1*(-10), -.2*(-10), -.2*(-10), -.1*(-10)), nrow=2, byrow=TRUE) eigen(J2) ## eigen() decomposition ## $values ## [1] 3 -1 ## ## $vectors ## [,1] [,2] ## [1,] 0.7071068 -0.7071068 ## [2,] 0.7071068 0.7071068 What do these results mean? ### In Fine So, how can you digest and communicate what you have found? You shjould be able to answer these questions: Did the simulation perform as you thought and how do you know? Did the simulation confirm something we first assessed analytically? If so, how? How do you explain the differences between the simulations and analytical equilibrium (extremely large vs. negative population sizes)? References "],
["consumer-resource-interactions.html", "9 Consumer-resource Interactions 9.1 Ratio dependence 9.2 Prey dependence 9.3 Interlude: Functional response - what an individual predator does 9.4 Stability analysis for the prey-dependent Lotka–Volterra model 9.5 Prey carrying capacity and type II functional response", " 9 Consumer-resource Interactions Consumption is unavoidably fundamental to life. Organisms are at a disequilibrium with their surroundings, requiring inputs of resources to maintain themselves, grow, and reproduce. We first considered organisms from this biophysical or energetic context when we discussed foraging. Optimal foraging theory seeks to understand individual behavior of diet choice as a solution to the problem of maximizing net resource gain per unit time. We have also considered population growth from a demographic context beginning in chapter 3 and have continued, as we described with \\[\\Delta N = B+I-D-E\\]. In consumer-resource theory, we combine biophysical and demographic approaches. Figure 9.1: Lynx-snowshoe hare cycles. One of the most famous examples of species interactions in all of ecology is the lynx–snowshoe hare cycle, based on data from the Hudson Bay Trading Co. trapping records (Fig. 9.1).50 For decades, the lynx–hare cycle was used as a possible example of a predator-prey interaction, until a lot of hard work by a lot of people (Stenseth et al. 1997; Krebs et al. 1995) showed an asymmetric dynamic — while the lynx depends quite heavily on the hare, and seems to track hare abundance, the hare cycles seem to be caused by more than just lynx. In this chapter, we will do a few things. First, we will cover a few flavors of enemy-victim models of different levels of complexity, and style. Also known as enemy–victim relations, or exploitative interactions, we represent cases in which one species has a negative effect and one a positive effect on the other. In doing so, we will illustrate some fundamental concepts about consumer–resource dynamics, such as how predators respond to prey abundances in both a numerical and a functional manner. We will try to develop an understanding of the range of dynamics for both continuous and discrete time systems. In this chapter, we discuss interactions between consumers and resources. In what we consider, the consumer is always an organism. However, we will consider cases in which the resource an inorganic substrate, such as nitrogen, and well as cases the resource is another organism. In general, we can conceptualize these as coupled equations, \\[\\begin{align*} \\frac{1}{R}\\frac{dR}{dt}&amp;= f_R\\left(R,C\\right)\\\\ \\frac{1}{C}\\frac{dC}{dt} &amp;= f_C\\left(C,R\\right) \\end{align*}\\] in which per-unit change in the resource is a function, \\(f_R\\), of the resource itself and the consumer. Likewise, per-unit change in the consumer is a function, \\(f_C\\), of the consumer itself, and the resource. Holt (2011) identified five universal propositions including that the consumption of resource necessarily reduces the amount of the resource. Both of these depend on the environmental context, but we’ll ignore that for now. We start with a famous consumer-resource pairing, that of predator and prey, also known as enemy-victim interactions. Let’s go all the way back to the beginning of this book where we introduced exponential growth. Let’s imagine that our exponentially growing population grows at rate \\[\\dot{N} = bN-dN\\] We knew that this, like all models, was wrong, but have argued that it is very useful. Indeed, it is in some ways null model for biological systems because exponential growth is so fundamental to life. Let us stick with this simplicity, and link a predator \\(P\\) to the prey. A very simple way to do this is to include predators as another source of death of prey (\\(aN\\)), and prey as the source of life for predators (\\(eaN\\)), \\[\\begin{align*} \\dot{N} &amp;= bN-dN -aN\\\\ \\dot{P} &amp;= eaN - mP \\end{align*}\\] where \\(e&lt;1\\) and is the relative efficiency with which predators turn captured prey into new predators. This efficiency, \\(e\\), shows us another general proposition about enemy-victim interactions; if we consider enemy and victim in the same units (e.g., grams), that the cost to the victim is always greater than the benefit to the enemy. This is simply the result of the second law of thermodynamics. With these two equations, we can make a simple prediction regarding the equilibrium, \\(P^*\\), by setting \\(\\dot{P} = 0\\), \\[P^* = \\frac{ea}{m}N\\quad ; \\quad \\frac{P}{N} = \\frac{ea}{m}\\] Thus, this simple theory predicts that the relative abundances of predator and prey will be constant. Because the prey only grow (or die) exponentially, this theory can make no prediction about \\(N^*\\). However, it does predict that predator and prey will persist at a constant ratio, assuming the parameters are fixed. 9.1 Ratio dependence If prey grows exponentially, so will the predators. If this is true, then it makes sense that the prey get captured at a constant per capita rate: the predators will always be lurking about at the same relative abundance. And this leads us to another way to think about these equations. Now we will make our predators explicit, so that the per capita capture rate of prey is \\(a\\) while the total rate also depends on \\(P\\). On average, the number of prey available to each predator is just \\(N/P\\). Therefore, predators will capture their share of prey at rate \\[aP\\frac{N}{P}\\] In this expression, we see that the capture rate of prey and growth rate of predators depends on the ratio of prey to predators. Putting this explicit treatment back into our model, we have \\[\\begin{align*} \\dot{N} &amp;= bN-dN -aP\\frac{N}{P}\\\\ \\dot{P} &amp;= eaP\\frac{N}{P} - mP \\end{align*}\\] We refer to this simple predator prey model as ratio-dependent predation (Arditi and Ginzburg 1989). We have added biological and mathematical complexity, and what is the end result? If we simplify these expressions, and let the \\(P\\)’s cancel out, we wind up just where we were before. That is reassuring. Both of these pairs of equations are the same: they describe ratio-dependent predation. As a first model of predator-prey interactions, this is analogous to exponential growth of a single population, and thus has some very satisfying properties: Prey and predator both grow and die exponentially; the predator is merely along for the ride. the populations are coupled by the simplest possible connection. 9.1.1 Dynamics of ratio dependent predation The dynamics of ratio-dependent predation are very simple. There are no cycles or fluctuations. It assumes that predation rate is a function of predator abundance and the ratio of prey to predators, and it predicts that predator abundance is is a constant fraction of the prey. This qualitative prediction is often roughly consistent with data. Let’s make a quick model, where we continue to make the ratio-dependence assumption transparent (\\((N/P)P\\)) for clarity.51 cr_ratio_dep_pred &lt;- function(time, y, parameters){ # the populations N &lt;- y[1]; P &lt;- y[2] with(as.list(parameters),{ # the equations dndt &lt;- r*N - a*N/P*P dpdt &lt;- e*a*N/P*P - m*P # returning a list with one component that is # a two element vector, c(rate1, rate2) return(list(c(dndt, dpdt))) }) } Now we run it and plot the output. t &lt;- 0:100 p &lt;- list(r=0.05, a=0.01, e=0.1, m=.1) y0 &lt;-c(N=100, P=3) outdf &lt;- as.data.frame(ode(y0, t, cr_ratio_dep_pred, p)) outL &lt;- pivot_longer(outdf, -time, names_to=&quot;State_vars&quot;, values_to=&quot;abun.&quot;) ggplot(outL, aes(time, abun., colour=State_vars)) + geom_line() + scale_y_log10() Figure 9.2: With the assumption of simple ratio-dependence, the predator population is a constant fraction of the prey population. If we plot these in state space, we get Fig. 9.3. Figure 9.3: The predator isocline under ratio dependence. There is no prey isocline because its abundance is completely independent of the predator population. Arrows indicate the trajectories. Note the prey are simply increaing Exercise Calculate by hand the equilibrium abundance of predators in the above model. 9.2 Prey dependence A more widely used model of predator-prey dynamics is that of Alfred Lotka and Vito Volterra. In this formulation, the per predator capture rate depends only on the prey abundance, not on the ratio of prey to predators. When capture rate is independent of the number of other predators in the population, we describe it thus. \\[\\begin{align*} \\dot{N} &amp;= bN-dN - aNP\\\\ \\dot{P} &amp;= eaNP - mP \\end{align*}\\] Here the per predator capture rate is simply \\(aN\\). We find equilibria, or more correctly, zero net growth isoclines, by setting \\(\\frac{P}{dt} = 0\\) and \\(\\frac{dN}{dt}=0\\). When we do this we get curious results. Predator isocline \\(\\frac{dP}{dt} = 0 \\implies N=\\frac{m}{ea}\\) Prey isocline \\(\\frac{dN}{dt} = 0 \\implies P=\\frac{a}{r}\\) Each population’s growth rate is zero when the other population is at a fixed value. More on this when we deal with dynamics later on. 9.2.1 Dyanmics of prey-dependent predation Now let’s create a numerical model of prey-dependent, or Lotka-Volterra, predation. cr_prey_dep_pred &lt;- function(time, y, parameters){ # the populations N &lt;- y[1]; P &lt;- y[2] with(as.list(parameters),{ # the equations dndt &lt;- r*N - a*N*P dpdt &lt;- e*a*N*P - m*P # returning a list with one component that is # a two element vector, c(rate1, rate2) return(list(c(dndt, dpdt))) }) } Now we run this model, using the same parameters, and plot the output. t &lt;- 0:200; y0 &lt;-c(N=100, P=3) p &lt;- list(r=0.05, a=0.01, e=0.1, m=.1) outdf &lt;- as.data.frame( ode(y0, t, cr_prey_dep_pred, p) ) outL &lt;- pivot_longer(outdf, -time, names_to=&quot;State_vars&quot;, values_to=&quot;abun.&quot;) ggplot(outL, aes(time, abun., colour=State_vars)) + geom_line() Figure 9.4: With the assumption of simple prey-dependence, dynamics are different than with ratio dependence.. With prey dependent predation, we get competely different dynamics. Let’s integrate for more time. Figure 9.5: Prey-dependent or Lotka-Volterra predation results in oscillations. Prey increase until predators are sufficiently abundant to control them, at which point they decline, leading to the decline of preadtors. The predator peaks lag behind the prey peaks. Figure 9.6: Prey-dependent or Lotka-Volterra predation results in oscillations. Prey increase until predators are sufficiently abundant to control them, at which point they decline, leading to the decline of preadtors. The predator peaks lag behind the prey peaks. Figure 9.7: The prey and predator isoclines under prey dependence. Arrows indicate the direction of changing population sizes. The black lines are tractories based on two different initial abundances. The ‘nullclines’ are the zero net growth isoclines for the prey (x) and the predator (y). Based on the arrow heads, we can see that the trajectories oscillate in a counterclockwise direction. Think about these isoclines for a bit. Under what conditions does the prey increase (arrows pointing right)? Under what conditions does the prey decrease (arrows pointing left)? This shows us that the prey increase whenever the predator abundance is below a certain value. We found that value above, and it is \\(P = r/a\\). When does the predator increase or decrease? When the prey is above or below a particular value, \\(N=m/(ea)\\). The only time these populations are at rest is when both of these are true. 9.3 Interlude: Functional response - what an individual predator does We refer to the per predator kill rate as the functional response. It is the response of a predator to different levels of \\(N\\) and \\(P\\). The functional response of the ratio-dependent model is \\(aN/P\\), where as for the prey-dependent model it is \\(aN\\) (Fig. 9.8). These are referred to as type I functional responses. Are these type I functional responses realistic? They both imply that a predator captures a constant fraction of all prey, no matter how many prey there are. It predicts that regardless whether there are two prey individuals or one gazillion prey, a single predator can nonetheless capture the same fraction. So, if prey reach high densities, then type I functional responses are not realistic. However, if prey never reach high densities, then type I is reasonable with the bounds of realized prey densities. What is typically thought to be more realistic is if the predator satiates, where the capture rate approaches a plateau as the density of prey increases. After all, a predator has to catch, subdue, and kill a prey item, swallow it, and then move on. Optimal foraging models (Chapter 2) typically account for this. Ecologists refer to this activity as “handling” and the time required to do that as handling time. Buzz Holling (1959) developed a mathematical form for a functional response with prey-dependent predation that includes handling time: \\[\\frac{aN}{1+ahN}\\] where \\(a\\) is attack rate, and \\(h\\) ia handling time. We refer to this functional response as a type II functional response (Fig. 9.8). As \\(N\\) gets really big, this fraction approaches \\(1/h\\), \\[\\lim_{N \\rightarrow \\infty} \\frac{aN}{1+ahN} = \\frac{1}{h}\\] If it is not yet clear why this should be, pause and reflect on it. We can do the same exercise using the ratio, \\(N/P\\), \\[\\lim_{N/P \\rightarrow \\infty} \\frac{aN/P}{1+ahN/P} = \\frac{1}{h}\\] Sometimes predators don’t feed a lot until there are enough prey available. Sometimes this is due to predators switching from one prey type to another once the other becomes sufficiently common. A predator may develop a search image for a prey type, and ignore others. We’ve all known people like that. We represent this via an exponent (\\(z&gt;1\\)) in our functional response, \\[\\frac{aN^z}{1+ahN^z}\\] where \\(z&gt;1\\) and we refer to this as a type III functional response. { par(mgp=c(0,1,1)) curve(.5*x, 0, 2.5, ylab=bquote(&quot;no. prey (or prey/predator) killed\\nper predator per time&quot;), xlab=&quot;N or N/P&quot;, axes=FALSE, main=&quot;Functional Responses&quot;) box() curve(x/(1+x), add=TRUE, lty=2 ) curve(x^3/(1+x^3), add=TRUE, lty=3 ) text(2, 1.2, &quot;Type I&quot;) text(2.5, 1, &quot;Type III&quot;, adj=1) text(2.5, .6, &quot;Type II&quot;, adj=1) par(mgp=c(0,1,1)) curve(.5*x/x, 0, 2.5, ylab=bquote(&quot;no. prey (or prey/predator) killed\\nper predator per time&quot;), ylim=c(0, 1), xlab=&quot;N or N/P&quot;, axes=FALSE, main=&quot;Functional Responses&quot;) box() curve(x/(1+x)/x, add=TRUE, lty=2 ) curve(x^3/(1+x^3)/x, add=TRUE, lty=3 ) text(0, .55, &quot;Type I&quot;, adj=0) text(0, .1, &quot;Type III&quot;, adj=0) text(0, 1, &quot;Type II&quot;, adj=0) } Figure 9.8: Left: Functional responses for either prey-dependent or ratio-dependent predation; \\(z=3\\). Right: Same functional responses on a per-prey basis. If we ever want to use data to ask about the behavior of a predator, it can be very difficult to distinguish between these foraging behaviors by fitting data to functional response curves. We typically have more success fitting data of kill rate per unit prey vs. prey density (Fig. 9.8) because there are qualitative differences in slope (negative vs. positive) at low prey density (Juliano 2001). The numerical response of the predator is simply the \\(dP/dt\\) vs. \\(N\\). 9.4 Stability analysis for the prey-dependent Lotka–Volterra model In this section, we will perform the necessary analytical work to understand the dynamics of Lokta–Volterra predator–prey dynamics, and we follow this up with a peek at the time series dynamics to confirm our understanding based on the analytical work. As before for competition, we follow four steps: determine equilibria, create the Jacobian matrix, and solve and use the Jacobian. Lotka–Volterra equilibrium All we have to do is to solve the isoclines for where they cross. Thus we could set these equations equal to each other. It turns out, however, that the isoclines were just straight lines, so we see that the equilibrium is at \\((r/a,\\,m/(ea))\\). Creating, solving and using the Jacobian matrix Take a look at the growth equations again. Here we take the partial derivatives of these because we want to know how each population growth rate changes in response to changes in the abundance each of the other population. The partial derivatives of the prey growth equation, with respect to itself and to the predator, go into the first row of the matrix, whereas the partial derivatives of the predator growth rate, with respect to the herbivore and itself go into the second row.52 \\[\\begin{align} \\tag{9.1} \\left( \\begin {array}{cc} \\frac{\\partial \\dot{N}}{\\partial N}&amp;\\frac{\\partial \\dot{N}}{\\partial P}\\\\ \\frac{\\partial \\dot{P}}{\\partial N}&amp;\\frac{\\partial \\dot{P}}{\\partial P} \\end {array} \\right) = \\left( \\begin {array}{cc} r-aP &amp; -aN\\\\ eaP &amp; eaN-g\\\\ \\end {array} \\right) \\end{align}\\] We can replace the \\(P\\) and \\(N\\) in the Jacobian with the equibria found above. When we do this, we get \\[\\begin{align} \\label{eq:jacLV2} \\left( \\begin {array}{cc} r-a(r/a)&amp;-a(m/(ae))\\\\ ea(r/a)&amp;ea(m/(ae))-s\\\\ \\end {array} \\right) = \\left( \\begin {array}{cc} 0&amp;-m/e\\\\ er&amp;0\\\\ \\end {array} \\right). \\end{align}\\] Typically a system will be more stable if the diagonal elements are more negative — that would mean that each population is self regulating, and it corresponds to the Routh-Hurwitz criterion (see the competition chapter for an earlier use of the Routh-Hurwitz criteria). \\[\\begin{equation} \\tag{9.2} \\mathbf{J_{11}} + \\mathbf{J_{22}} &lt; 0. \\end{equation}\\] We notice that in (??) these diagonal elements are both zero. These zeroes reveal that there is no negative density dependence within each population, that is, no self-regulation. The other part of the Routh-Hurwitz criteria is the condition, \\[\\begin{equation} \\tag{9.3} \\mathbf{J_{11}}\\mathbf{J_{22}-\\mathbf{J_{12}}\\mathbf{J_{21}}} &gt; 0. \\end{equation}\\] In the predator–prey context, this suggests that the herbivore declines due to the predator (\\(\\mathbf{J_{12}}&lt;0\\)) and the predator increases due to the herbivore (\\(\\mathbf{J_{21}}&gt;0\\)). The signs of these elements make their product negative, and help make the above condition true. Note that because \\(\\mathbf{J_{11}}\\mathbf{J_{22}}\\), this condition reduces to \\(bs&gt;0\\). Thus it seems that this will be true as along as both \\(b\\) and \\(s\\) are positive (which is always the case). We can perform eigenanalysis given the parameters above. # our parameters are inside the list called &#39;p&#39;, so we use &#39;with()&#39; Jac &lt;- with( p, matrix( c(0, -m/e, e*r, 0), byrow=TRUE, nr=2) ) eigen(Jac)[[&quot;values&quot;]] ## [1] 0+0.07071068i 0-0.07071068i We would find that the eigenvalues are complex. Because they are complex, this means that the populations will oscillate or cycle, with period \\(2\\pi/\\omega\\) (see Competition chapter). Because the real parts are zero, this means that the Lotka–Volterra predator–prey exhibits neutral stability. Recall that neutral stability is the “in-between” case where perturbations at the equilibrium neither grow nor decline over time. They merely change the abundances but cause no response. 9.5 Prey carrying capacity and type II functional response Among the more commonly used predator-prey models include a carrying capacity for the prey and a nonlinear type II functional response for the predator. This has commonly been attributed to Rosenzweig and MacArthur (1963), and others soon began using similar approaches (May 1973). Here is a common version, which I’ll refer to as our Rosenzweig-MacArthur model: \\[\\begin{align*} \\frac{dN}{dt} &amp;= rN(1-\\alpha N) - \\frac{aN}{1+ahN}P \\frac{dP}{dt} &amp;= e\\frac{aN}{1+ahN}P - mP \\end{align*}\\] To investigate its dynamics, we can create an ODE function of this consumer-resource model. cr_RM_pred &lt;- function(time, y, p){ N &lt;- y[1]; P &lt;- y[2] with(as.list(p),{ dN &lt;- r*N*(1-alpha*N) - a*N*P/(1+a*h*N) dP &lt;- e*a*N*P/(1+a*h*N) - m*P return(list(c(dN, dP))) }) } t &lt;- 0:100; y0 &lt;-c(N=100, P=3) p &lt;- list(r=0.8, alpha=0.001, a=.02, e=0.04, m=.15, h=.1) outdf &lt;- as.data.frame( ode(y0, t, cr_RM_pred, p) ) outL &lt;- pivot_longer(outdf, -time, names_to=&quot;State_vars&quot;, values_to=&quot;abun.&quot;) ggplot(outL, aes(time, abun., colour=State_vars)) + geom_line() Figure 9.9: Predator-prey dynamics with prey carrying capacity and type II predator functional response. With these parameter values, we see damped oscillations. If we plot the isoclines, we can see the dynamical phase plane more clearly. Figure 9.10: Damped oscillations can arise with prey negative density dependence, and a type II predator funcional response. Arrows indicate the direction of changing population sizes. The black lines are tractories based on two different initial abundances. The nullclines are the zero net growth isoclines for the prey (x) and the predator (y). Based on the arrow heads, we can see that the trajectories oscillate in a counterclockwise direction. ## [,1] ## [1,] 300.0 ## [2,] 44.8 9.5.1 Paradox of enrichment Rosenzweig (1971) showed an unexpected phenomenon — that increasing a prey’s carry capacity could drive it to extinction. This can happen if the prey grow too quickly to high abundance and temporarily support a high abundance of predators which then drive the prey extinct. We can demonstrate that here by lowering \\(\\alpha\\) enough to increase oscillations so that abundances get infinitessimally close to zero. t &lt;- 0:100; y0 &lt;-c(N=100, P=3) p &lt;- list(r=0.8, alpha=0.0005, a=.02, e=0.04, m=.15, h=.1) outdf &lt;- as.data.frame( ode(y0, t, cr_RM_pred, p) ) outL &lt;- pivot_longer(outdf, -time, names_to=&quot;State_vars&quot;, values_to=&quot;abun.&quot;) ggplot(outL, aes(time, abun., colour=State_vars)) + geom_line() Figure 9.11: Predator-prey dynamics with prey carrying capacity and type II predator functional response. With these parameter values, we see damped oscillations. References "],
["disease.html", "10 Disease", " 10 Disease Here we discuss epidemiological disease models. Pathogens cause diseases, and are typically defined as microorganisms (fungi, bacteria, and viruses) with some host specificity, and which undergo population growth within the host. Our simplest models of disease are funny, in that they don’t model pathogens (the enemy) at all. These famous models, by Kermack and McCormick (1927), keep track of different types of hosts, primarily those with and without diseas that model all \\(N\\) hosts by keeping track of where \\(N=S+I+R\\). It is important to note that \\(N\\), \\(S\\), \\(I\\), and \\(R\\) are . That is, we track numbers of individuals in a fixed area. This is important because it has direct consequences for the spread, or transmission, of disease (McCallum, Barlow, and Hone 2001). Disease spreads from infected individuals to susceptible individuals. The rate depends to some extent on the number or alternatively, on the fraction of the population that is infected. Resistant individuals are not typically considered vectors of the pathogens, and so increased abundance of resistant individuals slow the transmission rate by diluting the other two groups. A good starting place is a simple SIR model for a population of constant size, with no immigration or emigration (Ellner and Guckenheimer 2006, @Kermack:1927fk). \\[\\begin{align*} \\tag{10.1} \\frac{d S}{d t} &amp;= -\\beta IS\\\\ \\frac{d I}{d t} &amp;=\\beta IS - \\gamma I\\\\ \\frac{d R}{d t} &amp;= \\gamma I \\end{align*}\\] # Here we create the function for the simple SIR model. SIR &lt;- function(t, y, p) { with( as.list(c(y, p)), { dS.dt &lt;- -B*I*S dI.dt &lt;- B*I*S - g*I dR.dt &lt;- g*I return( list(c(dS.dt, dI.dt, dR.dt)) ) } ) } In this model, the transmission coefficient, \\(\\beta\\), describes the instantaneous rate at which the number of infected hosts increases per infected individual. It is directly analogous to the attack rate of type I prey-dependent models. Recall that it is based on the law of mass action, borrowed from physics and chemistry. It assumes that the rate at which events occur (new infections) is due to complete and random mixing of the reactants (\\(S,\\,I\\)), and the rate at which the reactants collide and react can be described by a single constant, \\(\\beta\\). As density of either type of molecule increases, so too does the rate of interaction. In prey-dependent predation, we referred to \\(aN\\) as a linear functional response; here we refer to \\(\\beta S\\) as the density-dependent transmission function. The transmission rate is the instantaneous rate for the number of new infections or cases per unit time (McCallum, Barlow, and Hone 2001). Resistant individuals might be resistant for one of two reasons. They may die, or they may develop immunities. In either case, we assume they cannot catch the disease again, nor spread the disease. As this model assumses a constant population size, we continue to count all \\(R\\) individuals, regardless of whether they become immune or die. The individuals become resistant to this disease at the constant per capita rate, \\(\\gamma\\). The rate \\(\\gamma\\) is also the inverse of the mean residence time, or , of the disease. Disease is the number of new infections or cases occurring over a defined time interval. This definition makes incidence a discrete-time version of transmission rate. is the fraction of the population that is infected \\(I/N\\). A common question in disease ecology is to ask under what conditions will an outbreak occur. Another way of asking that is to ask what conditions cause \\(\\dot{I}&gt;0\\). We can set \\(dI/dt &gt; 0\\) and solve for something interesting about what is required for an outbreak to occur. \\[\\begin{align} 0 &amp; &lt; \\beta IS - \\gamma I\\notag\\\\ \\frac{\\gamma}{\\beta} &amp;&lt; S \\end{align}\\] What does this tell us? First, because we could divide through by \\(I\\), it means that if no one is infected, then an outbreak can’t happen — it is the usual, but typically unstable equilibrium at 0. Second, it tells us that an outbreak will occur if the absolute density of susceptibles53 is greater than \\(\\gamma / \\beta\\). If we consider the pre-outbreak situation where \\(S \\approx N\\), then simply making the population size (and density) low enough can halt the spread of disease. This is why outbreaks tend to occur in high density populations, such as agricultural hosts (e.g., cattle), or historically in urban human populations, or in schools. Vaccinations are a way to reduce \\(S\\) without reducing \\(N\\). If a sufficient number of individuals in the population are vaccinated to reduce \\(S\\) below \\(\\gamma / \\beta\\), this tends to protect the unvaccinated individuals as well. Another common representation of this is called the force of infection or basic reproductive rate of the disease. If we assume that in a large population \\(S \\approx N\\), then rearranging eq. (10.2) gives us \\[\\begin{equation} \\tag{10.2} R_0=\\frac{\\beta N}{\\gamma} \\end{equation}\\] where \\(R_0\\) is the basic reproductive rate of the disease. If \\(R_0 &gt; 1\\), then an outbreak (i.e., disease growth) is plausible. This is analogous to the finite rate of increase of a population where \\(\\lambda&gt;1\\). Here we model the outbreak of a nonlethal disease (e.g., a new cold virus in winter on a university campus). We assume that the disease is neither life-threatening, and nor is anyone resistant, thus \\(R_{t=0}=0\\). We can investigate the SIR model by pretending that, as is often the case, we begin with a largely uninfected population and \\(t=0\\), so \\(I_0=1\\) and \\(S_0\\approx N\\). We first set parameters. Let’s imagine that a N &lt;- 10^4; I &lt;- R &lt;- 1; S &lt;- N - I - R y &lt;- c(S=S, I=I, R=R) parms &lt;- c(B=.01, g=4) # Next we integrate for three months. months &lt;- seq(0,3, by=0.01) out1 &lt;- data.frame( ode(y, months, SIR, parms) ) out2 &lt;- pivot_longer(out1, cols=S:R, names_to=&quot;Host&quot;, values_to=&quot;N&quot;) ggplot(out2, aes(time, N, linetype=Host)) + geom_line() + labs(x=&quot;Months&quot;) # Emerald ash borer? N &lt;- 10^4; I &lt;- R &lt;- 1; S &lt;- N - I - R y &lt;- c(S=S, I=I, R=R) # ash death takes about 4 years to die, # meaning it is infected for about 4 years duration &lt;- 4 gamma = 1/duration # question = how to estimate beta? beta = .0005 parms &lt;- c(B=beta, g=gamma) years &lt;- seq(0,10, by=0.01) out1 &lt;- data.table( ode(y, years, SIR, parms) ) out2 &lt;- pivot_longer(out1, cols=S:R, names_to=&quot;Host&quot;, values_to=&quot;N&quot;) ggplot(out2, aes(time, N, linetype=Host)) + geom_line() + labs(x=&quot;Years&quot;) It is important at this point to reiterate a point we made above — these conclusions apply when S, I, and R are densities (McCallum, Barlow, and Hone 2001). If you increase population size but also the area associated with the population, then you have not changed density. If population size only increases, but density is constant, then interaction frequency does not increase. Some populations may increase in density as they increase is size, but some may not. Mass action dynamics are the same as type I functional response as predators — there is a constant linear increase in per capita infection rate as the number of susceptible hosts increases. 10.0.1 SIR with frequency–dependent transmission In addition to density dependent transmission, investigators have used other forms of density dependence. One the most common is typically known as frequency–dependent transmission, where transmission depends on the prevalence, or the frequency of infecteds in the population, \\(I/N\\). \\[\\begin{align} \\frac{d S}{d t} &amp;= - \\beta \\frac{SI}{N} \\#eq:SIRfd1\\\\ \\frac{d I}{d t} &amp;= \\beta \\frac{SI}{N} - \\gamma I \\#eq:SIRfd2\\\\ \\frac{d I}{d t} &amp;= \\gamma I. \\#eq:SIRfd2 \\end{align}\\] Here we create the function for the system of ODEs in eq. . SIRf &lt;- function(t, y, p) { N &lt;- sum(y) with( as.list(c(y,p)), { dS.dt &lt;- -B*I*S/N dI.dt &lt;- B*I*S/N - g*I dR.dt &lt;- g*I return( list(c(dS.dt, dI.dt, dR.dt)) ) } ) } The proper form of the transmission function depends on the mode of transmission (McCallum, Barlow, and Hone 2001). Imagine two people are on an elevator, one sick (infected), and one healthy but susceptible, and then the sick individual sneezes (Ellner and Guckenheimer 2006). This results in a particular probability, \\(\\beta\\), that the susceptible individual gets infected. Now imagine resistant individuals get on the elevator — should adding resistant individuals change the probability that the susceptible individual gets infected? Note what has and has not changed. First, with the addition of a resistant individual, \\(N\\) has increased, and prevalence, \\(I/N\\), has decreased. However, the densities of \\(I\\) and \\(S\\) remain the same (1 per elevator). What might happen? There are at least two possible outcomes: If sufficient amounts of the virus spread evenly throughout the elevator, adding a resistant individual does not change the probability of the susceptible becoming sick, and the rate of spread will remain dependent on the densities of \\(I\\) and \\(S\\) — the rate will not vary with declining prevalence. If only the immediate neighbor gets exposed to the pathogen, then the probability that the neighbor is susceptible declines with increasing \\(R\\), and thus the rate of spread will decline with declining prevalence. It is fairly easy to imagine different scenarios, and it is very important to justify the form of the function. R &lt;- 0; S &lt;- I &lt;- 1000; Ss &lt;- Is &lt;- seq(1, S, length=11); N &lt;- S+I+R betaD &lt;- 0.1; betaF &lt;- betaD*N # sapply will calculate the transmission functions for each combination of # the values of $I$ and $S$. mat1 &lt;- sapply(Is, function(i) betaD * i * Ss) mat2 &lt;- sapply(Is, function(i) betaF * i * Ss / (i + Ss + R) ) # Now we plot these matrices. { layout(matrix(1:2, nr=1)) persp(mat1, theta=20, phi=15, r=10, zlim=c(0,betaD*S*I), main=&quot;Density Dependent&quot;, xlab=&quot;I&quot;, ylab=&quot;S&quot;, zlab=&quot;Transmission Rate&quot;) persp(mat2, theta=20, phi=15, r=10, zlim=c(0,betaF*S*I/N), main=&quot;Frequency Dependent&quot;, xlab=&quot;I&quot;, ylab=&quot;S&quot;, zlab=&quot;Transmission Rate&quot;) } 10.0.2 Antonovic et al. Metapopulation disease dynamics Silene alba and Microbotryum violacea Proportion of subpopulations that have an infected plant increases with the size of the subpopulation Disease prevalence declines with subpopulation size. This is characteristic of frequency-dependent transmission. 10.0.3 Lyme Disease Van Buskirk and Ostfeld 1995 Eco. Appl. Borrelia burgdorferi spirochete Blacklegged tick Ixodes scapularis Peromyscus leucopus Whitefooted mouse Whitetailed deer Oedicoilius virginiana spring 1: eggs summer 1: larva on intermediate host - small mammal or bird spring 2: nymph a new intermediate host small mammal or bird summer 2: drops off host 2, seeks definitive host (tyupically deer); most dangerous to humans fall 2: adult on deer (low risk to humans) host competence: whitefooted mice vs. chipmunks and birds References "],
["references.html", "11 References", " 11 References "]
]
